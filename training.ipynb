{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "993a70ad-9bef-468d-99b1-c0d2aaa0d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 11:55:23.953388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import learned_simulator\n",
    "import noise_utils\n",
    "import reading_utils\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import tree\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216a8b27-c8e4-4731-ba58-867a1cb99aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-14 11:28:32--  https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/WaterDrop/metadata.json\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.212.208, 216.58.212.240, 142.250.179.240, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.212.208|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 361 [application/octet-stream]\n",
      "Saving to: ‘/tmp/datasets/metadata.json’\n",
      "\n",
      "/tmp/datasets/metad 100%[===================>]     361  --.-KB/s    in 0s      \n",
      "\n",
      "2021-10-14 11:28:34 (116 MB/s) - ‘/tmp/datasets/metadata.json’ saved [361/361]\n",
      "\n",
      "--2021-10-14 11:28:34--  https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/WaterDrop/train.tfrecord\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.169.16, 216.58.213.16, 142.250.200.16, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.169.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4541246980 (4.2G) [application/octet-stream]\n",
      "Saving to: ‘/tmp/datasets/train.tfrecord’\n",
      "\n",
      "/tmp/datasets/train 100%[===================>]   4.23G  49.1MB/s    in 82s     \n",
      "\n",
      "2021-10-14 11:29:56 (52.8 MB/s) - ‘/tmp/datasets/train.tfrecord’ saved [4541246980/4541246980]\n",
      "\n",
      "--2021-10-14 11:29:56--  https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/WaterDrop/valid.tfrecord\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.169.16, 216.58.213.16, 142.250.200.16, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.169.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 137190408 (131M) [application/octet-stream]\n",
      "Saving to: ‘/tmp/datasets/valid.tfrecord’\n",
      "\n",
      "/tmp/datasets/valid 100%[===================>] 130.83M  68.9MB/s    in 1.9s    \n",
      "\n",
      "2021-10-14 11:29:59 (68.9 MB/s) - ‘/tmp/datasets/valid.tfrecord’ saved [137190408/137190408]\n",
      "\n",
      "--2021-10-14 11:29:59--  https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/WaterDrop/test.tfrecord\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.169.16, 216.58.213.16, 142.250.200.16, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.169.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 136885800 (131M) [application/octet-stream]\n",
      "Saving to: ‘/tmp/datasets/test.tfrecord’\n",
      "\n",
      "/tmp/datasets/test. 100%[===================>] 130.54M  67.8MB/s    in 1.9s    \n",
      "\n",
      "2021-10-14 11:30:02 (67.8 MB/s) - ‘/tmp/datasets/test.tfrecord’ saved [136885800/136885800]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "!mkdir -p '/tmp/datasets'\n",
    "!wget -O /tmp/datasets/metadata.json https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/WaterDrop/metadata.json\n",
    "!wget -O /tmp/datasets/train.tfrecord https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/WaterDrop/train.tfrecord\n",
    "!wget -O /tmp/datasets/valid.tfrecord https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/WaterDrop/valid.tfrecord\n",
    "!wget -O /tmp/datasets/test.tfrecord https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/WaterDrop/test.tfrecord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9c08155e-e9f2-4264-aa46-2569938b8f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SEQUENCE_LENGTH = 6  # So we can calculate the last 5 velocities.\n",
    "NUM_PARTICLE_TYPES = 9\n",
    "KINEMATIC_PARTICLE_ID = 3\n",
    "\n",
    "batch_size=2\n",
    "\n",
    "def _read_metadata(data_path):\n",
    "    with open(os.path.join(data_path, 'metadata.json'), 'rt') as fp:\n",
    "        return json.loads(fp.read())\n",
    "\n",
    "def prepare_inputs(tensor_dict):\n",
    "  \"\"\"Prepares a single stack of inputs by calculating inputs and targets.\n",
    "\n",
    "  Computes n_particles_per_example, which is a tensor that contains information\n",
    "  about how to partition the axis - i.e. which nodes belong to which graph.\n",
    "\n",
    "  Adds a batch axis to `n_particles_per_example` and `step_context` so they can\n",
    "  later be batched using `batch_concat`. This batch will be the same as if the\n",
    "  elements had been batched via stacking.\n",
    "\n",
    "  Note that all other tensors have a variable size particle axis,\n",
    "  and in this case they will simply be concatenated along that\n",
    "  axis.\n",
    "\n",
    "\n",
    "\n",
    "  Args:\n",
    "    tensor_dict: A dict of tensors containing positions, and step context (\n",
    "    if available).\n",
    "\n",
    "  Returns:\n",
    "    A tuple of input features and target positions.\n",
    "\n",
    "  \"\"\"\n",
    "  # Position is encoded as [sequence_length, num_particles, dim] but the model\n",
    "  # expects [num_particles, sequence_length, dim].\n",
    "  pos = tensor_dict['position']\n",
    "  pos = tf.transpose(pos, perm=[1, 0, 2])\n",
    "\n",
    "  # The target position is the final step of the stack of positions.\n",
    "  target_position = pos[:, -1]\n",
    "\n",
    "  # Remove the target from the input.\n",
    "  tensor_dict['position'] = pos[:, :-1]\n",
    "\n",
    "  # Compute the number of particles per example.\n",
    "  num_particles = tf.shape(pos)[0]\n",
    "  # Add an extra dimension for stacking via concat.\n",
    "  tensor_dict['n_particles_per_example'] = num_particles[tf.newaxis]\n",
    "\n",
    "  if 'step_context' in tensor_dict:\n",
    "    # Take the input global context. We have a stack of global contexts,\n",
    "    # and we take the penultimate since the final is the target.\n",
    "    tensor_dict['step_context'] = tensor_dict['step_context'][-2]\n",
    "    # Add an extra dimension for stacking via concat.\n",
    "    tensor_dict['step_context'] = tensor_dict['step_context'][tf.newaxis]\n",
    "  return tensor_dict, target_position\n",
    "\n",
    "def batch_concat(dataset, batch_size):\n",
    "  \"\"\"We implement batching as concatenating on the leading axis.\"\"\"\n",
    "\n",
    "  # We create a dataset of datasets of length batch_size.\n",
    "  windowed_ds = dataset.window(batch_size)\n",
    "\n",
    "  # The plan is then to reduce every nested dataset by concatenating. We can\n",
    "  # do this using tf.data.Dataset.reduce. This requires an initial state, and\n",
    "  # then incrementally reduces by running through the dataset\n",
    "\n",
    "  # Get initial state. In this case this will be empty tensors of the\n",
    "  # correct shape.\n",
    "  initial_state = tree.map_structure(\n",
    "      lambda spec: tf.zeros(  # pylint: disable=g-long-lambda\n",
    "          shape=[0] + spec.shape.as_list()[1:], dtype=spec.dtype),\n",
    "      dataset.element_spec)\n",
    "\n",
    "  # We run through the nest and concatenate each entry with the previous state.\n",
    "  def reduce_window(initial_state, ds):\n",
    "    return ds.reduce(initial_state, lambda x, y: tf.concat([x, y], axis=0))\n",
    "\n",
    "  return windowed_ds.map(\n",
    "      lambda *x: tree.map_structure(reduce_window, initial_state, x))\n",
    "\n",
    "\n",
    "def prepare_rollout_inputs(context, features):\n",
    "  \"\"\"Prepares an inputs trajectory for rollout.\"\"\"\n",
    "  out_dict = {**context}\n",
    "  # Position is encoded as [sequence_length, num_particles, dim] but the model\n",
    "  # expects [num_particles, sequence_length, dim].\n",
    "  pos = tf.transpose(features['position'], [1, 0, 2])\n",
    "  # The target position is the final step of the stack of positions.\n",
    "  target_position = pos[:, -1]\n",
    "  # Remove the target from the input.\n",
    "  out_dict['position'] = pos[:, :-1]\n",
    "  # Compute the number of nodes\n",
    "  out_dict['n_particles_per_example'] = [tf.shape(pos)[0]]\n",
    "  if 'step_context' in features:\n",
    "    out_dict['step_context'] = features['step_context']\n",
    "  out_dict['is_trajectory'] = tf.constant([True], tf.bool)\n",
    "  return out_dict, target_position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dca61597-9862-4d9f-a0f7-218538136fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_inputs at 0x7f68c60631f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmphrxadieq.py, line 13)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function prepare_inputs at 0x7f68c60631f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmphrxadieq.py, line 13)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = '/tmp/datasets'\n",
    "\n",
    "# Loads the metadata of the dataset.\n",
    "metadata = _read_metadata(data_path)\n",
    "#Create a tf.data.Dataset from the TFRecord.\n",
    "\n",
    "ds = tf.data.TFRecordDataset([os.path.join(data_path, 'train.tfrecord')])\n",
    "ds = ds.map(functools.partial(reading_utils.parse_serialized_simulation_example, metadata=metadata))\n",
    "# Splits an entire trajectory into chunks of 7 steps.\n",
    "# Previous 5 velocities, current velocity and target.\n",
    "split_with_window = functools.partial(\n",
    "    reading_utils.split_trajectory,\n",
    "    window_length=INPUT_SEQUENCE_LENGTH + 1)\n",
    "ds = ds.flat_map(split_with_window)\n",
    "# Splits a chunk into input steps and target steps\n",
    "ds = ds.map(prepare_inputs)\n",
    "# If in train mode, repeat dataset forever and shuffle.\n",
    "ds = ds.repeat()\n",
    "ds = ds.shuffle(512)\n",
    "# Custom batching on the leading axis.\n",
    "ds = batch_concat(ds, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "14cb6ad8-950e-48e6-8d65-a080c6d4a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_std=6.7e-4\n",
    "latent_size=128\n",
    "hidden_size=128\n",
    "hidden_layers=2\n",
    "message_passing_steps=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85213a69-192d-47c4-8e60-86a7114e3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Gets one step model for training simulation.\"\"\"\n",
    "metadata = _read_metadata(data_path)\n",
    "model_kwargs = dict(\n",
    "      latent_size=latent_size,\n",
    "      mlp_hidden_size=hidden_size,\n",
    "      mlp_num_hidden_layers=hidden_layers,\n",
    "      num_message_passing_steps=message_passing_steps)\n",
    "def _combine_std(std_x, std_y):\n",
    "  return np.sqrt(std_x**2 + std_y**2)\n",
    "\n",
    "Stats = collections.namedtuple('Stats', ['mean', 'std'])\n",
    "vel_noise_std=noise_std\n",
    "acc_noise_std=noise_std\n",
    "\"\"\"Instantiates the simulator.\"\"\"\n",
    "# Cast statistics to numpy so they are arrays when entering the model.\n",
    "cast = lambda v: np.array(v, dtype=np.float32)\n",
    "acceleration_stats = Stats(cast(metadata['acc_mean']), _combine_std(cast(metadata['acc_std']), acc_noise_std))\n",
    "velocity_stats = Stats(cast(metadata['vel_mean']),_combine_std(cast(metadata['vel_std']), vel_noise_std))\n",
    "normalization_stats = {'acceleration': acceleration_stats, 'velocity': velocity_stats}\n",
    "\n",
    "\n",
    "\n",
    "if 'context_mean' in metadata:\n",
    "    context_stats = Stats(cast(metadata['context_mean']), cast(metadata['context_std']))\n",
    "    normalization_stats['context'] = context_stats\n",
    "\n",
    "\n",
    "simulator = learned_simulator.LearnedSimulator(\n",
    "      num_dimensions=metadata['dim'],\n",
    "      connectivity_radius=metadata['default_connectivity_radius'],\n",
    "      graph_network_kwargs=model_kwargs,\n",
    "      boundaries=metadata['bounds'],\n",
    "      num_particle_types=NUM_PARTICLE_TYPES,\n",
    "      normalization_stats=normalization_stats,\n",
    "      particle_type_embedding_size=16)\n",
    "\n",
    "\n",
    "KINEMATIC_PARTICLE_ID = 3\n",
    "def get_kinematic_mask(particle_types):\n",
    "  \"\"\"Returns a boolean mask, set to true for kinematic (obstacle) particles.\"\"\"\n",
    "  return tf.equal(particle_types, KINEMATIC_PARTICLE_ID)\n",
    "\n",
    "#@tf.function\n",
    "def loss_fn(features, labels):\n",
    "    target_next_position = labels\n",
    "    # Sample the noise to add to the inputs to the model during training.\n",
    "    sampled_noise = noise_utils.get_random_walk_noise_for_position_sequence(\n",
    "        features['position'], noise_std_last_step=noise_std)\n",
    "    non_kinematic_mask = tf.logical_not(get_kinematic_mask(features['particle_type']))\n",
    "    noise_mask = tf.cast(non_kinematic_mask, sampled_noise.dtype)[:, tf.newaxis, tf.newaxis]\n",
    "    sampled_noise *= noise_mask\n",
    "\n",
    "    # Get the predictions and target accelerations.\n",
    "    pred_target = simulator.get_predicted_and_target_normalized_accelerations(\n",
    "        next_position=target_next_position,\n",
    "        position_sequence=features['position'],\n",
    "        position_sequence_noise=sampled_noise,\n",
    "        n_particles_per_example=features['n_particles_per_example'],\n",
    "        particle_types=features['particle_type'],\n",
    "        global_context=features.get('step_context'))\n",
    "    pred_acceleration, target_acceleration = pred_target\n",
    "\n",
    "    # Calculate the loss and mask out loss on kinematic particles/\n",
    "    loss = (pred_acceleration - target_acceleration)**2\n",
    "\n",
    "    num_non_kinematic = tf.reduce_sum(tf.cast(non_kinematic_mask, tf.float32))\n",
    "    loss = tf.where(tf.expand_dims(non_kinematic_mask,-1), loss, tf.zeros_like(loss))\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(num_non_kinematic)\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0eefc6e8-0bd8-4661-bcbf-beb0e97ab415",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lr = 1e-6\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4 - min_lr,\n",
    "                                decay_steps=int(5e6),\n",
    "                                decay_rate=0.1) #+ min_lr\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dd790b1a-a1e3-49c4-94b6-2df6ebd93da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function - ideally we'd like to decorate this with tf.function for faster code - but the connectivity utils is written using numpy so will need to be converted to tensorflow code\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(x,y)\n",
    "    grads = tape.gradient(loss_value, simulator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, simulator.trainable_variables))\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e9259-2ebf-40ca-9d84-0382c6da00c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 14:47:28.656539: W tensorflow/core/framework/dataset.cc:477] Input of WindowDataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 0: 5.8301\n",
      "Seen so far: 2 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 14:47:58.828774: W tensorflow/core/framework/dataset.cc:477] Input of WindowDataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(ds):\n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "102a128f-444d-4483-b673-0bbba281a5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./waterRampsSim/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(simulator, './waterRampsSim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f95d6ed0-28d2-4ae5-90a9-a5a2b936eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rollout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "08d6f3e9-26be-4950-9938-c3d17149d52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_rollout_inputs at 0x7f68c504c310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpuuxsm07u.py, line 13)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function prepare_rollout_inputs at 0x7f68c504c310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpuuxsm07u.py, line 13)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "data_path = '/tmp/datasets'\n",
    "\n",
    "# Loads the metadata of the dataset.\n",
    "metadata = _read_metadata(data_path)\n",
    "#Create a tf.data.Dataset from the TFRecord.\n",
    "\n",
    "ds = tf.data.TFRecordDataset([os.path.join(data_path, 'train.tfrecord')])\n",
    "ds = ds.map(functools.partial(reading_utils.parse_serialized_simulation_example, metadata=metadata))\n",
    "# Splits an entire trajectory into chunks of 7 steps.\n",
    "# Previous 5 velocities, current velocity and target.\n",
    "ds = ds.map(prepare_rollout_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e9363eb-cef0-45a4-8f06-a528f7bcc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = _read_metadata(data_path)\n",
    "num_steps = metadata['sequence_length'] - INPUT_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2109f0cc-5914-4b61-b220-6e0c167b1fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "71ecf2f7-3926-4df1-80af-ffde9b52bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(simulator, features, num_steps):\n",
    "  \"\"\"Rolls out a trajectory by applying the model in sequence.\"\"\"\n",
    "  initial_positions = features['position'][:, 0:INPUT_SEQUENCE_LENGTH]\n",
    "  ground_truth_positions = features['position'][:, INPUT_SEQUENCE_LENGTH:]\n",
    "  global_context = features.get('step_context')\n",
    "  def step_fn(step, current_positions, predictions):\n",
    "\n",
    "    if global_context is None:\n",
    "      global_context_step = None\n",
    "    else:\n",
    "      global_context_step = global_context[\n",
    "          step + INPUT_SEQUENCE_LENGTH - 1][tf.newaxis]\n",
    "\n",
    "    next_position = simulator(\n",
    "        current_positions,\n",
    "        n_particles_per_example=features['n_particles_per_example'],\n",
    "        particle_types=features['particle_type'],\n",
    "        global_context=global_context_step)\n",
    "\n",
    "    # Update kinematic particles from prescribed trajectory.\n",
    "    kinematic_mask = get_kinematic_mask(features['particle_type'])\n",
    "    next_position_ground_truth = ground_truth_positions[:, step]\n",
    "    next_position = tf.where(tf.expand_dims(kinematic_mask,-1), next_position_ground_truth,\n",
    "                             next_position)\n",
    "    updated_predictions = predictions.write(step, next_position)\n",
    "\n",
    "    # Shift `current_positions`, removing the oldest position in the sequence\n",
    "    # and appending the next position at the end.\n",
    "    next_positions = tf.concat([current_positions[:, 1:],\n",
    "                                next_position[:, tf.newaxis]], axis=1)\n",
    "\n",
    "    return (step + 1, next_positions, updated_predictions)\n",
    "\n",
    "  predictions = tf.TensorArray(size=num_steps, dtype=tf.float32)\n",
    "  _, _, predictions = tf.while_loop(\n",
    "      cond=lambda step, state, prediction: tf.less(step, num_steps),\n",
    "      body=step_fn,\n",
    "      loop_vars=(0, initial_positions, predictions),\n",
    "      back_prop=False,\n",
    "      parallel_iterations=1)\n",
    "\n",
    "  output_dict = {\n",
    "      'initial_positions': tf.transpose(initial_positions, [1, 0, 2]),\n",
    "      'predicted_rollout': predictions.stack(),\n",
    "      'ground_truth_rollout': tf.transpose(ground_truth_positions, [1, 0, 2]),\n",
    "      'particle_types': features['particle_type'],\n",
    "  }\n",
    "\n",
    "  if global_context is not None:\n",
    "    output_dict['global_context'] = global_context\n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2233c2a7-d9a1-48a8-89bd-f24175830a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "253b3383-e47b-4d40-8de2-cb08d57acba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for databatch in ds:\n",
    "    output = rollout(simulator,databatch[0],num_steps)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7ef7632d-2333-43ad-8b59-8930775c315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['metadata'] = metadata\n",
    "filename = 'rollouts/waterramp.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(output, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335cf840-06ca-4dc1-9f69-a41e06d1cad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
