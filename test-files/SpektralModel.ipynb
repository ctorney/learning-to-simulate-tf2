{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpektralModel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNRJ35rHY3fsLIF8H6n3NAD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctorney/learning-to-simulate-tf2/blob/main/test-files/SpektralModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SPTqZ5bToXO"
      },
      "source": [
        "!pip install spektral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfoYzr9AWlXB"
      },
      "source": [
        "#@title ### Imports { form-width: \"30%\" }\n",
        "\n",
        "import os, sys\n",
        "import numpy as np\n",
        "from math import *\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import pickle\n",
        "\n",
        "import functools\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Concatenate\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from spektral.layers import ECCConv, GlobalAvgPool, MessagePassing, XENetConv, GlobalAttentionPool, GlobalMaxPool, GlobalSumPool,GlobalAttnSumPool\n",
        "\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.style.use('seaborn-paper') \n",
        "plt.style.use('seaborn-whitegrid')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djgc1AVtrAdy"
      },
      "source": [
        "# Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_lpv__-npkr",
        "cellView": "form"
      },
      "source": [
        "#@title ### Zonal Model { form-width: \"30%\" }\n",
        "\n",
        "def get_record(group_id,pos,vel,acc):\n",
        "    feature = { 'group_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[group_id])),\n",
        "                'pos': tf.train.Feature(bytes_list=tf.train.BytesList(value=[pos.numpy()])),\n",
        "                'vel': tf.train.Feature(bytes_list=tf.train.BytesList(value=[vel.numpy()])),\n",
        "                'acc': tf.train.Feature(bytes_list=tf.train.BytesList(value=[acc.numpy()]))\n",
        "                }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "class zonal_model:\n",
        "    def __init__(self, N, timesteps, discard, repeat, L, dt, save_interval,train_directory='train_datasets', valid_directory='valid_datasets', disable_progress=False):\n",
        "        self.N = N\n",
        "        self.timesteps = timesteps\n",
        "        self.discard = discard\n",
        "        self.B = repeat  # repeat for B batches\n",
        "        self.L = L\n",
        "        self.dt = dt\n",
        "        self.save_interval = save_interval\n",
        "        \n",
        "        self.micro_state = np.zeros((self.B, (self.timesteps - self.discard)//self.save_interval, N, 4),dtype=np.float32)\n",
        "\n",
        "        self.sim_counter=0\n",
        "\n",
        "        if not os.path.exists(train_directory):\n",
        "            os.makedirs(train_directory)\n",
        "\n",
        "        if not os.path.exists(valid_directory):\n",
        "            os.makedirs(valid_directory)\n",
        "\n",
        "        self.train_directory = train_directory\n",
        "        self.valid_directory = valid_directory\n",
        "\n",
        "        # turn progress bar on or off\n",
        "        self.disable_progress = disable_progress\n",
        "\n",
        "        self.valid_fraction = 0.1\n",
        "        \n",
        "    def initialise_state(self):\n",
        "\n",
        "        #self.positions = tf.random.uniform((self.B,self.N,2),0.5*self.L, 0.5*self.L+20) #0,self.L)\n",
        "        self.positions = tf.random.uniform((self.B,self.N,2),0, self.L) \n",
        "        self.angles = tf.random.uniform((self.B,self.N,1), 0, 2*pi) #\n",
        "        \n",
        "\n",
        "\n",
        "    def run_sim(self, *params):\n",
        "\n",
        "        eta, Ra, Ro, Rr, vs, va, sigma = params\n",
        "        \n",
        "        record_file = self.train_directory + '/microstates-' + str(self.sim_counter) + '.tfrecords'\n",
        "        self.writer = tf.io.TFRecordWriter(record_file) \n",
        "        \n",
        "        valid_file = self.valid_directory + '/microstates-' + str(self.sim_counter) + '.tfrecords'\n",
        "        self.validwriter = tf.io.TFRecordWriter(valid_file) \n",
        "        \n",
        "        # tensorflow function to run an update step\n",
        "        @tf.function\n",
        "        def update_tf(X, A):\n",
        "            cos_A = tf.math.cos(A)\n",
        "            sin_A = tf.math.sin(A)\n",
        "\n",
        "\n",
        "            Xx = tf.expand_dims(X[...,0],-1)\n",
        "            dx = -Xx + tf.linalg.matrix_transpose(Xx)\n",
        "            dx = tf.where(dx>0.5*self.L, dx-self.L, dx)\n",
        "            dx = tf.where(dx<-0.5*self.L, dx+self.L, dx)\n",
        "\n",
        "            Xy = tf.expand_dims(X[...,1],-1)\n",
        "            dy = -Xy + tf.linalg.matrix_transpose(Xy)\n",
        "            dy = tf.where(dy>0.5*self.L, dy-self.L, dy)\n",
        "            dy = tf.where(dy<-0.5*self.L, dy+self.L, dy)\n",
        "\n",
        "\n",
        "            angle_to_neigh = tf.math.atan2(dy, dx)\n",
        "            cos_N = tf.math.cos(angle_to_neigh)\n",
        "            sin_N = tf.math.sin(angle_to_neigh)\n",
        "            rel_angle_to_neigh = angle_to_neigh - A\n",
        "            rel_angle_to_neigh = tf.math.atan2(tf.math.sin(rel_angle_to_neigh), tf.math.cos(rel_angle_to_neigh))\n",
        "            \n",
        "            dist = tf.math.sqrt(tf.square(dx)+tf.square(dy))\n",
        "    \n",
        "            # repulsion \n",
        "            rep_x = tf.where(dist<=Rr, -dx, tf.zeros_like(dx))\n",
        "            rep_x = tf.where(rel_angle_to_neigh<0.5*va, rep_x, tf.zeros_like(rep_x))\n",
        "            rep_x = tf.where(rel_angle_to_neigh>-0.5*va, rep_x, tf.zeros_like(rep_x))\n",
        "            rep_x = tf.math.divide_no_nan(rep_x,tf.math.square(dist))\n",
        "            rep_x = tf.reduce_sum(rep_x,axis=2)\n",
        "\n",
        "            rep_y = tf.where(dist<=Rr, -dy, tf.zeros_like(dy))\n",
        "            rep_y = tf.where(rel_angle_to_neigh<0.5*va, rep_y, tf.zeros_like(rep_y))\n",
        "            rep_y = tf.where(rel_angle_to_neigh>-0.5*va, rep_y, tf.zeros_like(rep_y))\n",
        "            rep_y = tf.math.divide_no_nan(rep_y,tf.math.square(dist))\n",
        "            rep_y = tf.reduce_sum(rep_y,axis=2)\n",
        "\n",
        "            # alignment \n",
        "            align_x = tf.where(dist<=Ro, cos_A, tf.zeros_like(cos_A))\n",
        "            align_x = tf.where(rel_angle_to_neigh<0.5*va, align_x, tf.zeros_like(align_x))\n",
        "            align_x = tf.where(rel_angle_to_neigh>-0.5*va, align_x, tf.zeros_like(align_x))\n",
        "            align_x = tf.reduce_sum(align_x,axis=1)\n",
        "            \n",
        "            align_y = tf.where(dist<=Ro, sin_A, tf.zeros_like(sin_A))\n",
        "            align_y = tf.where(rel_angle_to_neigh<0.5*va, align_y, tf.zeros_like(align_y))\n",
        "            align_y = tf.where(rel_angle_to_neigh>-0.5*va, align_y, tf.zeros_like(align_y))\n",
        "            align_y = tf.reduce_sum(align_y,axis=1)\n",
        "\n",
        "            al_norm = tf.math.sqrt(align_x**2+align_y**2)\n",
        "            align_x = tf.math.divide_no_nan(align_x,al_norm)\n",
        "            align_y = tf.math.divide_no_nan(align_y,al_norm)\n",
        "\n",
        "            # attractive interactions\n",
        "            attr_x = tf.where(dist<=Ra, dx, tf.zeros_like(dx))\n",
        "            attr_x = tf.where(rel_angle_to_neigh<0.5*va, attr_x, tf.zeros_like(attr_x))\n",
        "            attr_x = tf.where(rel_angle_to_neigh>-0.5*va, attr_x, tf.zeros_like(attr_x))\n",
        "            attr_x = tf.reduce_sum(attr_x,axis=2)\n",
        "\n",
        "            attr_y = tf.where(dist<=Ra, dy, tf.zeros_like(dy))\n",
        "            attr_y = tf.where(rel_angle_to_neigh<0.5*va, attr_y, tf.zeros_like(attr_y))\n",
        "            attr_y = tf.where(rel_angle_to_neigh>-0.5*va, attr_y, tf.zeros_like(attr_y))\n",
        "            attr_y = tf.reduce_sum(attr_y,axis=2)\n",
        "\n",
        "            at_norm = tf.math.sqrt(attr_x**2+attr_y**2)\n",
        "            attr_x = tf.math.divide_no_nan(attr_x,at_norm)\n",
        "            attr_y = tf.math.divide_no_nan(attr_y,at_norm)\n",
        "\n",
        "            # combine angles and convert to desired angle change\n",
        "            social_x = rep_x + align_x + attr_x\n",
        "            social_y = rep_y + align_y + attr_y\n",
        "\n",
        "            d_angle = tf.math.atan2(social_y,social_x)\n",
        "            d_angle = tf.expand_dims(d_angle,-1)\n",
        "\n",
        "            \n",
        "            d_angle = tf.math.atan2((1-eta)*tf.math.sin(d_angle) + eta*sin_A, (1-eta)*tf.math.cos(d_angle) + eta*cos_A)\n",
        "\n",
        "            d_angle = d_angle - A\n",
        "            d_angle = tf.where(d_angle>pi, d_angle-2*pi, d_angle)\n",
        "            d_angle = tf.where(d_angle<-pi, d_angle+2*pi, d_angle)\n",
        "\n",
        "\n",
        "            # add perception noise\n",
        "            noise = tf.random.normal(shape=(self.B,self.N,1),mean=0,stddev=sigma*(self.dt**0.5))\n",
        "            d_angle = d_angle + noise\n",
        "            \n",
        "            # restrict to maximum turning angle\n",
        "            #d_angle = tf.where(tf.math.abs(d_angle)>eta*self.dt, tf.math.sign(d_angle)*eta*self.dt, d_angle)\n",
        "            \n",
        "            # rotate headings\n",
        "            A = A + d_angle\n",
        "            \n",
        "            # update positions\n",
        "            velocity = self.dt*vs*tf.concat([tf.cos(A),tf.sin(A)],axis=-1)\n",
        "            X += velocity\n",
        "\n",
        "            # add periodic boundary conditions\n",
        "            A = tf.where(A<-pi,  A+2*pi, A)\n",
        "            A = tf.where(A>pi, A-2*pi, A)\n",
        "\n",
        "            X = tf.where(X>self.L, X-self.L, X)\n",
        "            X = tf.where(X<0, X+self.L, X)\n",
        "\n",
        "            X = tf.where(X>self.L, X-self.L, X)\n",
        "            X = tf.where(X<0, X+self.L, X)\n",
        "\n",
        "            return X, A\n",
        "            \n",
        "        self.initialise_state()\n",
        "\n",
        "        counter=0\n",
        "        for i in tqdm(range(self.timesteps),disable=self.disable_progress):\n",
        "            self.positions, self.angles = update_tf(self.positions,  self.angles)\n",
        "            if i>=self.discard:\n",
        "                if i%self.save_interval==0:\n",
        "                    # store in an array in case we want to visualise\n",
        "                    self.micro_state[:,counter,:,0:2] = self.positions.numpy()\n",
        "                    self.micro_state[:,counter,:,2:3] = np.cos(self.angles.numpy())\n",
        "                    self.micro_state[:,counter,:,3:4] = np.sin(self.angles.numpy())\n",
        "                    \n",
        "                        \n",
        "                    \n",
        "\n",
        "                    counter = counter + 1\n",
        "\n",
        "        for b in range(self.B):\n",
        "            self.save_tf_record(b)\n",
        "\n",
        "        self.writer.close()\n",
        "        self.validwriter.close()\n",
        "        self.sim_counter+=1\n",
        "        return \n",
        "\n",
        "    def save_tf_record(self, b):\n",
        "        pos =  tf.io.serialize_tensor(self.micro_state[b,:,:,0:2])\n",
        "        vel =  tf.io.serialize_tensor(self.micro_state[b,:,:,2:4])\n",
        "        acc =  tf.io.serialize_tensor(np.gradient(self.micro_state[b,:,:,2:4], axis=1))\n",
        "\n",
        "        tf_record = get_record(b,pos,vel,acc)\n",
        "        if b> self.B*self.valid_fraction:\n",
        "            self.writer.write(tf_record.SerializeToString())\n",
        "        else:\n",
        "            self.validwriter.write(tf_record.SerializeToString())\n",
        "\n",
        "        \n",
        "        return "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-iHCH3WaZuO",
        "cellView": "form"
      },
      "source": [
        "#@title ### Params { form-width: \"30%\" }\n",
        "\n",
        "n_points=50 #10\n",
        "\n",
        "param_values = np.linspace(0,25,n_points)\n",
        "L= 200\n",
        "N= 100 \n",
        "repeat = 100\n",
        "discard = 0\n",
        "timesteps = 200\n",
        "save_interval=1\n",
        "dt=1\n",
        "\n",
        "\n",
        "sim = zonal_model(N,timesteps=timesteps+discard,discard=discard,L=L,repeat=repeat, dt=dt,save_interval=save_interval,disable_progress=False)\n",
        "\n",
        "latt=0  # adapt\n",
        "lrep= 1 # adapt\n",
        "lali= 5 # adapt\n",
        "eta=0.5 # adapt\n",
        "va=2*pi # adapt\n",
        "vs=2 # fix \n",
        "sigma=0. "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "kiyL0DASnrzU",
        "cellView": "form",
        "outputId": "0db8c1ef-b61f-4d05-b4a3-29688c748ee6"
      },
      "source": [
        "#@title ### Create Training Data { form-width: \"30%\" }\n",
        "\n",
        "def evaluate_zonal_model(X):\n",
        "    sim.run_sim(eta, latt, X, lrep, vs, va, sigma)\n",
        "    return\n",
        "\n",
        "evaluate_zonal_model(0)\n",
        "\n",
        "\"\"\"\n",
        "for i in tqdm(range(param_values.shape[0])):\n",
        "    evaluate_zonal_model(param_values[i])\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:28<00:00,  7.03it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor i in tqdm(range(param_values.shape[0])):\\n    evaluate_zonal_model(param_values[i])\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMGNTWjMWcTv"
      },
      "source": [
        "# Parsing/Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDyPgl9V-C3n",
        "cellView": "form"
      },
      "source": [
        "#@title ### Parsing Functions { form-width: \"30%\" }\n",
        "\n",
        "\n",
        "def _parse_record(x):\n",
        "  # Parse the input tf.train.Example proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(x, feature_description)\n",
        "\n",
        "def _parse_tensor(x):\n",
        "    output = {'group_id': x['group_id'],\n",
        "                'pos': tf.io.parse_tensor(x['pos'],out_type=tf.float32),\n",
        "                'vel': tf.io.parse_tensor(x['vel'],out_type=tf.float32),\n",
        "                'acc': tf.io.parse_tensor(x['acc'],out_type=tf.float32)}\n",
        "    return output\n",
        "\n",
        "def make_window_dataset(x):\n",
        "    # make a dataset from the time series tensor\n",
        "    windows = tf.data.Dataset.from_tensor_slices((x['pos'],x['vel'],x['acc']))\n",
        "    # convert to windows\n",
        "    windows = windows.window(WINDOW_SIZE, shift=1, stride=1)\n",
        "    # take a batch of window size and combine pos, vel, acc to a single dataset\n",
        "    windows = windows.flat_map(lambda pos_ds,vel_ds,acc_ds: tf.data.Dataset.zip((pos_ds.batch(WINDOW_SIZE, drop_remainder=True),vel_ds.batch(WINDOW_SIZE, drop_remainder=True),acc_ds.batch(WINDOW_SIZE, drop_remainder=True))))\n",
        "    return windows\n",
        "\n",
        "\n",
        "def split_targets(x, y, z, w=7):\n",
        "    inputs = (x[0:w-1], y[0:w-1], z[0:w-1])\n",
        "    targets = z[-1]\n",
        "    return (inputs, targets)\n",
        "\n",
        "\n",
        "def _parse_graph(inputs, targets):\n",
        "    #inputs, targets = x\n",
        "    X, V, A = inputs\n",
        "    X_current = X[-1]\n",
        "    V_current = V[-1]\n",
        "\n",
        "    Xx = tf.expand_dims(X_current[...,0],-1)\n",
        "    dx = -Xx + tf.linalg.matrix_transpose(Xx)\n",
        "    dx = tf.where(dx>0.5*DOMAIN_SIZE, dx-DOMAIN_SIZE, dx)\n",
        "    dx = tf.where(dx<-0.5*DOMAIN_SIZE, dx+DOMAIN_SIZE, dx)\n",
        "\n",
        "    Xy = tf.expand_dims(X_current[...,1],-1)\n",
        "    dy = -Xy + tf.linalg.matrix_transpose(Xy)\n",
        "    dy = tf.where(dy>0.5*DOMAIN_SIZE, dy-DOMAIN_SIZE, dy)\n",
        "    dy = tf.where(dy<-0.5*DOMAIN_SIZE, dy+DOMAIN_SIZE, dy)\n",
        "\n",
        "    Vx = tf.expand_dims(V_current[...,0],-1)\n",
        "    dvx = -Vx + tf.linalg.matrix_transpose(Vx)\n",
        "\n",
        "    Vy = tf.expand_dims(V_current[...,1],-1)\n",
        "    dvy = -Vy + tf.linalg.matrix_transpose(Vy)\n",
        "    \n",
        "    dvnorm = tf.math.sqrt(dvx**2+dvy**2)\n",
        "    dvx = tf.math.divide_no_nan(dvx,dvnorm)\n",
        "    dvy = tf.math.divide_no_nan(dvy,dvnorm)\n",
        "\n",
        "    angles = tf.expand_dims(tf.math.atan2(V_current[...,1],V_current[...,0]),-1)\n",
        "    angle_to_neigh = tf.math.atan2(dy, dx)\n",
        "\n",
        "    rel_angle_to_neigh = angle_to_neigh - angles\n",
        "\n",
        "    dist = tf.math.sqrt(tf.square(dx)+tf.square(dy))\n",
        "\n",
        "    interaction_radius = 25.0# tf.reduce_mean(dist,axis=[1,2],keepdims=True)\n",
        "    adj_matrix = tf.where(dist<interaction_radius, tf.ones_like(dist,dtype=tf.int32), tf.zeros_like(dist,dtype=tf.int32))\n",
        "    adj_matrix = tf.linalg.set_diag(adj_matrix, tf.zeros(tf.shape(adj_matrix)[:2],dtype=tf.int32))\n",
        "    sender_recv_list = tf.where(adj_matrix)\n",
        "    n_edge = tf.reduce_sum(adj_matrix, axis=[1,2])\n",
        "    n_node = tf.ones_like(n_edge)*tf.shape(adj_matrix)[-1]\n",
        "\n",
        "    output_i = tf.repeat(tf.range(tf.shape(adj_matrix)[0]),n_node)\n",
        "    output_ie = tf.repeat(tf.range(tf.shape(adj_matrix)[0]),n_edge)\n",
        "\n",
        "\n",
        "    senders = tf.squeeze(tf.slice(sender_recv_list,(0,1),size=(-1,1)))+ tf.squeeze(tf.slice(sender_recv_list,(0,0),size=(-1,1)))*tf.shape(adj_matrix,out_type=tf.int64)[-1]\n",
        "    receivers = tf.squeeze(tf.slice(sender_recv_list,(0,2),size=(-1,1))) + tf.squeeze(tf.slice(sender_recv_list,(0,0),size=(-1,1)))*tf.shape(adj_matrix,out_type=tf.int64)[-1]\n",
        "\n",
        "    output_a = tf.sparse.SparseTensor(indices=tf.stack([senders,receivers],axis=1), values = tf.ones_like(senders),dense_shape=[tf.shape(output_i)[0],tf.shape(output_i)[0]])\n",
        "    edge_distance = tf.expand_dims(tf.gather_nd(dist/interaction_radius, sender_recv_list),-1)\n",
        "    edge_x_distance =  tf.expand_dims(tf.gather_nd(tf.math.cos(rel_angle_to_neigh),sender_recv_list),-1)  # neigbour position relative to sender heading\n",
        "    edge_y_distance =  tf.expand_dims(tf.gather_nd(tf.math.sin(rel_angle_to_neigh),sender_recv_list),-1)  # neigbour position relative to sender heading\n",
        "\n",
        "    edge_x_orientation =  tf.expand_dims(tf.gather_nd(dvx,sender_recv_list),-1)  # neigbour velocity relative to sender heading\n",
        "    edge_y_orientation =  tf.expand_dims(tf.gather_nd(dvy,sender_recv_list),-1)  # neigbour velocity relative to sender heading\n",
        "\n",
        "\n",
        "    output_e = tf.concat([edge_distance,edge_x_distance,edge_y_distance,edge_x_orientation,edge_y_orientation],axis=-1)\n",
        "    node_velocities = tf.transpose(V, perm=[1,0,2])\n",
        "    node_accelerations = tf.transpose(A, perm=[1,0,2])\n",
        "\n",
        "    # shape = node_velocities.get_shape().as_list()\n",
        "    # dim = tf.math.reduce_prod(shape[1:])\n",
        "    node_velocities = tf.reshape(node_velocities,(-1,2*(WINDOW_SIZE-1)))\n",
        "    node_accelerations = tf.reshape(node_accelerations,(-1,2*(WINDOW_SIZE-1)))\n",
        "\n",
        "    output_x = tf.concat([X_current, node_velocities,node_accelerations],axis=-1)\n",
        "    #dist = tf.linalg.set_diag(dist, 25.0*tf.ones(tf.shape(dist)[:2],dtype=tf.float32))\n",
        "\n",
        "    #dist_out =  tf.reduce_mean(tf.reduce_min(dist,axis=[2]),axis=[1])\n",
        "    X_T, V_T, A_T = targets\n",
        "    #node_targets = tf.concat([X_T, V_T, A_T], axis=-1)\n",
        "    target = A_T\n",
        "\n",
        "    return (output_x, output_a, output_e, output_i,output_ie), target#, tf.ones_like(targets)/max_params"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgifs2W-T6R7",
        "cellView": "form"
      },
      "source": [
        "#@title ### Preprocessing { form-width: \"30%\" }\n",
        "\n",
        "train_dir = 'train_datasets/'\n",
        "valid_dir = 'valid_datasets/'\n",
        "\n",
        "WINDOW_SIZE=7\n",
        "\n",
        "n_out = 2\n",
        "n_feat_node = (WINDOW_SIZE-1)*4+2\n",
        "n_feat_edge = 5\n",
        "\n",
        "BATCH_SIZE=32\n",
        "EPOCHS=2\n",
        "\n",
        "\n",
        "all_file_list = [train_dir + filename for filename in os.listdir(train_dir)]\n",
        "\n",
        "dataset_size = sum(1 for _ in tf.data.TFRecordDataset(all_file_list[0]))*len(all_file_list)//BATCH_SIZE\n",
        "\n",
        "\n",
        "feature_description = {'group_id': tf.io.FixedLenFeature([], tf.int64),\n",
        "                        'pos': tf.io.FixedLenFeature([], tf.string),\n",
        "                        'vel': tf.io.FixedLenFeature([], tf.string),\n",
        "                        'acc': tf.io.FixedLenFeature([], tf.string)}\n",
        "\n",
        "\n",
        "split_with_window = functools.partial(\n",
        "  split_targets,\n",
        "  w=WINDOW_SIZE)\n",
        "\n",
        "DOMAIN_SIZE=200\n",
        "\n",
        "train_dataset =  tf.data.TFRecordDataset(tf.data.Dataset.list_files([train_dir + filename for filename in os.listdir(train_dir)]))\n",
        "\n",
        "parsed_train_dataset = train_dataset.map(_parse_record)\n",
        "parsed_train_dataset = parsed_train_dataset.map(_parse_tensor)\n",
        "parsed_train_dataset = parsed_train_dataset.flat_map(make_window_dataset)\n",
        "parsed_train_dataset = parsed_train_dataset.map(split_with_window)\n",
        "parsed_train_dataset = parsed_train_dataset.shuffle(10000, reshuffle_each_iteration=True)\n",
        "parsed_train_dataset = parsed_train_dataset.repeat(EPOCHS)\n",
        "parsed_train_dataset = parsed_train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "#parsed_train_dataset = parsed_train_dataset.map(_parse_graph)\n",
        "\n",
        "\n",
        "valid_dataset =  tf.data.TFRecordDataset(tf.data.Dataset.list_files([valid_dir + filename for filename in os.listdir(valid_dir)]))\n",
        "\n",
        "parsed_valid_dataset = valid_dataset.map(_parse_record)\n",
        "parsed_valid_dataset = parsed_valid_dataset.map(_parse_tensor)\n",
        "parsed_valid_dataset = parsed_valid_dataset.flat_map(make_window_dataset)\n",
        "parsed_valid_dataset = parsed_valid_dataset.map(split_with_window)\n",
        "parsed_valid_dataset = parsed_valid_dataset.shuffle(10000, reshuffle_each_iteration=True)\n",
        "parsed_valid_dataset = parsed_valid_dataset.repeat(EPOCHS)\n",
        "parsed_valid_dataset = parsed_valid_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "#parsed_valid_dataset = parsed_valid_dataset.map(_parse_graph)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W6tPjaGAa1D"
      },
      "source": [
        "# Ignore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0urz9D8Dzq-"
      },
      "source": [
        "  # Learning rate\n",
        "\n",
        "\n",
        "X_in = Input(shape=(n_feat_node,))\n",
        "A_in = Input(shape=(None,), sparse=True)\n",
        "E_in = Input(shape=(n_feat_edge,))\n",
        "I_in = Input(shape=(), dtype=tf.int64)\n",
        "\n",
        "X_1 = ECCConv(32, activation=\"relu\")([X_in, A_in, E_in])\n",
        "X_2 = ECCConv(32, activation=\"relu\")([X_1, A_in, E_in])\n",
        "X_3 = GlobalAvgPool()([X_2, I_in])\n",
        "output = Dense(n_out, activation=\"sigmoid\")(X_3)\n",
        "\n",
        "gnn_model = Model(inputs=[X_in, A_in, E_in, I_in], outputs=output)\n",
        "\n",
        "all_output = gnn_model(pre_model.outputs)\n",
        "\n",
        "model = Model(pre_model.inputs,all_output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A5WqDiqUKg6",
        "cellView": "form"
      },
      "source": [
        "#@title ### Model { form-width: \"30%\" }\n",
        "\n",
        "\n",
        "\n",
        "MLP_SIZE=16\n",
        "\n",
        "X_in = Input(shape=(n_feat_node,))\n",
        "A_in = Input(shape=(None,), sparse=True)\n",
        "E_in = Input(shape=(n_feat_edge,))\n",
        "I_in = Input(shape=(), dtype=tf.int64)\n",
        "IE_in = Input(shape=(), dtype=tf.int64)\n",
        "\n",
        "\n",
        "\n",
        "X = Dense(MLP_SIZE, activation=\"linear\")(X_in)\n",
        "E = Dense(MLP_SIZE, activation=\"linear\")(E_in)\n",
        "\n",
        "# X = Concatenate()([X, X_in])\n",
        "# E = Concatenate()([E, E_in])\n",
        "\n",
        "\n",
        "mp_steps = 3\n",
        "\n",
        "#XEMP_layer = XENetConv(32, 16, 16, node_activation=\"relu\", edge_activation=\"relu\")\n",
        "#for _ in range(mp_steps):\n",
        "\n",
        "#    X, E = XEMP_layer([X, A_in, E])\n",
        "# X, E = XENetConv([8,8], 8, 8)([X, A_in, E])\n",
        "# X, E = XENetConv(8, 8, 8)([X, A_in, E])\n",
        "# X, E = XENetConv(8, 8, 8)([X, A_in, E])\n",
        "\n",
        "## below works well\n",
        "# X, E = XENetConv([16,16], 32, 16, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "# X, E = XENetConv([16,16], 32, 16, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "\n",
        "\n",
        "X, E = XENetConv([MLP_SIZE,MLP_SIZE], MLP_SIZE, 2*MLP_SIZE, node_activation=\"relu\", edge_activation=\"relu\")([X, A_in, E])\n",
        "X, E = XENetConv([MLP_SIZE,MLP_SIZE], MLP_SIZE, 2*MLP_SIZE, node_activation=\"relu\", edge_activation=\"relu\")([X, A_in, E])\n",
        "#X, E = XENetConv([16,16], 32, 16, node_activation=\"relu\", edge_activation=\"relu\")([X, A_in, E])\n",
        "\n",
        "\n",
        "#X, E = XENetConv(2, 4, 5, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "#X, E = XENetConv(2, 4, 5, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "\n",
        "\n",
        "#X, E = XENetConv(5, 10, 10, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "#X, E = XENetConv(5, 10, 10, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "#X, E = XENetConv(5, 10, 10, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "\n",
        "\n",
        "#X, E = XENetConv(4, 8, 8, False, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "#X, E = XENetConv(4, 8, 8, False, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "#X, E = XENetConv(4, 8, 8, False, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "#X, E = XENetConv(4, 8, 8, False, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "#X, E = XENetConv(4, 8, 8, False, node_activation=\"tanh\", edge_activation=\"tanh\")([X, A_in, E])\n",
        "\n",
        "X = Dense(MLP_SIZE, activation=\"linear\",use_bias=False)(X)\n",
        "E = Dense(MLP_SIZE, activation=\"linear\",use_bias=False)(E)\n",
        "\n",
        "\n",
        "#X_2 = ECCConv(32, activation=\"relu\")([X_1, A_in, E_1])\n",
        "#X_3 = ECCConv(32, activation=\"relu\")([X_2, A_in, E_1])\n",
        "\n",
        "X = Concatenate()([X, X_in])\n",
        "E = Concatenate()([E, E_in])\n",
        "#X = Dense(16, activation=\"linear\",use_bias=False)(X)\n",
        "\n",
        "Xs = GlobalAttnSumPool()([X, I_in])\n",
        "Xm = GlobalMaxPool()([X, I_in])\n",
        "Xp = GlobalAttentionPool(MLP_SIZE)([X, I_in])\n",
        "Xa = GlobalAvgPool()([X, I_in])\n",
        "\n",
        "Es = GlobalAttnSumPool()([E, IE_in])\n",
        "Em = GlobalMaxPool()([E, IE_in])\n",
        "Ep = GlobalAttentionPool(MLP_SIZE)([E, IE_in])\n",
        "Ea = GlobalAvgPool()([E, IE_in])\n",
        "\n",
        "#X = Concatenate()([Xs, Xm, Xp, Xa, Es, Em, Ep, Ea])\n",
        "X = Concatenate()([Xs,Xm,Xa, Es,Em,Ea])\n",
        "\n",
        "\n",
        "# E = GlobalAttentionPool(16)([E,IE_in])\n",
        "\n",
        "# X = Concatenate()([X, X_in])\n",
        "# X = GlobalAttentionPool(16)([X,I_in])\n",
        "\n",
        "# X = Concatenate()([X, E])\n",
        "X = Dense(MLP_SIZE, activation=\"linear\",use_bias=False)(X)\n",
        "\n",
        "output = Dense(n_out, activation=\"relu\",use_bias=False)(X)\n",
        "\n",
        "gnn_model = Model(inputs=[X_in, A_in, E_in, I_in, IE_in], outputs=output)\n",
        "\n",
        "gnn_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1h7f15NUWXe",
        "cellView": "form"
      },
      "source": [
        "#@title ### Compile Model { form-width: \"30%\" }\n",
        "\n",
        "learning_rate = 1e-3# Learning rate\n",
        "gnn_model.compile(optimizer=Adam(learning_rate), loss=\"mse\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2P_xvzgUg47",
        "cellView": "form"
      },
      "source": [
        "#@title ### Train { form-width: \"30%\" }\n",
        "\n",
        "for run in range(20):\n",
        "    print(run)\n",
        "    gnn_model.fit(parsed_train_dataset, steps_per_epoch=dataset_size, epochs=EPOCHS,validation_data=parsed_valid_dataset)\n",
        "    valid_loss = 0\n",
        "    \n",
        "    \n",
        "    c = 0\n",
        "    pred_list = []\n",
        "    true_values = []\n",
        "    for databatch in tqdm(parsed_valid_dataset):\n",
        "\n",
        "        target = databatch[1]\n",
        "        true_values.append(target.numpy())\n",
        "\n",
        "\n",
        "        predictions = gnn_model(databatch[0])\n",
        "        pred_list.append(np.squeeze(predictions.numpy()))\n",
        "\n",
        "        loss_value = tf.keras.losses.MeanSquaredError()(target,predictions).numpy()\n",
        "        valid_loss+= loss_value\n",
        "        c+=1\n",
        "\n",
        "\n",
        "\n",
        "    print('validation loss', valid_loss/c)\n",
        "\n",
        "    fig, axs = plt.subplots(2,2, figsize=(8, 6), facecolor='w', edgecolor='k')  \n",
        "\n",
        "    axs = axs.ravel()\n",
        "    for pred_i in range(4):\n",
        "\n",
        "        pred_vals = np.array([pp[:,pred_i] for pp in pred_list]).flatten()\n",
        "        true_vals = np.array([tt[:,pred_i] for tt in true_values]).flatten()\n",
        "\n",
        "        bin_means, bin_edges, binnumber = stats.binned_statistic(true_vals, pred_vals,bins=100)\n",
        "        bin_width = (bin_edges[1] - bin_edges[0])\n",
        "        bin_centers = bin_edges[1:] - bin_width/2\n",
        "\n",
        "        bin_stds, bin_edges, binnumber = stats.binned_statistic(true_vals, pred_vals,statistic='std',bins=100)\n",
        "\n",
        "\n",
        "        axs[pred_i].plot(bin_centers,bin_means,c='C0')\n",
        "\n",
        "        axs[pred_i].fill_between(bin_centers,bin_means-bin_stds,bin_means+bin_stds,color='C0',alpha=0.5)\n",
        "\n",
        "        xx = np.linspace(0,true_vals.max(),10)\n",
        "        axs[pred_i].plot(xx,xx,c='k',ls='--')\n",
        "\n",
        "        axs[pred_i].set_ylabel('GNN prediction of parameter')\n",
        "        axs[pred_i].set_xlabel('True parameter that generated the microstate')\n",
        "\n",
        "\n",
        "\n",
        "    plt.savefig('gnn_' + str(run) + '.png',dpi=300)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlzzQSMkAeqx"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOId7yMy2XWp",
        "cellView": "form"
      },
      "source": [
        "#@title ### Preprocessing Layer { form-width: \"30%\" }\n",
        "#@markdown Issues with @tf.function here - input signature wrong (also possibly related to issue in train step)\n",
        "\n",
        "class PreprocessingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, L):\n",
        "        super(PreprocessingLayer, self).__init__()\n",
        "        self._L = L\n",
        "        \n",
        "\n",
        "    #@tf.function(input_signature=([tf.TensorSpec(shape=(None,WINDOW_SIZE-1,N,2), dtype=tf.float32),tf.TensorSpec(shape=(None,WINDOW_SIZE-1,N,2), dtype=tf.float32),tf.TensorSpec(shape=(None,WINDOW_SIZE-1,N,2), dtype=tf.float32)]))\n",
        "    def call(self, inputs):\n",
        "        \n",
        "        X, V, A = inputs\n",
        "        # node features xpos, ypos, xvel, yvel\n",
        "        # edge features distance, rel angle to receiver\n",
        "        X_current = X[:,-1]\n",
        "        V_current = V[:,-1]\n",
        "\n",
        "        Xx = tf.expand_dims(X_current[...,0],-1)\n",
        "        dx = -Xx + tf.linalg.matrix_transpose(Xx)\n",
        "        dx = tf.where(dx>0.5*self._L, dx-self._L, dx)\n",
        "        dx = tf.where(dx<-0.5*self._L, dx+self._L, dx)\n",
        "\n",
        "        Xy = tf.expand_dims(X_current[...,1],-1)\n",
        "        dy = -Xy + tf.linalg.matrix_transpose(Xy)\n",
        "        dy = tf.where(dy>0.5*self._L, dy-self._L, dy)\n",
        "        dy = tf.where(dy<-0.5*self._L, dy+self._L, dy)\n",
        "\n",
        "        Vx = tf.expand_dims(V_current[...,0],-1)\n",
        "        dvx = -Vx + tf.linalg.matrix_transpose(Vx)\n",
        "\n",
        "        Vy = tf.expand_dims(V_current[...,1],-1)\n",
        "        dvy = -Vy + tf.linalg.matrix_transpose(Vy)\n",
        "        \n",
        "        dvnorm = tf.math.sqrt(dvx**2+dvy**2)\n",
        "        dvx = tf.math.divide_no_nan(dvx,dvnorm)\n",
        "        dvy = tf.math.divide_no_nan(dvy,dvnorm)\n",
        "\n",
        "        angles = tf.expand_dims(tf.math.atan2(V_current[...,1],V_current[...,0]),-1)\n",
        "        angle_to_neigh = tf.math.atan2(dy, dx)\n",
        "\n",
        "        rel_angle_to_neigh = angle_to_neigh - angles\n",
        "\n",
        "        dist = tf.math.sqrt(tf.square(dx)+tf.square(dy))\n",
        "\n",
        "        interaction_radius = 25.0# tf.reduce_mean(dist,axis=[1,2],keepdims=True)\n",
        "        adj_matrix = tf.where(dist<interaction_radius, tf.ones_like(dist,dtype=tf.int32), tf.zeros_like(dist,dtype=tf.int32))\n",
        "        adj_matrix = tf.linalg.set_diag(adj_matrix, tf.zeros(tf.shape(adj_matrix)[:2],dtype=tf.int32))\n",
        "        sender_recv_list = tf.where(adj_matrix)\n",
        "        n_edge = tf.reduce_sum(adj_matrix, axis=[1,2])\n",
        "        n_node = tf.ones_like(n_edge)*tf.shape(adj_matrix)[-1]\n",
        "        output_i = tf.repeat(tf.range(tf.shape(adj_matrix)[0]),n_node)\n",
        "\n",
        "        senders = tf.squeeze(tf.slice(sender_recv_list,(0,1),size=(-1,1)))+ tf.squeeze(tf.slice(sender_recv_list,(0,0),size=(-1,1)))*tf.shape(adj_matrix,out_type=tf.int64)[-1]\n",
        "        receivers = tf.squeeze(tf.slice(sender_recv_list,(0,2),size=(-1,1))) + tf.squeeze(tf.slice(sender_recv_list,(0,0),size=(-1,1)))*tf.shape(adj_matrix,out_type=tf.int64)[-1]\n",
        "\n",
        "        output_a = tf.sparse.SparseTensor(indices=tf.stack([senders,receivers],axis=1), values = tf.ones_like(senders),dense_shape=[tf.shape(output_i)[0],tf.shape(output_i)[0]])\n",
        "        edge_distance = tf.expand_dims(tf.gather_nd(dist/self._L,sender_recv_list),-1)\n",
        "        #print(\"ed\", edge_distance.shape)\n",
        "        edge_x_distance = tf.expand_dims(tf.gather_nd(tf.math.cos(rel_angle_to_neigh),sender_recv_list),-1)  # neigbour position relative to sender heading\n",
        "        edge_y_distance = tf.expand_dims(tf.gather_nd(tf.math.sin(rel_angle_to_neigh),sender_recv_list),-1)  # neigbour position relative to sender heading\n",
        "        edge_x_orientation = tf.expand_dims(tf.gather_nd(dvx,sender_recv_list),-1)  # neigbour velocity relative to sender heading\n",
        "        edge_y_orientation = tf.expand_dims(tf.gather_nd(dvy,sender_recv_list),-1)  # neigbour velocity relative to sender heading\n",
        "\n",
        "\n",
        "        output_e = tf.concat([edge_distance,edge_x_distance,edge_y_distance,edge_x_orientation,edge_y_orientation],axis=-1)\n",
        "        #edges = tf.concat([edge_distance,edge_x_distance,edge_y_distance],axis=-1)\n",
        "        node_velocities = tf.transpose(V, perm=[0,2,1,3])\n",
        "        node_accelerations = tf.transpose(A, perm=[0,2,1,3])\n",
        "\n",
        "        # shape = node_velocities.get_shape().as_list()\n",
        "        # dim = tf.math.reduce_prod(shape[1:])\n",
        "        node_velocities = tf.reshape(node_velocities,(-1,2*(WINDOW_SIZE-1)))\n",
        "        node_accelerations = tf.reshape(node_accelerations,(-1,2*(WINDOW_SIZE-1)))\n",
        "        node_positions = (X_current - (self._L/2.))/self._L\n",
        "        node_positions = tf.reshape(node_positions,(-1,2))\n",
        "        output_x = tf.concat([node_positions, node_velocities, node_accelerations],axis=-1)\n",
        "        #dist = tf.linalg.set_diag(dist, 25.0*tf.ones(tf.shape(dist)[:2],dtype=tf.float32))\n",
        "\n",
        "        #dist_out =  tf.reduce_mean(tf.reduce_min(dist,axis=[2]),axis=[1])\n",
        "        #X_T, V_T, A_T = targets\n",
        "        #node_targets = tf.concat([X_T, V_T, A_T], axis=-1)\n",
        "        #target = A_T\n",
        "        #output_x.set_shape((None,n_feat_node))\n",
        "        #output_a.set_shape((None,N))\n",
        "        #output_e.set_shape((None,5))\n",
        "        #input_graphs = utils_tf.set_zero_global_features(input_graphs,self._output_size)\n",
        "        return output_x, output_a, output_e, output_i"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-vHZ2pB-loI",
        "cellView": "form"
      },
      "source": [
        "#@title ### Pre-Model { form-width: \"30%\" }\n",
        "\n",
        "pos = Input(shape=(WINDOW_SIZE-1,N,2))\n",
        "vel = Input(shape=(WINDOW_SIZE-1,N,2))\n",
        "acc = Input(shape=(WINDOW_SIZE-1,N,2))\n",
        "\n",
        "output = PreprocessingLayer(200)([pos,vel,acc])\n",
        "\n",
        "pre_model = Model(inputs=[pos,vel,acc], outputs=output)\n",
        "\n",
        "for data_batch in parsed_train_dataset.take(1):\n",
        "    pre_model(data_batch[0])\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4pqnbtbGG7u"
      },
      "source": [
        "#@title ### Build model { form-width: \"30%\" }\n",
        "\n",
        "learning_rate = 1e-5\n",
        "epochs = 10  # Number of training epochs\n",
        "batch_size = 32  # Batch size\n",
        "\n",
        "class GNNNet(Model):\n",
        "    def __init__(self,n_out=4,mp_steps=5):\n",
        "        super().__init__()\n",
        "        self.preprocess = PreprocessingLayer(200)\n",
        "        self.encoder = ECCConv(32, activation=\"relu\")\n",
        "        self.process = MessagePassing(aggregate='mean')# 32, activation=\"relu\")\n",
        "        self.decoder = ECCConv(n_out, activation=\"relu\")\n",
        "        #self.global_pool = GlobalAvgPool()\n",
        "        #self.dense = Dense(32, activation=\"relu\")\n",
        "        #self.final = Dense(n_out, activation=\"sigmoid\")\n",
        "        self.mp_steps=mp_steps\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        x, a, e, i = self.preprocess(inputs)\n",
        "        #x.set_shape([None,None])\n",
        "        #print(x.shape, a.shape, e.shape, i.shape)\n",
        "        x = self.encoder([x, a, e])\n",
        "        for _ in range(self.mp_steps):\n",
        "            x = self.process([x, a, e])         \n",
        "        x = self.decoder([x, a, e])\n",
        "\n",
        "        #x = self.global_pool([x, i])\n",
        "        #x = self.dense(x)\n",
        "        #x = self.final(x)\n",
        "\n",
        "        x = tf.reshape(x, (-1, N, 2))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "model = GNNNet(n_out=n_out)\n",
        "optimizer = Adam(learning_rate)\n",
        "loss_fn = MeanSquaredError()\n",
        "\n",
        "#model.build(input_shape=((None,WINDOW_SIZE-1,N,2)))\n",
        "#model.summary()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPbjfwN1H9vy",
        "cellView": "form"
      },
      "source": [
        "#@title ### Fit model { form-width: \"30%\" }\n",
        "#@markdown Issues with @tf.function here - 1st dimension of sender_recv_list in preprocessing layer does not compute a dimension and causes error in encoder step. Hacky fix - do not use @tf.function\n",
        "\n",
        "#@tf.function()#input_signature=[[tf.TensorSpec(shape=(None,None,2), dtype=tf.float32),tf.TensorSpec(shape=(None,None,2), dtype=tf.float32),tf.TensorSpec(shape=(None,None,2), dtype=tf.float32)],tf.TensorSpec(shape=(None,4), dtype=tf.float32)], experimental_relax_shapes=True)\n",
        "def train_step(inputs, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(target, predictions) #+ sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFV3nFtKICJc",
        "outputId": "2bc9fa81-ecab-4f5d-add5-f41a5d4984dc"
      },
      "source": [
        "step = losses = 0\n",
        "total=len(list(parsed_train_dataset))\n",
        "divisor=20\n",
        "loss_values = np.zeros(total)\n",
        "for step, batch in tqdm(enumerate(parsed_train_dataset), total=total):\n",
        "    inputs, target = batch\n",
        "    #inputs = layer(inputs)\n",
        "    losses = train_step(inputs,target)\n",
        "    loss_values[step]=losses.numpy()\n",
        "    if step%divisor==0:\n",
        "        print(tf.reduce_mean(loss_values[step-divisor:step]).numpy())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1079 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/spektral/layers/convolutional/conv.py:94: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  f\"The adjacency matrix of dtype {a.dtype} is incompatible with the dtype \"\n",
            "  0%|          | 1/1079 [00:02<42:28,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 21/1079 [00:07<04:41,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30721020698547363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 41/1079 [00:13<04:45,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3086159393191338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 61/1079 [00:18<04:29,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30416660755872726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 81/1079 [00:24<04:30,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30318104177713395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 101/1079 [00:29<04:15,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30007900297641754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 121/1079 [00:34<04:19,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.29943530857563017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 141/1079 [00:40<04:10,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2987641155719757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 161/1079 [00:45<04:01,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2942768454551697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 181/1079 [00:50<03:58,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2914547935128212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▊        | 201/1079 [00:55<03:53,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2914232283830643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 221/1079 [01:01<03:45,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28934250921010973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 241/1079 [01:06<03:44,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.289860762655735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 261/1079 [01:11<03:43,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2874287888407707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 281/1079 [01:17<03:35,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28641157895326613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 301/1079 [01:22<03:33,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2847049251198769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 321/1079 [01:28<03:24,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28545213043689727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 341/1079 [01:33<03:20,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2842435523867607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 361/1079 [01:38<03:14,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28113970160484314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 381/1079 [01:44<03:07,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2821690633893013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 401/1079 [01:49<03:01,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28041328936815263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 421/1079 [01:54<02:54,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28108986020088195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 441/1079 [02:00<02:47,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2795191049575806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 461/1079 [02:05<02:48,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28044062554836274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 481/1079 [02:11<02:36,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27592080384492873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▋     | 501/1079 [02:16<02:33,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27647294402122496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 521/1079 [02:21<02:28,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2775289207696915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 541/1079 [02:27<02:25,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2758832201361656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 561/1079 [02:32<02:19,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27727662324905394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 581/1079 [02:37<02:14,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2747888043522835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 601/1079 [02:43<02:10,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2759414047002792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 621/1079 [02:48<02:02,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27486543655395507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 641/1079 [02:54<01:59,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2747505694627762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████▏   | 661/1079 [02:59<01:51,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27469817250967027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 681/1079 [03:04<01:49,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2757466271519661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 701/1079 [03:10<01:43,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2725460737943649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 721/1079 [03:15<01:40,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2712635830044746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 741/1079 [03:21<01:30,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2716733396053314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 761/1079 [03:26<01:27,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27181217074394226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 781/1079 [03:31<01:18,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.271646623313427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 801/1079 [03:37<01:13,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27174055874347686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 821/1079 [03:42<01:10,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27112991362810135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 841/1079 [03:47<01:00,  3.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2705730706453323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 861/1079 [03:52<00:56,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27065361440181734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 881/1079 [03:58<00:52,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27069797962903974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 901/1079 [04:03<00:45,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2709941819310188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 921/1079 [04:08<00:41,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2686782583594322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 941/1079 [04:13<00:35,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2686575025320053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 961/1079 [04:18<00:30,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.26766877472400663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 981/1079 [04:24<00:25,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.26817848086357116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 1001/1079 [04:29<00:19,  3.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2670255541801453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 1021/1079 [04:34<00:14,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27006683498620987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▋| 1041/1079 [04:39<00:09,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.267473965883255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 1061/1079 [04:44<00:04,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.26848774701356887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1079/1079 [04:49<00:00,  3.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "n7l4QZmaAa0U",
        "outputId": "fe78c799-38e4-4b55-dc51-cdb6bf016234"
      },
      "source": [
        "compression = 10\n",
        "\n",
        "loss = np.ndarray.flatten(loss_values)\n",
        "loss = np.nanmean(np.pad(loss.astype(float), (0, compression - loss.size%compression), mode='constant', constant_values=np.NaN).reshape(-1, compression), axis=1)\n",
        "plt.plot(loss)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb8d6fb5c10>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deWBU1dnH8e+dfSbJhISQhQBJSICELewggigq4l4VxIrWan1dWmvFVkWbtoKiLdVSrVrUuBYsrnUtaFFQQUFkXxKDQZYQErKQZZLZ575/DAzELCxZhpl5Pn+Ze8/ceU7S+vPcc889iqqqKkIIIcSPaIJdgBBCiNOTBIQQQogWSUAIIYRokQSEEEKIFklACCGEaJEEhBBCiBbpuvoL169f39VfKYQQ4jhGjhzZ7FiXBwS0XMjJKCgoICcnp4OqOf1FWn9B+hwJIq2/cPr2ubX/cG8zIIqKisjPz8dqtZKRkcHMmTMBeP755ykpKaGxsZHp06czbNgwnnvuOT777DPeeeedjq9eCCFEl2tzDiI/P59Zs2aRl5fHihUrcLlcAOTm5jJnzhyuv/56vvzyS7xeL9dccw1Wq7VLihZCCNH52gyIqqoqkpOTAYiNjcVmswEwZswYXnvtNR555BEuu+wyzGYzCQkJnV+tEEKILtPmLabk5GTKyspISUmhpqaGuLg4ANasWcO1117LlClTmDt3Lk8++eRJfWlBQcGpVww4HI52XyOURFp/QfocCSKtvxB6fVbaellfcXExzz77LFarlX79+rFlyxbmzZvH3/72NxwOBxUVFVxwwQX079+fN998k2XLljF16lRuuOGGwMjjx9avXy+T1Ccp0voL0udIEGn9hdO3z639e7nNEURmZibz588P/DxjxgwA7r777mZt77vvPu6777721imEEOI0IQvlhBBCtEgCQgghRIvCIiBUn4+qv+ZR8/JTeKsrg12OEEKEhaCspO5orh2baVy5DHR66v+zmKhzLyb2xl+jjYkNdmlCCBGywmIE0bByKdqEJHr+aymx1/4fjSuXYntvSbDLEkKIkBbyAaG63dhXfYpl0hS01m5YZ9yEIScXV3FhsEsTQoiQFvIB4Vj/Fb76WixnXxg4Zsjoj/uHoiBWJYQQoS/kA6Jh5TJ0aX3RZ/QLHNP37Ye3ohxvfW0QKxNCiNAW0gHha7ThWPsFUWdfiKIogeP6vgMAcP+wM1ilCSFEyAu5gLB99Bbawi2oPh/2r1aiupxYzp7apI2+Vzro9Lh3yW0mIYQ4VSH1mKuqqjR++T/MW9dTtvR1UDQYBg1Dl5jSpJ2i06FP64tLRhBCCHHKQmoEoSgKPR5dSOPtv0efnoWndC/R51/eYlt9Rn/cu77r4gqFECJ8hNQIAvwh4cvMJuGSK/A57ChGU4vtDBn9aFy5DNXjQdGFXDeFECLoQmoE8WMak7nJ5PSx9H37g8eNu2R31xYlhBBhIqQDoi2GjP4AcptJCCFOUdgGhCbGirZHMu5dMlEthBCnImwDAkCf0Q+XrKgWQohTEtYBYejbH/euItrYVVUIIUQrwjog9H3746urwSd7RAghxEkL74A4PFHtkolqIYQ4aWEdELrkVBSzRV79LYQQpyCsA0LRaDAOHIZzy/pglyKEECEnrAMCwDR8DM7tm/A5HMEuRQghQkrYB4Rx+DjwuHFu3xjsUoQQIqSEfUDo0zLRdOuOc9M3wS5FCCFCStgHhKIomIaNwbFxbbBLEUKIkBL2AQFgGj4W9w9FeA9VBbsUIYQIGREREMZhYwBwbF4X5EqEECJ0RERA6BIS0fXOwLlJbjMJIcSJioiAAP9tJsfGb1BVFV+DjZoXn6Dxi0+CXZYQQpy2ImarNdPwsdjeX4Lt/SXUv/0v/3yEz4unvJSYaTe0uvGQEEJEqogZQRgHjwCtlprnHkfXJ4OU59/BOuMmal9+ipqFf0X1eoNdohBCnFYiZgShsUTR7eZZaKKisUy+GEVRiP3ZL9HE96Bm4Xw01lhiZ94a7DKFEOK0ETEjCICYy64h6txLmtxOirlkOpZJF2Bf+0UQKxNCiNNPRAVEa4yDR+DeVYSvwRbsUoQQ4rQhAcHh+QlVxVmwOdilCCHEaUMCAtD1SkMTG4dzm7zQTwghjpCAwP++JuOgYTi3bQh2KUIIcdqQgDjMOHgErp078Dll3wghhAAJiADj4OHg8eD6bluwSxFCiNOCBMRh+vR+KJYomYcQQojDJCAOU7RajANzZec5IYQ4TALiGMZBI3AVbEH1eIJdihBCBJ0ExDGMg4ejOh24vi8MdilCCBF0EhDHMPQbiGIw4twuj7sKIcRxX9ZXVFREfn4+VquVjIwMZs6cCcDzzz9PSUkJjY2NTJ8+nbS0NB577DESEhIwm83ceeednV58R1P0eozDxmB7bwlRky9GG9f9uJ9R3S5Urw+NydQFFQohRNc57ggiPz+fWbNmkZeXx4oVK3C5XADk5uYyZ84crr/+er788kuWLFnCjBkzuO+++ygtLeXAgQOdXnxniPvVbFSvh6o/399kLsJnb8TnsDdrX/W3P1E59+6uLFEIIbrEcQOiqqqK5ORkAGJjY7HZ/C+0GzNmDK+99hqPPPIIl112GZWVlSQlJQGQmJhIRUVFJ5bdeXQJSXS//884CzZT88Lf8Tns1C15gdKfXUjFH3+NqqqBtp4DJdi/XI6rYDOqVya2hRDh5bi3mJKTkykrKyMlJYWamhri4uIAWLNmDddeey1Tpkxh7ty5ZGdnU15eTu/evTlw4AA9e/Zs9ZoFBQXtKtrhcLT7Gm3SmtFf8lN4bxH1yz8Epx1vdi7q9g3sfPcNvNlDATC8vxiDqqK6nBStXI6vZ1qnlNPp/T0NSZ/DX6T1F0Kvz8cNiJtuuokFCxZgtVqZMmUKeXl5zJs3j6+++orPPvuMiooKLrroIkaNGsX8+fNZvnw56enpJCQktHrNnJycdhVdUFDQ7mscj5qdTa0GvPW1xP70ZrRJPTn42xsxfPERiT+5GtXeSOm3X2K56Coalr5DqsdBdCfV1BX9Pd1In8NfpPUXTt8+r1+/vsXjxw2IzMxM5s+fH/h5xowZANx9d/P77se2C3WKotDt5ruaHIu97jYq/nAHjnWr8JTtR3U4sE6/EeeW9bh27oALfhKkaoUQouNFzJajHcE4fCyGgbnULlqI2tiA+Yyz0SUmY+g/ENfO0Bk2CiHEiZB1ECdBURRir7sNd/F3eA6UEPOTnwL+9RPu3TtR3a4gVyiEEB1HAuIkGYeOwpg7GsOAwRhycgF/QODx4PphZ5CrE0KIjiO3mE6Soigk/OFxUH0oigKAPqM/aLS4inZg7D8oyBUKIUTHkIA4BRqzpenPJhP6tEzc3+8IUkVCCNHx5BZTBzH0H4irSAJCCBE+JCA6iKFfDu59P7T4Og4hhAhFEhAdxNBvEPh8uIu/C3YpQgjRISQgOog+LRN0ev+COSGECAMSEB1E0esx9O0vASGECBsSEB1In5WDS24xCSHChAREB9L3TsdzYJ+8+lsIERYkIDqQLjUNPB485aG5WZIQQhxLAqID6XunA+Ap2RPcQoQQogNIQHQgbUISitGIZ//uYJcihBDtJgHRgRSNBl3PPrhlBCGECAMSEB1Ml5omt5iEEGFBAqKD6XulyQhCCBEWJCA6mK5XOr6aKnwNtmCXIoQQ7SIB0cH0vdIAcJfsDm4hQgjRThIQHUyX2gcAzzEBofp8qB5ZPCeECC0SEB1MY4lGE5/QZB6ibkk+5XffEMSqhBDi5MmOcp1An5qGZ78/IFSfj4aP38NbdRDV5UQxGINcnRBCnBgZQXQCXe/0wKOuzm0b8FaWg6riLt0X5MqEEOLESUB0An1qGu7SfaheL40rl6GxxgLg2bc7uIUJIcRJkIDoBLpeaeB24dm/l8ZVnxJ1wRVooq245RUcQogQIgHRCfSp/kdd6997DbWhHsvZU9H1SsezTxbQCSFChwREJ9AmpoDeQMP/3kefnoUhPQtdrzRZGyGECCkSEJ1A0WrR9+wNXi+Ws6cC/gV0npLdqKoa5OqEEOLESEB0Et3hFdWWSUcCIh3VYcdbdTCYZQkhxAmTdRCdxDLhPLTxPdAlJgP+R1/B/ySTLiEpiJUJIcSJkRFEJ7GcNYW42+4J/KxL7gVarcxDCCFChgREF1F0OnQpvWWvCCFEyJCA6EL63umtjiDs366mYu7dMokthDhtSEB0odZ2m1PdbmoW/hXH2i/wHCgJQmVCCNGcBEQX0vdKx1tZjq+xoclx28fv4inbD4Brx+ZglCaEEM1IQHShwJNM+/cGjvnsjdT9Ox/LJP9qa2eBBIQQ4vQgAdGFjryC49h5iPr3XsNnqyX2ulsxDsyVgBBCnDYkILqQJsaKplv3wG5z3toa6t/+F9FTr0SX0gvDwFw8e3bhq687oev5HPZOrFYIEekkILqYvnca7j3F2D5+l/K7rgdVxXrNLwAw5gwFwFm45bjXcW7fROlPz8N7qKpT6xVCRC4JiC6mS03D/vVKDj35MIbMbJIefwltXPfAOY21G66CowFhX/M5lkfuRnU5m1zHVVyI6nLi2lXUpfULISKHvGqji1nOnorqchJz+bUYsrKbnFMUBUPOUJyHn2RSVZXaf/0TTXUFngMl6NMyA209h3enc+8pxjzyjK7rgBAiYkhAdDHTkJGYhoxs9bxxYC51rz2H6vHg2PA17t3fA+Au3dc0IA6vl/DsLe7cgoUQEUtuMZ1mjDm5qE4nrl3fUff6ixgGDEbVG/CU7m3SznPg6AhCCCE6gwTEacbQLwd0eurfeAlX4VasM27Cl5DUZO2E6vXiKS9Fm5CEe88uVJ8viBULIcJVm7eYioqKyM/Px2q1kpGRwcyZMwFYtGgRRUVFNDQ0MG3aNBITE/nnP/9JUlISVquVW2+9tUuKD0eKwYghKwf71yvRp2ViGj0B9d1/NxlBeCvLwePBPPYsbB+9ibe8FF1KryBWLYQIR22OIPLz85k1axZ5eXmsWLECl8sFQFZWFnPnzuX2229n5cqVfPHFF1x66aXcc889FBcXU1NT0yXFh6sjj7vGXH0jikaDLyE5MCkNR+cfzGdMAsC9d1fXFymECHttjiCqqqpITvZveBMbG4vNZiM+Pp5x48ZRXV3NCy+8wJ133onRaOTZZ59l27ZtVFVVUV1dTbdu3bqkA+HIcs6FeOtrsUw8DwBfj2S8VRX47I1ozBZ/QCgKxkHDUcxR/ieZxp4V5KqFEOGmzYBITk6mrKyMlJQUampqiIuLA6CwsJDFixcze/ZsYmNjOXjwINdddx29e/fm1ltvDYRKawoKCtpVtMPhaPc1TntTr+Zg0U4APNZ4TMDO1V/gS03DsG0Tuth4Cot3YU5MoXLLBvYPGXf0s402sEQHp+4OEhF/4x+JtD5HWn8h9PrcZkDcdNNNLFiwAKvVypQpU8jLy2PevHnce++9jB07loULF9K3b18mT57MvHnzSE5OZtKkSVgslja/NCcnp11FFxQUtPsaoaSwvhaA3kYdlpwcKt+x40vrS1pODtXZg3EVbafv4d+HY+t6Kh68g+Rn30Lfs3cwy26XSPsbQ+T1OdL6C6dvn9evX9/i8TYDIjMzk/nz5wd+njFjBgDvv/9+s7YLFy5sT32iDWq0FSUqGs9+/14SngMlGPoPBkCflknDpx+hej0oWh22/74FPi/uPcUhHRBCiOCTx1xDgaKg69kHd+k+VFXFc6AEXU//U0v6tEzwuPGUluCtq8H+1UoAvGWy8ZAQon1kJXWI0Pfsjad0L75DVagOe+CxVn2fvgC493yPt6oCVB+a+AQ8B/YHs1whRBiQgAgRutQ+ODZ9g+fwyECX7A8ITVx3NNZY3HuKsa/+DPOYs1C9nsAOdUIIcarkFlOI0PXsg6/2EK6d/icgjowgFEVBn5ZJ44qluPcUE3XB5eiSUwNBIoQQp0oCIkToUvsA4NjwNZpu8WgsUYFz+rRMPAdK0HZPxDTiDH9AlB9A9XqDVa4QIgxIQIQIfU9/QDi3rG/2Wg19H/9bXqPOvwxFq/Wf97j9cxJCCHGKJCBChCY6Bo21G6rL2SwgDIOGoYnrTtQFlwOgS04FkNtMQoh2kYAIIUduMzULiPQsUhd9jC4xBQBtYk8AmagWQrSLBEQI0fU8EhBtL4DTmExo4hPwtjMgXDt3oLpd7bqGECJ0SUCEEH0rI4iW6FJ6Bd76eip8jQ2U330jDZ9+dMrXEEKENgmIEKLPzEYxGAO3mtrif9T11EcQngMl/ld27PvhlK8hhAhtEhAhxDTyDFJe/ghtTOxx27Y7IA5PcB+7D4UQIrJIQIQQRVHQxp7YPhu65FR8dTX4Gm2n9F1HgkECQojIJQERpo4+6loKgOr1YPv4XTyVB0/o80fe5eQp2y8L7oSIUBIQYerIu5qOTFQ3frmcQ08+TNktV1L72vP4HI42P+85sA/FHOVfcFdZ3un1CiFOP/KyvjClieuOYjQG5iFs7/0bQ85QDNlDqHv9BRqWvYNh4DB0ST3R9exN1DkXohiMgc97DpRgGjYa+9cr8ZTuQ5fUM1hdEUIEiYwgwpSiKGgPT1Q7C7fiKtpOzFU/I+7mWSQ/8wamMRPxHaqi8fNlHHryYRpXfRr4rOp24a0sxzhsDGg0Mg8hRISSEUQY0yWl4i3bj+39JWiTUjGPmQj411PE3/FAoF3pLy7HtXMHUZMvAg7PW6gq+t4ZaBNTcJfuDUr9QojgkhFEGNOl9MJVXEjjquXEXDodRattsZ2h30BcO3cEfvYc2Hf4870Pb1QkIwghIpEERBjTJafiqz2EojcQdf7lrbYz9MvBves7VK8HODyxrdOj7d4DXQsBYfvoLdz7ZVQhRLiTgAhjR55kijrvEjTRMa22M2QNRHU6ce/bDfjXPuiSex5+dXjvJo+6eqsqOPTMn7F98Hqn1y+ECC4JiDBm6JeDof9AYn4ys+12WdkAgdtMnrKSwAsBdT37NHnU1b7+KwCcW9d3VtlCiNOEBEQY08Z1J2nBq8d9uZ8mKhpdah/ch7cz9ZSWBD6j63l4PcXh20yOb1eDRoN79/d4aw91YvVCiGCTgBDA0Ylq1evBc7D0aEAkpQYedVU9Hhwb1mKZfDEAzm0bglmyEKKTSUAIAAxZObh+2OlfWOfxBAJC0esDj7o6d2xCtTcQffE0tEk9cW6R20xChDMJCAH4RxC4XdjXfA6ArufRTYmOPOrq+HY1mtg4DFk5mIaOlHkIIcKcBIQAQJ85ABSFxs8/AY0GXeLRV2scedTVvm41plHjUTQajENG4t5TLPMQQoQxCQgBgMZsQdc7A3dxIdoeySh6feCcLqU3ntK9ePbuwjzqTACMQ0YC8jSTEOFMAkIEGPrlAEfXTxyh69kHfD7QaDANH+c/lpiCNilVAkKIMCYBIQIMWYcDouePAiLVPx9hyBmKJsYaOG4aOhKHTFQLEbYkIESAod9AgGbrJnSJPVGMxsDL/o4wDh2JZ+8uvDXVXVajEKLrSECIAH3f/ugzB2AcNKLJcUWvJ+mJxcRcfm2T48bB/nkIx8a1XVajEKLryOu+RYDGaCL5ycUtntP3Tm92TJeYjGHQMA79Yx6KTodl4vmdXKEQoivJCEK0S4+5/8A0ZiJVf76fmleelv2rhQgjMoIQ7aIxmel+3yPU9x1A7atPo4mOwXrVz4JdlhCiA8gIQrSboihYr/45puFjcW75ts22qs/XRVUJIdpLRhCiwxj6DcS29B1UVUVRlMDx6n/Mw77mc1R7I6rTQcwV19Ht5ruCWKkQ4kTICEJ0GEO/gfjqavBWlAWOqS4nDcs/xJgzlNjrb8c0ZiINn30kcxVChAAJCNFh9IfXUbiKtgeOOYu2g8eNdcZNxFwxE+v0n+OrPYRz+8ZWr2P/5ku0W9Z1er1CiLZJQIgOo0tIRBOfgOvwxkPg3zNCMVvQ9+0PgCF7CNruPbCv/qzFa/gcdqoXzMH0xvP4bPVdUrcQomUSEKJDHdl46AjX9k0Yc3JRtP7pLkWjwXzG2di/XtHihHXDsv/gs9WB24Xtoze7rG4hRHMSEKJDBXam8/lQvR6cOzZjHDy8SRvz+HPxVlXg+m5bk+Oq20X9O4uwnHUBntFnUf/ua/gcjq4sXwhxDAkI0aEM/QaiNjbgObAPV/F3qA47xsFNX91hHDwMjbVbs9tMDZ9+hLfqINarf47r7Ivx2epo+OTdrixfCHEMCQjRoQyBieodOLdtBL0BQ/+BTdooWh3mM86m8avPUFUVANXrof6tVzCfcTb6tEzUhCQsE8+n/u1/obrdJ/z9ji3fUv/evzuuQ0JEMAkI0aG0sd3QJvXEtXMHzm0bMA4YjKI3NGtnHj8Zb3kp7u8LUd0ubEvfwXOghJirbwy0iZn+c7yV5TSs+O8Jfbdjwxoq/ngnta8+EwgeIcSpk4VyosMZ+g3E9d12PCW7ib5keottTLmjUaKiqXjwLny2WvB4MI2ZiLH/oKPXyeiHedwkal94An2vdIwDc1v9TsfGNVQ+9Fs00TH4DlXhq69Fa+3W4X0TIpK0GRBFRUXk5+djtVrJyMhg5syZACxatIiioiIaGhqYNm0aWVlZPPnkkyQlJXHw4EHmzp3bJcWL05Oh/0BqVy0HaDZBfYSi19PthjtwfrcVQ1YOhqxsDP0GNWsXf9efqJg7i4q8X9L9/r9gHj2hWRvHtg1Uzv0txsHDiZn+cyruvw3vwTIJCCHaqc1bTPn5+cyaNYu8vDxWrFiBy+UCICsri7lz53L77bezcuVKNm/ezLBhw7jjjjuoqqrCZrN1SfHi9GTIOjznoNFiyB7aarvoi6fR/e45xFx2DcaBw5rsg32EJsZKj4eexpg7hsq5v6Vh5bIm51W3i0NPPIQ+cwDd8x5D3ysdAM/BAx3WHyEiVZsjiKqqKpKTkwGIjY3FZrMRHx/PuHHjqK6u5oUXXuDOO+8kJiaGO+64g61btxIVFUV0dHSbX1pQUNDm+eNxOBztvkYoCbn++jREKQq+1DS+273nlC7RrM9X3YTR46Xqbw9S4lHxpaYDoF/xEYYDJdivuY3qXT+Az0eUVkfp1k2445I7oDNdJ+T+zu0Uaf2F0OtzmwGRnJxMWVkZKSkp1NTUEBcXB0BhYSGLFy9m9uzZxMbG8uqrr3LLLbcwfvx45s2bR2FhIdnZ2a1eNycnp11FFxQUtPsaoSQU+1s+YDCmkeNJP8W6W+qz2v+vlN99I/rXnyfpiX+hOh0c+OwDLBdeRZ9zLwi0O5CUQoziIy7Efmeh+Hduj0jrL5y+fV6/vuW95dsMiJtuuokFCxZgtVqZMmUKeXl5zJs3j3vvvZexY8eycOFC+vbtyxlnnMGrr77Khg0bqK+vJy0trVM6IUJH4l9fgGPe6NoRFIOR7rMfofw313No4Xz/6myNhtjrbmvSTtsjBe/BslauIoQ4UW0GRGZmJvPnzw/8PGPGDADef//9Zm0feuihDi5NhDJF0zlPUOt7pRN3271U/30OAN1u+S3a2KaT0brEZFy7ijrl+4WIJPKYqwg5lvMuwVmwGdeuIqIvbv4YrTYxBe/az4NQmRDhRQJChBxFUYi/Mw/V52txpKJLTMFXV4vPYUdjMgehQiHCg6ykFiGrtdtY2h7+p5e88qirEO0iASHCji7RHxCyFkKI9pGAEGFHm5AEiiIjCCHaSQJChB1Fr0cb3wOPPOoqRLtIQIiwpE1MlhGEEO0kASHCki4x5ZTnINz791D1lwfYf+35eCrLO7gyIUKHBIQIS9rEk19N7a2vpfqJhyi77Wqc2zeiOh3YPjyxfbG9NdU4t22UfShEWJF1ECIs6RKT8VZXoLrdLb4l9se8tYeo+P0v8Rw8QOyNvyb64mnUvvI0DUvfwXrNL1pcT+FzOqh98UkcG9fg2b8XgO4PzMdy5uQO748QwSAjCBGWtIkpoKp4qw4et623upKDs2/FW11J4vx8rFdeh8ZoIubSGfga6mn89KMWP2f/cjm2D9/AOHQU8b+diz5zgOyhLcKKBIQIS7rEFOD4ayG8VRUcnH0LPlsdiX9+DkN61tFrpPTCPG4S9e+9hurzNfts46rlGLKHEn/HA0RNvojoqVfg2LCmzXkL545NqB7PKfZKiK4lASHCkvZwQLQ1D+Gtr+XgH36F6nCQ+Ofn0PfJaNYm+ifX4tm/F8e3XzU57rPV49i4BsuEcwPHLJOmouj1NCz/oMXv81Qe5OA9N2P78I1T6dIJOfT836j/4PVOu76ILBIQIixpTGY01thWRxA+h4PKB2fhq6qkx8NPoU/t02I746Dh6DOzqX/3tSbH7Ws+B48H8zEBoYmKxnzmuTR88kGLIw739/6NYhpWLD3VbgGgqio1Lz+Fff3Xzc41rlxG/buvyWS56BASECJs+feFaB4QPnsjVY/eh/uHIhLmPIG+T99Wr6EoCjFXzMS5+Rsc2zYEjjd++T8M2UPR9Wi6a13UlMvxlu/HubX5Biyu7wsBf1C49+0+xV5B4+cfU//myzR++mGT4976Wnw11XjL9uP+YecpX1+IIyQgRNjyr4UoQ3U5sa9bxaFnH6PsN9ez/+pzcGxcQ/cH5mPMHnLc61jOmoIhewiHnngIn8OBr74Ox6a1WCae16ytcfAIdD170/DJe83Oub4vwDBoGIolisaVpzaK8NbWUPPsY6AouPfuanLOs++HwD/bv15xStcX4lgSECJsaROTcRVuZv9Pz6Pywbuwf70Sfa90ut36O5L/+SbmUeNP6DqKVkv8b/6I52AZdYufbfH2UqCtohB1/mU0rv4MX31dk3Ou4kKMOblYzjyXhhVLm9wG8jnscAK3hWqefxzV6yXmyutx79uN6j064X1kVGIaexb2ryQgRPtJQIiwZR51JvqsHGKm3UDS00tIeekDut/zEDGXTG91zqE1+j4ZxF77f9S/u5i6t17BkDMUXUJSi20tky8Gt8sfJId5qyvxVVdiyMrBcs6FeMtLcRVsBsCxbQOl156P7pu2Nzmyf7uaxhVL6XbzXZiGjwGPG8+BksB5z77daBNTiDrnIty7v8dduu+k+ijEj0lAiLBlGjGOpPn5xP70ZgzpWevIYN0AABXcSURBVCjt3CM75qqfoU/PwlOyG8uE5reXjtAlJKLPysH+7erAsSPzD4asbIyDR6DtnkjDiqW4vi+kcs4sVJcT/bdftnpN1efj0D/nY8wdQ9T5l6HvkwmAe8/R20zufT+g752BadR40BvkNpNoNwkIIU6QotMRP+tBDP0HYjlrSpttzaPOxLFxTWDNg+v7ApSoGLTJqShaLZazL6Dx80+o+MMd6FLT/Htr/1CEp7LlhX3OLd/iLdtP7MxbUBQFTXwCSlQM7j3FgTbukt3oeqWhMVswDR8rt5lEu0lACHESDH37k7TgVbTxCW22M42egNpgw3n4NpLr+wIMWdmBUYzlnItQG+rRWLvRY86TRJ1zEapWi331py1er+F/H6Dr2RvDwFzAP9ehT88MTFT7nA685aXoe/vXcljGT8ZVuBVvVUWH9FtEJgkIITqBoV8OGms3HOv8t5ncxd9hyMw+ej6jH91nP0riowvRxnZDE2PF228wjV/+r9m1fA027F99RtS5lzS5Tabv0xf3Xv8IwrN/L6hqICBMYyeCRkvj1ys7sZci3ElACNEJFK0W06jx2L9dhbemGm9lOYas7CZtLBPPbzIS8eSOxVWwBU9F09XfjV98gup2YTn34ibH9X364inZg+p24ynZDYCudzoAWms3jENGYF+zssP7JiKHBIQQncQ86kw8e3YFJov1WTlttvcMHgE6HfZVTW8zNSz/ANPwsc0W5enTMsHrxVO6F/e+H9BYY9HGxh39/jETcW5dj6+xoYN6JCKNBIQQncQ04gzQaKh78xUUcxS6lF5tf8AchWn4OBqPCQj3vt24CrcSdd6lzZrr0w4/ybR3F+59u9H1bvouKfPYs8DjwbFxTfs7IyKSBIQQnUQTY8WQMxRveSmGrAEomuP/380y8TxchVtw/bATn62ehk/eQ4mKxnzG2c3aarvFo7F2w71nF56S3eh7pTc5r0vpha5XOva1rT8+K0RbZMMgITqRedQEXNs3Hff2UqD9uLNBb6D8jp8GjkVddBWKwdhie31aX9y7d+Iu2UPUj+YoAMxjJ9Lwvw9QvV4UrfaU+iAilwSEEJ3INGYCta88heEEA0ITFU3S4y/hKS8FjxvV68U08oxW2+vTMmn49CNwu5rdYgIwjzmL+rf/hatoO8acoafcDxGZJCCE6ESG9Cx6PPJPjIOGn/hnMgdgyBxwQm31fTJR7Y3+f/7RLSYAQ84QNNFW7N98KQEhTprMQQjRyUy5o1F0nfPfYro0/6vKFaMxsEnSsRStDtOoM3Gs/aJTvl+ENwkIIULYkb0sdKlprU6Cm8dOxL2n2H/bSoiTIAEhRAjTWruhieve4u2lI0wjzgCtFvs38jSTODkSEEKEuLhbf0f0FTNbPa+JjsGUO5r6N1/BvX9vF1YGqtsdeJOtCD0SEEKEOMvE8zH2H9Rmm7jf/AHFZOLgff/XbCe6zlT3xouUz/pZq2+pFac3CQghIoAuIYnEPz+HxhrLwdm34uqCPatVlxPbR2+Bz9fle1N4KsoovelyHJu+6dLvDTcSEEJECG18AomPPoe2ew8q7r8N186CTv2+hpXL8NUe8q/mXv1Zk3Oq24W2aGunfK/q81G9YC7e8v04vv2qU74jUkhACBFBtLHdSHxkIbqUVA4+cBvOgi0ttnPu2Ixt6dtN9s0+lurx4Cnbj/2bL6l5+SnK772Zg/ffhre2xn9eVbG9929Mo8YT85Of4ty+EW9NdeDz9e8swvzc/E4Zydg+fAPn5m/QJqfiKtre4dePJBIQQkQYTYyVHvOeQZ+eRcUf7sCxbUOT86rLSdX833PoqUepfuyPqC4nAL7GBmpefILSn19CyRXjOfCLy6mcM4uG/72P1hqHe/f3VM69G5/TgXPTN7h3f0/MT671vz5EVbEf3pvC53BQ/+5rAIFjHcW99wdqX/oHURdNI/rCK3F9X4Dq9XTod0QSWUktRATSWKLpMfcfVM65i6qH7yH56SVou/cAoP6DN/BWVRB7/e3U/jsfz8FSos67lNpFC1Ft9URNuRx9Wl+0iT3Rp/bxb6OqKDgLt1Jx/21UP/5HVKcDfVomxmFjURQF46Dh2L/6jOgLr6Thk3fx2erw9snEvmYlsdf+X4s1eqsrqfrbn4g6+0Isky867ssOVa+Xqr/9CW1CEt1+8RtcRdtRnQ7ce3/AkNGvw3+HkUBGEEJEKI3ZQvf7/wJaHVULHkT1+fDW11L3+otEXXA51mt+QeKjC/Hs38uhJx/GOGAwyf98g7jb7yX6ommYR41Hl9IrsMudMXsI8fc8jP2rFTi+/Yroy38aOGc+czKOzevwHqqi/p1/YZlwHu6JF+Au/g7PwQMt1te4ajnOjWupXvAg5Xddj2Pzt232x7l1Pe6dO4j71Ww0JrP//VeKguu7bR37i4sgEhBCRDBtbBzxs/6Ic+NabO8voe71F8HrIfbaWwAwDswl6clFJM7PJyHvMXTJqW1ezzL+HLrddi+GAYOxnD01cNw8fjJ4vVT99Q94K8qJmf5zPNm5/g2S1nze4rUc61ZhzB1N4l+eR9FqqXjgtjb3tmhcuRRtUk+MuaMB0Fii0PfpK/MQ7SABIUSEM486k+hLrqbm5aewffAGMVdd32QrVF1CEsZBw074ejGXTCfpby+jMZqOuUYihuwhODd/g2n0BAx9+4PZgmnoqBbnIXz2Rhxb1mMePQHj4OEkPv4yhv4DqV30bIsT56rLSePqz7BMuqDJvt2G/oMkINpBAkIIQexNd6JL6YUm2krMFdd1yneYzzwXAOvVPz96bNzZOLdtxFtX06StY9M34HFjGjMBAEWjwXrtLbgKt+LY0HwUYV+3CrWxgahzLmxy3DBgEO49xfgOv/E2mJwFW9BuWx/sMk6KBIQQAo3RROJfniNpwctozJZO+Y7oi6aR8ODfMQ48OhoxjT0LfF4c61Y1aetYtwpdzz7oU9OOth11Job+A6l77blmo4jGFcvQ9+0feHnhEYb+g8Dnw1Uc/Nd91L3xEqZ/L8TXaAt2KSdMAkIIAfhf/Kdr4ZXhHUVjMmEePaHJMV1CIob+g7B/fXQeQvX5sK9bhWn0mU3aKorS4ijCV1+Hfd0qLGc3HT0A6NOyUIxGXN8F/zaTp2QPitNBwyfvB7uUE3bcx1yLiorIz8/HarWSkZHBzJn+l4ItWrSIoqIiGhoamDZtGi6Xi1Wr/P8VsGrVKl577TXi4uI6t3ohRMgzn3E2dUvy8dbWoI3thrv4O3zVlc3CBJqOIkwjxqEoCo1ffQZeD5ZJU5q1V3Q69JnZQX+SSXW78JTtR9UbqH//daIvnRESW8AedwSRn5/PrFmzyMvLY8WKFbhcLgCysrKYO3cut99+OytXrmTSpEn8/ve/Z+rUqUyfPl3CQQhxQiznXIhiNFPxh1/hs9VjX7cKxWzBOHhEs7bHjiLK7/oZdW+9QsMn72EcPAJdQlKL1z8dJqo9B0rA58V13uX+V4CEyKvXjzuCqKqqIjk5GYDY2FhsNhvx8fGMGzeO6upqXnjhBe68885A+1dffZXHHnuszWsWFLTvHTAOh6Pd1wglkdZfkD5HgmP7q/nF7zAvfIS999wMbhdq1kAKv/++5Q9Gd0d7w5141q/G9a+FKB43jum/oKqV350uqhumijIK136Nau3WWd1pk3brOsyAbegYdNs3UPbvF3B0aznQTifHDYjk5GTKyspISUmhpqYmMDIoLCxk8eLFzJ49m9jYWAA2b95MdnY2er2+zWvm5JzYBu6tKSgoaPc1Qkmk9Rekz5GgSX9zcnD26U3FA79EtTcQN+NGotv6XeTkwNU/w9dow1W4DWPuKBRty/8688RZObD4GdJ8Tsyd9Pv11deBVoPGEt3i+botX1NnicKYkESPGTdS/dc8Mg2aE957vLOtX9/y01XHvcV00003sWDBAh5++GGmTJlCXl4eAPfeey8mk4mFCxfy5ptvArBp0yYGDhzYgWULISKFsf8gesx9AtOo8ZjHnnVCn9FYov1zEa2EA4A2qSfapFQaW1iQV/f6izQs/xDV6z3lugEq/3I/1X+f2+p5d8lu/65/ioJlwnlou/eg/v0l7frOrnDcEURmZibz588P/DxjxgwA3n+/+Uz8DTfc0IGlCSEijXHgMHrMebJDr6koClHnTKX+vX/ju/0+NCb/Aj5X8XfUvvoMAHVvvULs9bdjHn9Ok4V2J0L1eHDt2AQ6ParX2+Lks6dkN7reGf56dDqipl5B/Vuv4rv9XjQm83G/w1mwhcaVS+l2y++6dHJbHnMVQoQ9y+SLUO2N2NesDByzffQWmvgEEufno41PoOqRe6l54e9tXsd7qKrZOgb3D0WoTidqgw337uavL1dVFfe+Peh7ZRyt56wpqE5Hs/Ufral95WlsH75JwyfvnlD7jiIBIYQIe/rUNAwDBtO44r8A+Gz1NK5cSvTUKzAOGkbiI/8k9ud3YPvP4jbf91Txx19zaGHTh3CcBVtApwOdHufWDc0+462qQLU3oOudfrSeXunoMwfQ+MUnx63dvW83zq3r0Sb1pPaVZ5qtOu9MEhBCiIhgmXwRjg1r8R6qouGzj1DdbqIuuCJwPuaqn2EcOorqBXPw1tc2+7y3rgb3riIc675sMmfhKtiCoe8AjAMG49zafLLXU7Ib8IdCk3omno993erjrqy2LX0bTUwsiY8uRPV4ArfFuoIEhBAiIlgmTgEFGlcuw/bRm5jPmIQuITFwXtFoiL/7QXwOO4ee/nOz13m4dmwGwFdXi2vnjsBxZ+FWDDlDMQ4ZgXP7JlSfr8nn3CW7QatFl9KraT1nTQG3q9W32QL4nA4aP/2IqPMuRZfUk9iZt9Cw7D9Nvr8zSUAIISKCNrYbplFn+jdBKtlD9MVXN2uj65FM3C9nY//yf9hXLW9yzrl9E5pu3VGiogN7XXurKvAePIAxewjGwSPw1dfi3lPc5HOefbv9+2bomj4TpEvqiSF7CI1f/K/Vmu2rluOz1RF1oX+kE33pDHR9Mji08K+tbgfbkSQghBARI2ryRagN9eh6pWMcOrLFNpZJF2AcMgLbf99ucty5YxPGwcMxDR+H/dvV/mOF/j29DTlDMeQMBa222W2mwCOuLX3XxPNxbPi6xVtaALb/voMxd3TgpYWKTkfszNtwFW7Fs3/PCff7VElACCEihnnMRLQJScRceV2rj7MqioLlrCk4t23AW3sI8O+j7dq5A+OgYZhGjce9cwfemmpcBVvRdk9E1yPZv4td/0HNAsJTsgddKwFhnnAe+HzYv1rR7Jzrh524CrcQfeFVTY6bRowDnf6En4BqDwkIIUTEUAxGUl7+kOgLftJmO/MZ54CqBjYzcn23DbxejIOGYx45HgDHhq9xFmzBkD0k8DnjkJE4t20MzEP4GhvwVpa3OoLQJSRiHDwc24dv4KksDxx3FRdS+dDv0HZPxDxuUpPPaMwWTENHYl+3+mS7f9IkIIQQEeVEFsJp47pjHDQc++pPAf/tJcUShT49C218AvrMAdi/Xonr+wKMOccExOAR+OpqcO/dBYBn/16AJo+4/ph15q14qyspu3UadW++jO3jdzn4u1+giYoi8S/PobTw6iLT6Ak4t23A19C5e0tIQAghRAvMZ07GsXkd3vpanNs3YszJDaxiNo860z+68Lgx5OQGPmPMGQoaLc5t/vUQ7iOPuB6z8dGPmYaMJOXZt4k6/zJqX32GQ08+jGXSFBIfe7HZk0+B2kZPAK+3zTUbHeG4r9oQQohIZB4/mZpnH8P+1QpchVuxTjv6KiHTqPHUvf4i6PRNXrinsURh6JdD3ZIXcO8pxltVgaZbdzQx1ja/SxMdQ9xt9xB1wU/wlu3HNG5SmyMdXUovdL3Ssa9bjWXCee3vbGvf02lXFkKIEKZLSMSQPZS6JS+g2hsxDB4eOGcYMBglKgZ97wwUvaHJ5+LuzMP2/us4N32Dp3Sff1L5BBky+kFGvxNqax49gYYV/0X1+VA0nXMzSAJCCCFaYZkwmZr8v4NOj7H/oMBxRauj2w2/QtOt+cZohvQs4u/8PQCeijKUE3gZ36kwjZ5A/X8W+Z+uGjC4U75D5iCEEKIV5jPPBcDQLwfFYGxyLvriaVgOn2+Nrkcy2pjYTqnNOGgYiiUKRyc+zSQBIYQQrdAlpmA+c7L/tRinGUWnwzTiDOyduB5CAkIIIdqQ8MB8Yi67JthltCjq3EtQ3c5Ou77MQQghRIgyj5mAafSZnXZ9GUEIIUQIO9kd8E6GBIQQQogWSUAIIYRokQSEEEKIFklACCGEaJEEhBBCiBZJQAghhGiRBIQQQogWSUAIIYRokaKqqtqVX7h+/frjNxJCCNGlRo4c2exYlweEEEKI0CC3mIQQQrRIAkIIIUSLJCCEEEK0SAJCCCFEi0JqP4iioiLy8/OxWq1kZGQwc+bMYJfUKYqLi3n66aeJj49Hr9ej0+nweDxUVVUxe/Zs4uPjg11ip1BVlV//+tcMHDgQu90e9n2ura3lH//4BwaDgaSkJIqLi4mJiaG6upo5c+ZgMBiCXWKH2rlzJ4sWLSIuLg6fz4eqqmH7N66vr+e5555j27ZtvPTSSzz++ONN+lpUVMR7772HXq9nwoQJTJly+u1YByE2gsjPz2fWrFnk5eWxYsUKXC5XsEvqNA888AB5eXkUFhZSXV3Nfffdx5VXXsmSJUuCXVqneemllxg6dCg+ny8i+vzmm28SGxuLXq+nV69eJCUlcc899zBq1CiWLl0a7PI63OrVq7nwwgu566672LhxY1j/jd1uN7feeiuqqrJ3795mfX3++eeZM2cOc+fOZfHixcEut1UhFRBVVVUkJycDEBsbi81mC3JFnSMzM5Pu3bvz4osvMnLkSJKSkgBISkqioqIiyNV1jjVr1mAymcjNzQWIiD7v3buX3NxcZs2axW9+85vA/7bDtc9TpkzhmWee4f777wfC+28cHx9PdHQ0AJWVlc366vP5AiNEjeb0/ddwSN1iSk5OpqysjJSUFGpqaoiLiwt2SZ3C5XLxyCOPcMkll5CamspTTz0FQGlpKampqUGurnMsX76c2NhYtmzZwv79+wO7ZIVznxMSEgL/PGrUKMrKyoDw7fMrr7zCQw89RFpaGtdff33Y9/eIlJQUysvLgaN9PXDgAC6XC71ef1oHREgtlCsuLubZZ5/FarXSr18/ZsyYEeySOsXzzz/P2rVr6devHwBerxetVkt1dTWzZ88O22AEWLt2LevXr8flcuF0OsO6z+Xl5Tz66KMkJSWRlJTE3r17iYqK4tChQzz44INhNwexdu1ali1bRlxcHFVVVcTFxYXt33jTpk18/PHHLFu2jKlTpwaOH+lrcXExb7/9Nnq9nkmTJnHuuecGsdrWhVRACCGE6Dqn79hGCCFEUElACCGEaJEEhBBCiBZJQAghhGiRBIQQQogWSUAIIYRokQSEEEKIFklACCGEaNH/A2QfdBPnWZebAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 460.8x316.8 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "VlfyVholCPXm"
      },
      "source": [
        "#@title ### Rollouts\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}