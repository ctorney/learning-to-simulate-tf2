{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZonalModelAttempt.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyODJgfC+rV9K+yDGAVdJLs7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctorney/learning-to-simulate-tf2/blob/main/test-files/ZonalModelAttempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXVqnwzwXWxk"
      },
      "source": [
        "!pip install \"graph_nets>=1.1\" \"dm-sonnet>=2.0.0b0\" \"tensorflow_probability\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BL8x-cdXhgo",
        "cellView": "form"
      },
      "source": [
        "#@title ### connectivity_utils\n",
        "\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import neighbors\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def _compute_connectivity(positions, radius, add_self_edges):\n",
        "  \"\"\"Get the indices of connected edges with radius connectivity.\n",
        "  Args:\n",
        "    positions: Positions of nodes in the graph. Shape:\n",
        "      [num_nodes_in_graph, num_dims].\n",
        "    radius: Radius of connectivity.\n",
        "    add_self_edges: Whether to include self edges or not.\n",
        "  Returns:\n",
        "    senders indices [num_edges_in_graph]\n",
        "    receiver indices [num_edges_in_graph]\n",
        "  \"\"\"\n",
        "  tree = neighbors.KDTree(positions)\n",
        "  receivers_list = tree.query_radius(positions, r=radius)\n",
        "  num_nodes = len(positions)\n",
        "  senders = np.repeat(range(num_nodes), [len(a) for a in receivers_list])\n",
        "  receivers = np.concatenate(receivers_list, axis=0)\n",
        "\n",
        "  if not add_self_edges:\n",
        "    # Remove self edges.\n",
        "    mask = senders != receivers\n",
        "    senders = senders[mask]\n",
        "    receivers = receivers[mask]\n",
        "\n",
        "  return senders, receivers\n",
        "\n",
        "\n",
        "def _compute_connectivity_for_batch(\n",
        "    positions, n_node, radius, add_self_edges):\n",
        "  \"\"\"`compute_connectivity` for a batch of graphs.\n",
        "  Args:\n",
        "    positions: Positions of nodes in the batch of graphs. Shape:\n",
        "      [num_nodes_in_batch, num_dims].\n",
        "    n_node: Number of nodes for each graph in the batch. Shape:\n",
        "      [num_graphs in batch].\n",
        "    radius: Radius of connectivity.\n",
        "    add_self_edges: Whether to include self edges or not.\n",
        "  Returns:\n",
        "    senders indices [num_edges_in_batch]\n",
        "    receiver indices [num_edges_in_batch]\n",
        "    number of edges per graph [num_graphs_in_batch]\n",
        "  \"\"\"\n",
        "\n",
        "  # TODO(alvarosg): Consider if we want to support batches here or not.\n",
        "  # Separate the positions corresponding to particles in different graphs.\n",
        "  positions_per_graph_list = np.split(positions, np.cumsum(n_node[:-1]), axis=0)\n",
        "  receivers_list = []\n",
        "  senders_list = []\n",
        "  n_edge_list = []\n",
        "  num_nodes_in_previous_graphs = 0\n",
        "\n",
        "  # Compute connectivity for each graph in the batch.\n",
        "  for positions_graph_i in positions_per_graph_list:\n",
        "    senders_graph_i, receivers_graph_i = _compute_connectivity(\n",
        "        positions_graph_i, radius, add_self_edges)\n",
        "\n",
        "    num_edges_graph_i = len(senders_graph_i)\n",
        "    n_edge_list.append(num_edges_graph_i)\n",
        "\n",
        "    # Because the inputs will be concatenated, we need to add offsets to the\n",
        "    # sender and receiver indices according to the number of nodes in previous\n",
        "    # graphs in the same batch.\n",
        "    receivers_list.append(receivers_graph_i + num_nodes_in_previous_graphs)\n",
        "    senders_list.append(senders_graph_i + num_nodes_in_previous_graphs)\n",
        "\n",
        "    num_nodes_graph_i = len(positions_graph_i)\n",
        "    num_nodes_in_previous_graphs += num_nodes_graph_i\n",
        "\n",
        "  # Concatenate all of the results.\n",
        "  senders = np.concatenate(senders_list, axis=0).astype(np.int32)\n",
        "  receivers = np.concatenate(receivers_list, axis=0).astype(np.int32)\n",
        "  n_edge = np.stack(n_edge_list).astype(np.int32)\n",
        "\n",
        "  return senders, receivers, n_edge\n",
        "\n",
        "\n",
        "def compute_connectivity_for_batch_pyfunc(\n",
        "    positions, n_node, radius, add_self_edges=True):\n",
        "  \"\"\"`_compute_connectivity_for_batch` wrapped in a pyfunc.\"\"\"\n",
        "  partial_fn = functools.partial(\n",
        "      _compute_connectivity_for_batch, add_self_edges=add_self_edges)\n",
        "  senders, receivers, n_edge = tf.py_function(\n",
        "      partial_fn,\n",
        "      [positions, n_node, radius],\n",
        "      [tf.int32, tf.int32, tf.int32])\n",
        "  senders.set_shape([None])\n",
        "  receivers.set_shape([None])\n",
        "  n_edge.set_shape(n_node.get_shape())\n",
        "  return senders, receivers, n_edge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEx3i6DgXslW",
        "cellView": "form"
      },
      "source": [
        "#@title ### graph_network\n",
        "\n",
        "from typing import Callable\n",
        "\n",
        "import graph_nets as gn\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "\n",
        "Reducer = Callable[[tf.Tensor, tf.Tensor, tf.Tensor], tf.Tensor]\n",
        "\n",
        "\n",
        "def build_mlp(\n",
        "    hidden_size: int, num_hidden_layers: int, output_size: int) -> snt.Module:\n",
        "  \"\"\"Builds an MLP.\"\"\"\n",
        "  return snt.nets.MLP(\n",
        "      output_sizes=[hidden_size] * num_hidden_layers + [output_size])\n",
        "\n",
        "\n",
        "class EncodeProcessDecode(snt.Module):\n",
        "  \"\"\"Encode-Process-Decode function approximator for learnable simulator.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      latent_size: int,\n",
        "      mlp_hidden_size: int,\n",
        "      mlp_num_hidden_layers: int,\n",
        "      num_message_passing_steps: int,\n",
        "      output_size: int,\n",
        "      reducer: Reducer = tf.math.unsorted_segment_sum,\n",
        "      name: str = \"EncodeProcessDecode\"):\n",
        "    \"\"\"Inits the model.\n",
        "    Args:\n",
        "      latent_size: Size of the node and edge latent representations.\n",
        "      mlp_hidden_size: Hidden layer size for all MLPs.\n",
        "      mlp_num_hidden_layers: Number of hidden layers in all MLPs.\n",
        "      num_message_passing_steps: Number of message passing steps.\n",
        "      output_size: Output size of the decode node representations as required\n",
        "        by the downstream update function.\n",
        "      reducer: Reduction to be used when aggregating the edges in the nodes in\n",
        "        the interaction network. This should be a callable whose signature\n",
        "        matches tf.math.unsorted_segment_sum.\n",
        "      name: Name of the model.\n",
        "    \"\"\"\n",
        "\n",
        "    super().__init__(name=name)\n",
        "\n",
        "    self._latent_size = latent_size\n",
        "    self._mlp_hidden_size = mlp_hidden_size\n",
        "    self._mlp_num_hidden_layers = mlp_num_hidden_layers\n",
        "    self._num_message_passing_steps = num_message_passing_steps\n",
        "    self._output_size = output_size\n",
        "    self._reducer = reducer\n",
        "\n",
        "    #with self._enter_variable_scope():\n",
        "    self._networks_builder()\n",
        "\n",
        "  def __call__(self, input_graph: gn.graphs.GraphsTuple) -> tf.Tensor:\n",
        "    \"\"\"Forward pass of the learnable dynamics model.\"\"\"\n",
        "\n",
        "    # Encode the input_graph.\n",
        "    latent_graph_0 = self._encode(input_graph)\n",
        "\n",
        "    # Do `m` message passing steps in the latent graphs.\n",
        "    latent_graph_m = self._process(latent_graph_0)\n",
        "\n",
        "    # Decode from the last latent graph.\n",
        "    return self._decode(latent_graph_m)\n",
        "\n",
        "  def _networks_builder(self):\n",
        "    \"\"\"Builds the networks.\"\"\"\n",
        "    def build_mlp_with_layer_norm():\n",
        "      mlp = build_mlp(\n",
        "          hidden_size=self._mlp_hidden_size,\n",
        "          num_hidden_layers=self._mlp_num_hidden_layers,\n",
        "          output_size=self._latent_size)\n",
        "      return snt.Sequential([mlp, snt.LayerNorm(axis=slice(1, None),create_scale=False,create_offset=False)])\n",
        "\n",
        "    # The encoder graph network independently encodes edge and node features.\n",
        "    encoder_kwargs = dict(\n",
        "        edge_model_fn=build_mlp_with_layer_norm,\n",
        "        node_model_fn=build_mlp_with_layer_norm)\n",
        "    self._encoder_network = gn.modules.GraphIndependent(**encoder_kwargs)\n",
        "    # Create `num_message_passing_steps` graph networks with unshared parameters\n",
        "    # that update the node and edge latent features.\n",
        "    # Note that we can use `modules.InteractionNetwork` because\n",
        "    # it also outputs the messages as updated edge latent features.\n",
        "    self._processor_networks = []\n",
        "    for _ in range(self._num_message_passing_steps):\n",
        "      self._processor_networks.append(\n",
        "          gn.modules.InteractionNetwork(\n",
        "              edge_model_fn=build_mlp_with_layer_norm,\n",
        "              node_model_fn=build_mlp_with_layer_norm,\n",
        "              reducer=self._reducer))\n",
        "    # The decoder MLP decodes node latent features into the output size.\n",
        "    self._decoder_network = build_mlp(\n",
        "        hidden_size=self._mlp_hidden_size,\n",
        "        num_hidden_layers=self._mlp_num_hidden_layers,\n",
        "        output_size=self._output_size)\n",
        "  def _encode(\n",
        "      self, input_graph: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n",
        "    \"\"\"Encodes the input graph features into a latent graph.\"\"\"\n",
        "\n",
        "    # Copy the globals to all of the nodes, if applicable.\n",
        "    if input_graph.globals is not None:\n",
        "      broadcasted_globals = gn.blocks.broadcast_globals_to_nodes(input_graph)\n",
        "      input_graph = input_graph.replace(\n",
        "          nodes=tf.concat([input_graph.nodes, broadcasted_globals], axis=-1),\n",
        "          globals=None)\n",
        "\n",
        "    # Encode the node and edge features.\n",
        "    latent_graph_0 = self._encoder_network(input_graph)\n",
        "    return latent_graph_0\n",
        "\n",
        "  def _process(\n",
        "      self, latent_graph_0: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n",
        "    \"\"\"Processes the latent graph with several steps of message passing.\"\"\"\n",
        "\n",
        "    # Do `m` message passing steps in the latent graphs.\n",
        "    # (In the shared parameters case, just reuse the same `processor_network`)\n",
        "    latent_graph_prev_k = latent_graph_0\n",
        "    latent_graph_k = latent_graph_0\n",
        "    for processor_network_k in self._processor_networks:\n",
        "      latent_graph_k = self._process_step(\n",
        "          processor_network_k, latent_graph_prev_k)\n",
        "      latent_graph_prev_k = latent_graph_k\n",
        "\n",
        "    latent_graph_m = latent_graph_k\n",
        "    return latent_graph_m\n",
        "\n",
        "  def _process_step(\n",
        "      self, processor_network_k: snt.Module,\n",
        "      latent_graph_prev_k: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n",
        "    \"\"\"Single step of message passing with node/edge residual connections.\"\"\"\n",
        "\n",
        "    # One step of message passing.\n",
        "    latent_graph_k = processor_network_k(latent_graph_prev_k)\n",
        "\n",
        "    # Add residuals.\n",
        "    latent_graph_k = latent_graph_k.replace(\n",
        "        nodes=latent_graph_k.nodes+latent_graph_prev_k.nodes,\n",
        "        edges=latent_graph_k.edges+latent_graph_prev_k.edges)\n",
        "    return latent_graph_k\n",
        "\n",
        "  def _decode(self, latent_graph: gn.graphs.GraphsTuple) -> tf.Tensor:\n",
        "    \"\"\"Decodes from the latent graph.\"\"\"\n",
        "    return self._decoder_network(latent_graph.nodes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnGLHy8zTbYo",
        "cellView": "form"
      },
      "source": [
        "#@title ### learned_simulator\n",
        "\n",
        "\n",
        "\n",
        "import graph_nets as gn\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# from learning_to_simulate import connectivity_utils\n",
        "# from learning_to_simulate import graph_network\n",
        "\n",
        "STD_EPSILON = 1e-8\n",
        "\n",
        "\n",
        "class LearnedSimulator(snt.Module):\n",
        "  \"\"\"Learned simulator from https://arxiv.org/pdf/2002.09405.pdf.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      num_dimensions,\n",
        "      connectivity_radius,\n",
        "      graph_network_kwargs,\n",
        "      boundaries,\n",
        "      normalization_stats,\n",
        "      num_particle_types,\n",
        "      particle_type_embedding_size,\n",
        "      name=\"LearnedSimulator\"):\n",
        "    \"\"\"Inits the model.\n",
        "    Args:\n",
        "      num_dimensions: Dimensionality of the problem.\n",
        "      connectivity_radius: Scalar with the radius of connectivity.\n",
        "      graph_network_kwargs: Keyword arguments to pass to the learned part\n",
        "        of the graph network `model.EncodeProcessDecode`.\n",
        "      boundaries: List of 2-tuples, containing the lower and upper boundaries of\n",
        "        the cuboid containing the particles along each dimensions, matching\n",
        "        the dimensionality of the problem.\n",
        "      normalization_stats: Dictionary with statistics with keys \"acceleration\"\n",
        "        and \"velocity\", containing a named tuple for each with mean and std\n",
        "        fields, matching the dimensionality of the problem.\n",
        "      num_particle_types: Number of different particle types.\n",
        "      particle_type_embedding_size: Embedding size for the particle type.\n",
        "      name: Name of the Sonnet module.\n",
        "    \"\"\"\n",
        "    super().__init__(name=name)\n",
        "\n",
        "    self._connectivity_radius = connectivity_radius\n",
        "    self._num_particle_types = num_particle_types\n",
        "    self._boundaries = boundaries\n",
        "    self._normalization_stats = normalization_stats\n",
        "    #with self._enter_variable_scope():\n",
        "    self._graph_network = EncodeProcessDecode(output_size=num_dimensions, **graph_network_kwargs)\n",
        "\n",
        "    if self._num_particle_types > 1:\n",
        "        self._particle_type_embedding = tf.compat.v1.get_variable(\n",
        "            \"particle_embedding\",\n",
        "            [self._num_particle_types, particle_type_embedding_size],\n",
        "            trainable=True, use_resource=True)\n",
        "\n",
        "  def __call__(self, position_sequence, n_particles_per_example,\n",
        "             global_context=None, particle_types=None):\n",
        "    \"\"\"Produces a model step, outputting the next position for each particle.\n",
        "    Args:\n",
        "      position_sequence: Sequence of positions for each node in the batch,\n",
        "        with shape [num_particles_in_batch, sequence_length, num_dimensions]\n",
        "      n_particles_per_example: Number of particles for each graph in the batch\n",
        "        with shape [batch_size]\n",
        "      global_context: Tensor of shape [batch_size, context_size], with global\n",
        "        context.\n",
        "      particle_types: Integer tensor of shape [num_particles_in_batch] with\n",
        "        the integer types of the particles, from 0 to `num_particle_types - 1`.\n",
        "        If None, we assume all particles are the same type.\n",
        "    Returns:\n",
        "      Next position with shape [num_particles_in_batch, num_dimensions] for one\n",
        "      step into the future from the input sequence.\n",
        "    \"\"\"\n",
        "    input_graphs_tuple = self._encoder_preprocessor(\n",
        "        position_sequence, n_particles_per_example, global_context,\n",
        "        particle_types)\n",
        "\n",
        "    normalized_acceleration = self._graph_network(input_graphs_tuple)\n",
        "\n",
        "    next_position = self._decoder_postprocessor(\n",
        "        normalized_acceleration, position_sequence)\n",
        "\n",
        "    return next_position\n",
        "\n",
        "  def _encoder_preprocessor(\n",
        "      self, position_sequence, n_node, global_context, particle_types):\n",
        "    # Extract important features from the position_sequence.\n",
        "    most_recent_position = position_sequence[:, -1]\n",
        "    velocity_sequence = time_diff(position_sequence)  # Finite-difference.\n",
        "\n",
        "    # Get connectivity of the graph.\n",
        "    (senders, receivers, n_edge\n",
        "     ) = connectivity_utils.compute_connectivity_for_batch_pyfunc(\n",
        "         most_recent_position, n_node, self._connectivity_radius)\n",
        "\n",
        "    # Collect node features.\n",
        "    node_features = []\n",
        "\n",
        "    # Normalized velocity sequence, merging spatial an time axis.\n",
        "    velocity_stats = self._normalization_stats[\"velocity\"]\n",
        "    normalized_velocity_sequence = (\n",
        "        velocity_sequence - velocity_stats.mean) / velocity_stats.std\n",
        "\n",
        "    flat_velocity_sequence = snt.Flatten()(\n",
        "        normalized_velocity_sequence)\n",
        "    node_features.append(flat_velocity_sequence)\n",
        "\n",
        "    # Normalized clipped distances to lower and upper boundaries.\n",
        "    # boundaries are an array of shape [num_dimensions, 2], where the second\n",
        "    # axis, provides the lower/upper boundaries.\n",
        "    boundaries = tf.constant(self._boundaries, dtype=tf.float32)\n",
        "    distance_to_lower_boundary = (\n",
        "        most_recent_position - tf.expand_dims(boundaries[:, 0], 0))\n",
        "    distance_to_upper_boundary = (\n",
        "        tf.expand_dims(boundaries[:, 1], 0) - most_recent_position)\n",
        "    distance_to_boundaries = tf.concat(\n",
        "        [distance_to_lower_boundary, distance_to_upper_boundary], axis=1)\n",
        "    normalized_clipped_distance_to_boundaries = tf.clip_by_value(\n",
        "        distance_to_boundaries / self._connectivity_radius, -1., 1.)\n",
        "    node_features.append(normalized_clipped_distance_to_boundaries)\n",
        "\n",
        "    # Particle type.\n",
        "    if self._num_particle_types > 1:\n",
        "      particle_type_embeddings = tf.nn.embedding_lookup(\n",
        "          self._particle_type_embedding, particle_types)\n",
        "      node_features.append(particle_type_embeddings)\n",
        "\n",
        "    # Collect edge features.\n",
        "    edge_features = []\n",
        "\n",
        "    # Relative displacement and distances normalized to radius\n",
        "    normalized_relative_displacements = (\n",
        "        tf.gather(most_recent_position, senders) -\n",
        "        tf.gather(most_recent_position, receivers)) / self._connectivity_radius\n",
        "    edge_features.append(normalized_relative_displacements)\n",
        "\n",
        "    normalized_relative_distances = tf.norm(\n",
        "        normalized_relative_displacements, axis=-1, keepdims=True)\n",
        "    edge_features.append(normalized_relative_distances)\n",
        "\n",
        "    # Normalize the global context.\n",
        "    if global_context is not None:\n",
        "      context_stats = self._normalization_stats[\"context\"]\n",
        "      # Context in some datasets are all zero, so add an epsilon for numerical\n",
        "      # stability.\n",
        "      global_context = (global_context - context_stats.mean) / tf.math.maximum(\n",
        "          context_stats.std, STD_EPSILON)\n",
        "\n",
        "    return gn.graphs.GraphsTuple(\n",
        "        nodes=tf.concat(node_features, axis=-1),\n",
        "        edges=tf.concat(edge_features, axis=-1),\n",
        "        globals=global_context,  # self._graph_net will appending this to nodes.\n",
        "        n_node=n_node,\n",
        "        n_edge=n_edge,\n",
        "        senders=senders,\n",
        "        receivers=receivers,\n",
        "        )\n",
        "\n",
        "  def _decoder_postprocessor(self, normalized_acceleration, position_sequence):\n",
        "\n",
        "    # The model produces the output in normalized space so we apply inverse\n",
        "    # normalization.\n",
        "    acceleration_stats = self._normalization_stats[\"acceleration\"]\n",
        "    acceleration = (\n",
        "        normalized_acceleration * acceleration_stats.std\n",
        "        ) + acceleration_stats.mean\n",
        "\n",
        "    # Use an Euler integrator to go from acceleration to position, assuming\n",
        "    # a dt=1 corresponding to the size of the finite difference.\n",
        "    most_recent_position = position_sequence[:, -1]\n",
        "    most_recent_velocity = most_recent_position - position_sequence[:, -2]\n",
        "\n",
        "    new_velocity = most_recent_velocity + acceleration  # * dt = 1\n",
        "    new_position = most_recent_position + new_velocity  # * dt = 1\n",
        "    return new_position\n",
        "\n",
        "  def get_predicted_and_target_normalized_accelerations(\n",
        "      self, next_position, position_sequence_noise, position_sequence,\n",
        "      n_particles_per_example, global_context=None, particle_types=None):  # pylint: disable=g-doc-args\n",
        "    \"\"\"Produces normalized and predicted acceleration targets.\n",
        "    Args:\n",
        "      next_position: Tensor of shape [num_particles_in_batch, num_dimensions]\n",
        "        with the positions the model should output given the inputs.\n",
        "      position_sequence_noise: Tensor of the same shape as `position_sequence`\n",
        "        with the noise to apply to each particle.\n",
        "      position_sequence, n_node, global_context, particle_types: Inputs to the\n",
        "        model as defined by `_build`.\n",
        "    Returns:\n",
        "      Tensors of shape [num_particles_in_batch, num_dimensions] with the\n",
        "        predicted and target normalized accelerations.\n",
        "    \"\"\"\n",
        "\n",
        "    # Add noise to the input position sequence.\n",
        "    noisy_position_sequence = position_sequence + position_sequence_noise\n",
        "\n",
        "    # Perform the forward pass with the noisy position sequence.\n",
        "    input_graphs_tuple = self._encoder_preprocessor(\n",
        "        noisy_position_sequence, n_particles_per_example, global_context,\n",
        "        particle_types)\n",
        "    predicted_normalized_acceleration = self._graph_network(input_graphs_tuple)\n",
        "\n",
        "    # Calculate the target acceleration, using an `adjusted_next_position `that\n",
        "    # is shifted by the noise in the last input position.\n",
        "    next_position_adjusted = next_position + position_sequence_noise[:, -1]\n",
        "    target_normalized_acceleration = self._inverse_decoder_postprocessor(\n",
        "        next_position_adjusted, noisy_position_sequence)\n",
        "    # As a result the inverted Euler update in the `_inverse_decoder` produces:\n",
        "    # * A target acceleration that does not explicitly correct for the noise in\n",
        "    #   the input positions, as the `next_position_adjusted` is different\n",
        "    #   from the true `next_position`.\n",
        "    # * A target acceleration that exactly corrects noise in the input velocity\n",
        "    #   since the target next velocity calculated by the inverse Euler update\n",
        "    #   as `next_position_adjusted - noisy_position_sequence[:,-1]`\n",
        "    #   matches the ground truth next velocity (noise cancels out).\n",
        "\n",
        "    return predicted_normalized_acceleration, target_normalized_acceleration\n",
        "\n",
        "  def _inverse_decoder_postprocessor(self, next_position, position_sequence):\n",
        "    \"\"\"Inverse of `_decoder_postprocessor`.\"\"\"\n",
        "\n",
        "    previous_position = position_sequence[:, -1]\n",
        "    previous_velocity = previous_position - position_sequence[:, -2]\n",
        "    next_velocity = next_position - previous_position\n",
        "    acceleration = next_velocity - previous_velocity\n",
        "\n",
        "    acceleration_stats = self._normalization_stats[\"acceleration\"]\n",
        "    normalized_acceleration = (\n",
        "        acceleration - acceleration_stats.mean) / acceleration_stats.std\n",
        "    return normalized_acceleration\n",
        "\n",
        "\n",
        "def time_diff(input_sequence):\n",
        "  return input_sequence[:, 1:] - input_sequence[:, :-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ntN9CfJTROC",
        "cellView": "form"
      },
      "source": [
        "#@title ### noise_utils\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def get_random_walk_noise_for_position_sequence(\n",
        "    position_sequence, noise_std_last_step):\n",
        "  \"\"\"Returns random-walk noise in the velocity applied to the position.\"\"\"\n",
        "\n",
        "  velocity_sequence = learned_simulator.time_diff(position_sequence)\n",
        "\n",
        "  # We want the noise scale in the velocity at the last step to be fixed.\n",
        "  # Because we are going to compose noise at each step using a random_walk:\n",
        "  # std_last_step**2 = num_velocities * std_each_step**2\n",
        "  # so to keep `std_last_step` fixed, we apply at each step:\n",
        "  # std_each_step `std_last_step / np.sqrt(num_input_velocities)`\n",
        "  # TODO(alvarosg): Make sure this is consistent with the value and\n",
        "  # description provided in the paper.\n",
        "  num_velocities = velocity_sequence.shape.as_list()[1]\n",
        "  velocity_sequence_noise = tf.random.normal(\n",
        "      tf.shape(velocity_sequence),\n",
        "      stddev=noise_std_last_step / num_velocities ** 0.5,\n",
        "      dtype=position_sequence.dtype)\n",
        "\n",
        "  # Apply the random walk.\n",
        "  velocity_sequence_noise = tf.cumsum(velocity_sequence_noise, axis=1)\n",
        "\n",
        "  # Integrate the noise in the velocity to the positions, assuming\n",
        "  # an Euler intergrator and a dt = 1, and adding no noise to the very first\n",
        "  # position (since that will only be used to calculate the first position\n",
        "  # change).\n",
        "  position_sequence_noise = tf.concat([\n",
        "      tf.zeros_like(velocity_sequence_noise[:, 0:1]),\n",
        "      tf.cumsum(velocity_sequence_noise, axis=1)], axis=1)\n",
        "\n",
        "  return position_sequence_noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKnr3tQGX7pv",
        "cellView": "form"
      },
      "source": [
        "#@title ### reading_utils\n",
        "\n",
        "import functools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a description of the features.\n",
        "_FEATURE_DESCRIPTION = {\n",
        "    'pos': tf.io.VarLenFeature(tf.string),\n",
        "}\n",
        "\n",
        "_FEATURE_DESCRIPTION_WITH_GLOBAL_CONTEXT = _FEATURE_DESCRIPTION.copy()\n",
        "_FEATURE_DESCRIPTION_WITH_GLOBAL_CONTEXT['step_context'] = tf.io.VarLenFeature(\n",
        "    tf.string)\n",
        "\n",
        "_FEATURE_DTYPES = {\n",
        "    'pos': {\n",
        "        'in': np.float32,\n",
        "        'out': tf.float32\n",
        "    },\n",
        "    'step_context': {\n",
        "        'in': np.float32,\n",
        "        'out': tf.float32\n",
        "    }\n",
        "}\n",
        "\n",
        "_CONTEXT_FEATURES = {\n",
        "    'key': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    'particle_type': tf.io.VarLenFeature(tf.string)\n",
        "}\n",
        "\n",
        "\n",
        "def convert_to_tensor(x, encoded_dtype):\n",
        "  if len(x) == 1:\n",
        "    out = np.frombuffer(x[0].numpy(), dtype=encoded_dtype)\n",
        "  else:\n",
        "    out = []\n",
        "    for el in x:\n",
        "      out.append(np.frombuffer(el.numpy(), dtype=encoded_dtype))\n",
        "  out = tf.convert_to_tensor(np.array(out))\n",
        "  return out\n",
        "\n",
        "\n",
        "def parse_serialized_simulation_example(example_proto, metadata):\n",
        "  \"\"\"Parses a serialized simulation tf.SequenceExample.\n",
        "  Args:\n",
        "    example_proto: A string encoding of the tf.SequenceExample proto.\n",
        "    metadata: A dict of metadata for the dataset.\n",
        "  Returns:\n",
        "    context: A dict, with features that do not vary over the trajectory.\n",
        "    parsed_features: A dict of tf.Tensors representing the parsed examples\n",
        "      across time, where axis zero is the time axis.\n",
        "  \"\"\"\n",
        "  if 'context_mean' in metadata:\n",
        "    feature_description = _FEATURE_DESCRIPTION_WITH_GLOBAL_CONTEXT\n",
        "  else:\n",
        "    feature_description = _FEATURE_DESCRIPTION\n",
        "  context, parsed_features = tf.io.parse_single_sequence_example(\n",
        "      example_proto,\n",
        "      context_features=_CONTEXT_FEATURES,\n",
        "      sequence_features=feature_description)\n",
        "  for feature_key, item in parsed_features.items():\n",
        "    convert_fn = functools.partial(\n",
        "        convert_to_tensor, encoded_dtype=_FEATURE_DTYPES[feature_key]['in'])\n",
        "    parsed_features[feature_key] = tf.py_function(\n",
        "        convert_fn, inp=[item.values], Tout=_FEATURE_DTYPES[feature_key]['out'])\n",
        "\n",
        "  # There is an extra frame at the beginning so we can calculate pos change\n",
        "  # for all frames used in the paper.\n",
        "  position_shape = [metadata['sequence_length'] + 1, -1, metadata['dim']]\n",
        "\n",
        "  # Reshape positions to correct dim:\n",
        "  parsed_features['pos'] = tf.reshape(parsed_features['pos'],\n",
        "                                           position_shape)\n",
        "  # Set correct shapes of the remaining tensors.\n",
        "  sequence_length = metadata['sequence_length'] + 1\n",
        "  if 'context_mean' in metadata:\n",
        "    context_feat_len = len(metadata['context_mean'])\n",
        "    parsed_features['step_context'] = tf.reshape(\n",
        "        parsed_features['step_context'],\n",
        "        [sequence_length, context_feat_len])\n",
        "  # Decode particle type explicitly\n",
        "  context['particle_type'] = tf.py_function(\n",
        "      functools.partial(convert_fn, encoded_dtype=np.int64),\n",
        "      inp=[context['particle_type'].values],\n",
        "      Tout=[tf.int64])\n",
        "  context['particle_type'] = tf.reshape(context['particle_type'], [-1])\n",
        "  return context, parsed_features\n",
        "\n",
        "\n",
        "def split_trajectory(context, features, window_length=7):\n",
        "  \"\"\"Splits trajectory into sliding windows.\"\"\"\n",
        "  # Our strategy is to make sure all the leading dimensions are the same size,\n",
        "  # then we can use from_tensor_slices.\n",
        "\n",
        "  trajectory_length = features['pos'].get_shape().as_list()[0]\n",
        "\n",
        "  # We then stack window_length position changes so the final\n",
        "  # trajectory length will be - window_length +1 (the 1 to make sure we get\n",
        "  # the last split).\n",
        "  input_trajectory_length = trajectory_length - window_length + 1\n",
        "\n",
        "  model_input_features = {}\n",
        "  # Prepare the context features per step.\n",
        "  model_input_features['particle_type'] = tf.tile(\n",
        "      tf.expand_dims(context['particle_type'], axis=0),\n",
        "      [input_trajectory_length, 1])\n",
        "\n",
        "  if 'step_context' in features:\n",
        "    global_stack = []\n",
        "    for idx in range(input_trajectory_length):\n",
        "      global_stack.append(features['step_context'][idx:idx + window_length])\n",
        "    model_input_features['step_context'] = tf.stack(global_stack)\n",
        "\n",
        "  pos_stack = []\n",
        "  for idx in range(input_trajectory_length):\n",
        "    pos_stack.append(features['pos'][idx:idx + window_length])\n",
        "  # Get the corresponding positions\n",
        "  model_input_features['pos'] = tf.stack(pos_stack)\n",
        "\n",
        "  return tf.data.Dataset.from_tensor_slices(model_input_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahdNW0xyGqxy",
        "cellView": "form"
      },
      "source": [
        "#@title ### Zonal Model\n",
        "\n",
        "import numpy as np\n",
        "from math import *\n",
        "import sys\n",
        "import random\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "def get_record(group_id,timestep,parameter_vector,pos,vel):\n",
        "    feature = { 'group_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[group_id])),\n",
        "                'timestep': tf.train.Feature(int64_list=tf.train.Int64List(value=[timestep])),\n",
        "                'parameter_vector': tf.train.Feature(float_list=tf.train.FloatList(value=parameter_vector)),\n",
        "                'pos': tf.train.Feature(bytes_list=tf.train.BytesList(value=[pos.numpy()])),\n",
        "                'vel': tf.train.Feature(bytes_list=tf.train.BytesList(value=[vel.numpy()]))\n",
        "                }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "class zonal_model:\n",
        "    def __init__(self, N, timesteps, discard, repeat, L, dt, save_interval,train_directory='train_datasets', valid_directory='valid_datasets', disable_progress=False):\n",
        "        self.N = N\n",
        "        self.timesteps = timesteps\n",
        "        self.discard = discard\n",
        "        self.B = repeat  # repeat for B batches\n",
        "        self.L = L\n",
        "        self.dt = dt\n",
        "        self.save_interval = save_interval\n",
        "        \n",
        "        self.micro_state = np.zeros((self.B, (self.timesteps - self.discard)//self.save_interval, N, 4))\n",
        "\n",
        "        self.sim_counter=0\n",
        "\n",
        "        if not os.path.exists(train_directory):\n",
        "            os.makedirs(train_directory)\n",
        "\n",
        "        if not os.path.exists(valid_directory):\n",
        "            os.makedirs(valid_directory)\n",
        "\n",
        "        self.train_directory = train_directory\n",
        "        self.valid_directory = valid_directory\n",
        "\n",
        "        # turn progress bar on or off\n",
        "        self.disable_progress = disable_progress\n",
        "\n",
        "        self.valid_fraction = 0.1\n",
        "        \n",
        "    def initialise_state(self):\n",
        "\n",
        "        self.positions = tf.random.uniform((self.B,self.N,2),0.5*self.L, 0.5*self.L+20) #0,self.L)\n",
        "        #self.positions = tf.random.uniform((self.B,self.N,2),0, self.L) \n",
        "        self.angles = tf.random.uniform((self.B,self.N,1), 0, 2*pi) #\n",
        "        \n",
        "\n",
        "\n",
        "    def run_sim(self, *params):\n",
        "\n",
        "        eta, Ra, Ro, Rr, vs, va, sigma = params\n",
        "        \n",
        "        record_file = self.train_directory + '/microstates-' + str(self.sim_counter) + '.tfrecords'\n",
        "        self.writer = tf.io.TFRecordWriter(record_file) \n",
        "        \n",
        "        valid_file = self.valid_directory + '/microstates-' + str(self.sim_counter) + '.tfrecords'\n",
        "        self.validwriter = tf.io.TFRecordWriter(valid_file) \n",
        "        \n",
        "        # tensorflow function to run an update step\n",
        "        @tf.function\n",
        "        def update_tf(X, A):\n",
        "            cos_A = tf.math.cos(A)\n",
        "            sin_A = tf.math.sin(A)\n",
        "\n",
        "\n",
        "            Xx = tf.expand_dims(X[...,0],-1)\n",
        "            dx = -Xx + tf.linalg.matrix_transpose(Xx)\n",
        "            dx = tf.where(dx>0.5*self.L, dx-self.L, dx)\n",
        "            dx = tf.where(dx<-0.5*self.L, dx+self.L, dx)\n",
        "\n",
        "            Xy = tf.expand_dims(X[...,1],-1)\n",
        "            dy = -Xy + tf.linalg.matrix_transpose(Xy)\n",
        "            dy = tf.where(dy>0.5*self.L, dy-self.L, dy)\n",
        "            dy = tf.where(dy<-0.5*self.L, dy+self.L, dy)\n",
        "\n",
        "\n",
        "            angle_to_neigh = tf.math.atan2(dy, dx)\n",
        "            cos_N = tf.math.cos(angle_to_neigh)\n",
        "            sin_N = tf.math.sin(angle_to_neigh)\n",
        "            rel_angle_to_neigh = angle_to_neigh - A\n",
        "            rel_angle_to_neigh = tf.math.atan2(tf.math.sin(rel_angle_to_neigh), tf.math.cos(rel_angle_to_neigh))\n",
        "            \n",
        "            dist = tf.math.sqrt(tf.square(dx)+tf.square(dy))\n",
        "    \n",
        "            # repulsion \n",
        "            rep_x = tf.where(dist<=Rr, -dx, tf.zeros_like(dx))\n",
        "            rep_x = tf.where(rel_angle_to_neigh<0.5*va, rep_x, tf.zeros_like(rep_x))\n",
        "            rep_x = tf.where(rel_angle_to_neigh>-0.5*va, rep_x, tf.zeros_like(rep_x))\n",
        "            rep_x = tf.math.divide_no_nan(rep_x,tf.math.square(dist))\n",
        "            rep_x = tf.reduce_sum(rep_x,axis=2)\n",
        "\n",
        "            rep_y = tf.where(dist<=Rr, -dy, tf.zeros_like(dy))\n",
        "            rep_y = tf.where(rel_angle_to_neigh<0.5*va, rep_y, tf.zeros_like(rep_y))\n",
        "            rep_y = tf.where(rel_angle_to_neigh>-0.5*va, rep_y, tf.zeros_like(rep_y))\n",
        "            rep_y = tf.math.divide_no_nan(rep_y,tf.math.square(dist))\n",
        "            rep_y = tf.reduce_sum(rep_y,axis=2)\n",
        "\n",
        "            # alignment \n",
        "            align_x = tf.where(dist<=Ro, cos_A, tf.zeros_like(cos_A))\n",
        "            align_x = tf.where(rel_angle_to_neigh<0.5*va, align_x, tf.zeros_like(align_x))\n",
        "            align_x = tf.where(rel_angle_to_neigh>-0.5*va, align_x, tf.zeros_like(align_x))\n",
        "            align_x = tf.reduce_sum(align_x,axis=1)\n",
        "            \n",
        "            align_y = tf.where(dist<=Ro, sin_A, tf.zeros_like(sin_A))\n",
        "            align_y = tf.where(rel_angle_to_neigh<0.5*va, align_y, tf.zeros_like(align_y))\n",
        "            align_y = tf.where(rel_angle_to_neigh>-0.5*va, align_y, tf.zeros_like(align_y))\n",
        "            align_y = tf.reduce_sum(align_y,axis=1)\n",
        "\n",
        "            al_norm = tf.math.sqrt(align_x**2+align_y**2)\n",
        "            align_x = tf.math.divide_no_nan(align_x,al_norm)\n",
        "            align_y = tf.math.divide_no_nan(align_y,al_norm)\n",
        "\n",
        "            # attractive interactions\n",
        "            attr_x = tf.where(dist<=Ra, dx, tf.zeros_like(dx))\n",
        "            attr_x = tf.where(rel_angle_to_neigh<0.5*va, attr_x, tf.zeros_like(attr_x))\n",
        "            attr_x = tf.where(rel_angle_to_neigh>-0.5*va, attr_x, tf.zeros_like(attr_x))\n",
        "            attr_x = tf.reduce_sum(attr_x,axis=2)\n",
        "\n",
        "            attr_y = tf.where(dist<=Ra, dy, tf.zeros_like(dy))\n",
        "            attr_y = tf.where(rel_angle_to_neigh<0.5*va, attr_y, tf.zeros_like(attr_y))\n",
        "            attr_y = tf.where(rel_angle_to_neigh>-0.5*va, attr_y, tf.zeros_like(attr_y))\n",
        "            attr_y = tf.reduce_sum(attr_y,axis=2)\n",
        "\n",
        "            at_norm = tf.math.sqrt(attr_x**2+attr_y**2)\n",
        "            attr_x = tf.math.divide_no_nan(attr_x,at_norm)\n",
        "            attr_y = tf.math.divide_no_nan(attr_y,at_norm)\n",
        "\n",
        "            # combine angles and convert to desired angle change\n",
        "            social_x = rep_x + align_x + attr_x\n",
        "            social_y = rep_y + align_y + attr_y\n",
        "\n",
        "            d_angle = tf.math.atan2(social_y,social_x)\n",
        "            d_angle = tf.expand_dims(d_angle,-1)\n",
        "\n",
        "            \n",
        "            d_angle = tf.math.atan2((1-eta)*tf.math.sin(d_angle) + eta*sin_A, (1-eta)*tf.math.cos(d_angle) + eta*cos_A)\n",
        "\n",
        "            d_angle = d_angle - A\n",
        "            d_angle = tf.where(d_angle>pi, d_angle-2*pi, d_angle)\n",
        "            d_angle = tf.where(d_angle<-pi, d_angle+2*pi, d_angle)\n",
        "\n",
        "\n",
        "            # add perception noise\n",
        "            noise = tf.random.normal(shape=(self.B,self.N,1),mean=0,stddev=sigma*(self.dt**0.5))\n",
        "            d_angle = d_angle + noise\n",
        "            \n",
        "            # restrict to maximum turning angle\n",
        "            #d_angle = tf.where(tf.math.abs(d_angle)>eta*self.dt, tf.math.sign(d_angle)*eta*self.dt, d_angle)\n",
        "            \n",
        "            # rotate headings\n",
        "            A = A + d_angle\n",
        "            \n",
        "            # update positions\n",
        "            velocity = self.dt*vs*tf.concat([tf.cos(A),tf.sin(A)],axis=-1)\n",
        "            X += velocity\n",
        "\n",
        "            # add periodic boundary conditions\n",
        "            A = tf.where(A<-pi,  A+2*pi, A)\n",
        "            A = tf.where(A>pi, A-2*pi, A)\n",
        "\n",
        "            X = tf.where(X>self.L, X-self.L, X)\n",
        "            X = tf.where(X<0, X+self.L, X)\n",
        "\n",
        "            X = tf.where(X>self.L, X-self.L, X)\n",
        "            X = tf.where(X<0, X+self.L, X)\n",
        "\n",
        "            return X, A\n",
        "            \n",
        "        self.initialise_state()\n",
        "\n",
        "        counter=0\n",
        "        for i in tqdm(range(self.timesteps),disable=self.disable_progress):\n",
        "            self.positions, self.angles = update_tf(self.positions,  self.angles)\n",
        "            if i>=self.discard:\n",
        "                if i%self.save_interval==0:\n",
        "                    # store in an array in case we want to visualise\n",
        "                    self.micro_state[:,counter,:,0:2] = self.positions.numpy()\n",
        "                    self.micro_state[:,counter,:,2:3] = np.cos(self.angles.numpy())\n",
        "                    self.micro_state[:,counter,:,3:4] = np.sin(self.angles.numpy())\n",
        "                        \n",
        "                    counter = counter + 1\n",
        "                    self.save_tf_record(counter, params)\n",
        "\n",
        "        self.writer.close()\n",
        "        self.sim_counter+=1\n",
        "        return \n",
        "\n",
        "    def save_tf_record(self, counter, params):\n",
        "\n",
        "        A = self.angles\n",
        "\n",
        "        cos_A = tf.math.cos(A)\n",
        "        sin_A = tf.math.sin(A)\n",
        "\n",
        "        velocities = tf.concat([cos_A,sin_A],axis=-1)\n",
        "\n",
        "        for b in range(self.B):\n",
        "            pos =  tf.io.serialize_tensor(self.positions[b])\n",
        "            vel =  tf.io.serialize_tensor(velocities[b])\n",
        "\n",
        "            tf_record = get_record(b,counter,params,pos,vel)\n",
        "            if b> self.B*self.valid_fraction:\n",
        "                self.writer.write(tf_record.SerializeToString())\n",
        "            else:\n",
        "                self.validwriter.write(tf_record.SerializeToString())\n",
        "\n",
        "        \n",
        "        return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky-wfGjmHoLp",
        "cellView": "form",
        "outputId": "b0209b2b-db24-4efc-c553-f8b417ae3b19"
      },
      "source": [
        "#@title ### Create Training Data\n",
        "\n",
        "n_points=50 #10\n",
        "\n",
        "param_values = np.linspace(0,25,n_points)\n",
        "L= 200\n",
        "N= 100 \n",
        "repeat = 100\n",
        "discard = 500\n",
        "timesteps = 500\n",
        "save_interval=100 \n",
        "dt=0.1 \n",
        "\n",
        "\n",
        "sim = zonal_model(N,timesteps=timesteps+discard,discard=discard,L=L,repeat=repeat, dt=dt,save_interval=save_interval,disable_progress=True)\n",
        "\n",
        "latt=0  # adapt\n",
        "lrep= 1 # adapt\n",
        "lali= 5 # adapt\n",
        "eta=0.9 # adapt\n",
        "va=2*pi # adapt\n",
        "vs=5 # fix \n",
        "sigma=0.1 \n",
        "\n",
        "def evaluate_zonal_model(X):\n",
        "    sim.run_sim(eta, latt, X, lrep, vs, va, sigma)\n",
        "    return\n",
        "\n",
        "for i in tqdm(range(param_values.shape[0])):\n",
        "    evaluate_zonal_model(param_values[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [04:16<00:00,  5.13s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFgDdkQqT4bQ",
        "cellView": "form"
      },
      "source": [
        "#@title ### Preprocessing\n",
        "\n",
        "train_dir = 'train_datasets/'\n",
        "valid_dir = 'valid_datasets/'\n",
        "\n",
        "feature_description = {'group_id': tf.io.FixedLenFeature([], tf.int64),\n",
        "                        'timestep': tf.io.FixedLenFeature([], tf.int64),\n",
        "                        'parameter_vector': tf.io.FixedLenSequenceFeature([], tf.float32,allow_missing=True),\n",
        "                        'pos': tf.io.FixedLenFeature([], tf.string),\n",
        "                        'vel': tf.io.FixedLenFeature([], tf.string)}\n",
        "\n",
        "def _parse_record(x):\n",
        "  # Parse the input tf.train.Example proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(x, feature_description)\n",
        "\n",
        "def _parse_tensor(x):\n",
        "    output = {'group_id': x['group_id'],\n",
        "                'timestep': x['timestep'],\n",
        "                'parameter_vector': x['parameter_vector'],\n",
        "                'pos': tf.io.parse_tensor(x['pos'],out_type=tf.float32),\n",
        "                'vel': tf.io.parse_tensor(x['vel'],out_type=tf.float32)}\n",
        "    return output\n",
        "\n",
        "train_dataset =  tf.data.TFRecordDataset(tf.data.Dataset.list_files([train_dir + filename for filename in os.listdir(train_dir)]))\n",
        "\n",
        "parsed_train_dataset = train_dataset.map(_parse_record)\n",
        "parsed_train_dataset = parsed_train_dataset.map(_parse_tensor)\n",
        "parsed_train_dataset = parsed_train_dataset.shuffle(10000, reshuffle_each_iteration=True)\n",
        "parsed_train_dataset = parsed_train_dataset.batch(32, drop_remainder=True)\n",
        "\n",
        "\n",
        "\n",
        "valid_dataset =  tf.data.TFRecordDataset(tf.data.Dataset.list_files([valid_dir + filename for filename in os.listdir(valid_dir)]))\n",
        "\n",
        "parsed_valid_dataset = valid_dataset.map(_parse_record)\n",
        "parsed_valid_dataset = parsed_valid_dataset.map(_parse_tensor)\n",
        "parsed_valid_dataset = parsed_valid_dataset.shuffle(10000, reshuffle_each_iteration=True)\n",
        "parsed_valid_dataset = parsed_valid_dataset.batch(4, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzgGNFysMx35",
        "cellView": "form"
      },
      "source": [
        "#@title ### Preprocessing function\n",
        "\n",
        "interaction_radius = 15.0\n",
        "L = 200\n",
        "def preprocess_data(databatch):\n",
        "    \n",
        "    # node features xpos, ypos, xvel, yvel\n",
        "    # edge features distance, rel angle to receiver\n",
        "    X = databatch['pos']\n",
        "    V = databatch['vel']\n",
        "    \n",
        "    Xx = tf.expand_dims(X[...,0],-1)\n",
        "    dx = -Xx + tf.linalg.matrix_transpose(Xx)\n",
        "    dx = tf.where(dx>0.5*L, dx-L, dx)\n",
        "    dx = tf.where(dx<-0.5*L, dx+L, dx)\n",
        "\n",
        "    Xy = tf.expand_dims(X[...,1],-1)\n",
        "    dy = -Xy + tf.linalg.matrix_transpose(Xy)\n",
        "    dy = tf.where(dy>0.5*L, dy-L, dy)\n",
        "    dy = tf.where(dy<-0.5*L, dy+L, dy)\n",
        "\n",
        "\n",
        "\n",
        "    A = tf.expand_dims(tf.math.atan2(V[...,1],V[...,0]),-1)\n",
        "    angle_to_neigh = tf.math.atan2(dy, dx)\n",
        "\n",
        "    rel_angle_to_neigh = angle_to_neigh - A\n",
        "\n",
        "    dist = tf.math.sqrt(tf.square(dx)+tf.square(dy))\n",
        "\n",
        "    adj_matrix = tf.where(dist<interaction_radius, tf.ones_like(dist,dtype=tf.int32), tf.zeros_like(dist,dtype=tf.int32))\n",
        "    adj_matrix = tf.linalg.set_diag(adj_matrix, tf.zeros(tf.shape(adj_matrix)[:2],dtype=tf.int32))\n",
        "    sender_recv_list = tf.where(adj_matrix)\n",
        "    n_edge = tf.reduce_sum(adj_matrix, axis=[1,2])\n",
        "    n_node = tf.ones_like(n_edge)*tf.shape(adj_matrix)[-1]\n",
        "\n",
        "    senders = sender_recv_list[:,1] + sender_recv_list[:,0]*tf.shape(adj_matrix,out_type=tf.int64)[-1]\n",
        "    receivers = sender_recv_list[:,2] + sender_recv_list[:,0]*tf.shape(adj_matrix,out_type=tf.int64)[-1]\n",
        "\n",
        "\n",
        "    edge_distance = tf.expand_dims(tf.gather_nd(dist,sender_recv_list),-1)\n",
        "    edge_x_distance =  tf.expand_dims(tf.gather_nd(tf.math.cos(rel_angle_to_neigh),sender_recv_list),-1)  # relative to sender heading\n",
        "    edge_y_distance =  tf.expand_dims( tf.gather_nd(tf.math.sin(rel_angle_to_neigh),sender_recv_list),-1)  # relative to sender heading\n",
        "\n",
        "\n",
        "    edges = tf.concat([edge_distance,edge_x_distance,edge_y_distance],axis=-1)\n",
        "\n",
        "    node_positions = tf.reshape(X,(-1,2))\n",
        "    node_velocities = tf.reshape(V,(-1,2))\n",
        "\n",
        "    nodes = tf.concat([node_positions,node_velocities],axis=-1)\n",
        "\n",
        "    gn = graphs.GraphsTuple(nodes=nodes,edges=edges,globals=None,receivers=receivers,senders=senders,n_node=n_node,n_edge=n_edge)\n",
        "    gn = utils_tf.set_zero_global_features(gn,1)\n",
        "    \n",
        "    return gn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbMPiqZENpAe",
        "cellView": "form"
      },
      "source": [
        "#@title ### More Functions\n",
        "\n",
        "INPUT_SEQUENCE_LENGTH = 6  # So we can calculate the last 5 velocities.\n",
        "NUM_PARTICLE_TYPES = 9\n",
        "KINEMATIC_PARTICLE_ID = 3\n",
        "\n",
        "batch_size=2\n",
        "\n",
        "def _read_metadata(data_path):\n",
        "    with open(os.path.join(data_path, 'metadata.json'), 'rt') as fp:\n",
        "        return json.loads(fp.read())\n",
        "\n",
        "def prepare_inputs(tensor_dict):\n",
        "  \"\"\"Prepares a single stack of inputs by calculating inputs and targets.\n",
        "\n",
        "  Computes n_particles_per_example, which is a tensor that contains information\n",
        "  about how to partition the axis - i.e. which nodes belong to which graph.\n",
        "\n",
        "  Adds a batch axis to `n_particles_per_example` and `step_context` so they can\n",
        "  later be batched using `batch_concat`. This batch will be the same as if the\n",
        "  elements had been batched via stacking.\n",
        "\n",
        "  Note that all other tensors have a variable size particle axis,\n",
        "  and in this case they will simply be concatenated along that\n",
        "  axis.\n",
        "\n",
        "\n",
        "\n",
        "  Args:\n",
        "    tensor_dict: A dict of tensors containing positions, and step context (\n",
        "    if available).\n",
        "\n",
        "  Returns:\n",
        "    A tuple of input features and target positions.\n",
        "\n",
        "  \"\"\"\n",
        "  # Position is encoded as [sequence_length, num_particles, dim] but the model\n",
        "  # expects [num_particles, sequence_length, dim].\n",
        "  pos = tensor_dict['pos']\n",
        "  print(tf.shape(pos))\n",
        "  pos = tf.transpose(pos, perm=[1, 0, 2])\n",
        "\n",
        "  # The target position is the final step of the stack of positions.\n",
        "  target_position = pos[:, -1]\n",
        "\n",
        "  # Remove the target from the input.\n",
        "  tensor_dict['pos'] = pos[:, :-1]\n",
        "\n",
        "  # Compute the number of particles per example.\n",
        "  num_particles = tf.shape(pos)[0]\n",
        "  # Add an extra dimension for stacking via concat.\n",
        "  tensor_dict['n_particles_per_example'] = num_particles[tf.newaxis]\n",
        "\n",
        "  if 'step_context' in tensor_dict:\n",
        "    # Take the input global context. We have a stack of global contexts,\n",
        "    # and we take the penultimate since the final is the target.\n",
        "    tensor_dict['step_context'] = tensor_dict['step_context'][-2]\n",
        "    # Add an extra dimension for stacking via concat.\n",
        "    tensor_dict['step_context'] = tensor_dict['step_context'][tf.newaxis]\n",
        "  return tensor_dict, target_position\n",
        "\n",
        "def batch_concat(dataset, batch_size):\n",
        "  \"\"\"We implement batching as concatenating on the leading axis.\"\"\"\n",
        "\n",
        "  # We create a dataset of datasets of length batch_size.\n",
        "  windowed_ds = dataset.window(batch_size)\n",
        "\n",
        "  # The plan is then to reduce every nested dataset by concatenating. We can\n",
        "  # do this using tf.data.Dataset.reduce. This requires an initial state, and\n",
        "  # then incrementally reduces by running through the dataset\n",
        "\n",
        "  # Get initial state. In this case this will be empty tensors of the\n",
        "  # correct shape.\n",
        "  initial_state = tree.map_structure(\n",
        "      lambda spec: tf.zeros(  # pylint: disable=g-long-lambda\n",
        "          shape=[0] + spec.shape.as_list()[1:], dtype=spec.dtype),\n",
        "      dataset.element_spec)\n",
        "\n",
        "  # We run through the nest and concatenate each entry with the previous state.\n",
        "  def reduce_window(initial_state, ds):\n",
        "    return ds.reduce(initial_state, lambda x, y: tf.concat([x, y], axis=0))\n",
        "\n",
        "  return windowed_ds.map(\n",
        "      lambda *x: tree.map_structure(reduce_window, initial_state, x))\n",
        "\n",
        "\n",
        "def prepare_rollout_inputs(context, features):\n",
        "  \"\"\"Prepares an inputs trajectory for rollout.\"\"\"\n",
        "  out_dict = {**context}\n",
        "  # Position is encoded as [sequence_length, num_particles, dim] but the model\n",
        "  # expects [num_particles, sequence_length, dim].\n",
        "  print(2)\n",
        "  pos = tf.transpose(features['pos'], [1, 0, 2])\n",
        "  # The target position is the final step of the stack of positions.\n",
        "  target_position = pos[:, -1]\n",
        "  # Remove the target from the input.\n",
        "  out_dict['pos'] = pos[:, :-1]\n",
        "  # Compute the number of nodes\n",
        "  out_dict['n_particles_per_example'] = [tf.shape(pos)[0]]\n",
        "  if 'step_context' in features:\n",
        "    out_dict['step_context'] = features['step_context']\n",
        "  out_dict['is_trajectory'] = tf.constant([True], tf.bool)\n",
        "  return out_dict, target_position"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgUJ3nUEOVfs",
        "cellView": "form",
        "outputId": "68c50659-ca75-4808-df04-136697befb01"
      },
      "source": [
        "#@title ### Create Dataset\n",
        "\n",
        "import collections\n",
        "import functools\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import tree\n",
        "\n",
        "data_path = '/content/'\n",
        "\n",
        "\"\"\"\n",
        "What metadata do we need?\n",
        "-sequence length\n",
        "-dim\n",
        "\"\"\"\n",
        "\n",
        "#Experiment metadata dict\n",
        "metadata = {\"sequence_length\": 7,\n",
        "            \"dim\": 2,\n",
        "            \"acc_mean\": 1,\n",
        "            \"acc_std\": 1,\n",
        "            \"vel_mean\": 1,\n",
        "            \"vel_std\": 1,\n",
        "            \"default_connectivity_radius\": 1,\n",
        "            \"bounds\": 1\n",
        "            }\n",
        "\n",
        "\"\"\"\n",
        "# Loads the metadata of the dataset.\n",
        "metadata = _read_metadata(data_path)\n",
        "\"\"\"\n",
        "\n",
        "#Create a tf.data.Dataset from the TFRecord.\n",
        "ds = tf.data.TFRecordDataset([os.path.join(data_path, 'train_datasets')])\n",
        "ds = ds.map(functools.partial(parse_serialized_simulation_example, metadata=metadata))\n",
        "\n",
        "# Splits an entire trajectory into chunks of 7 steps.\n",
        "# Previous 5 velocities, current velocity and target.\n",
        "split_with_window = functools.partial(\n",
        "    split_trajectory,\n",
        "    window_length=INPUT_SEQUENCE_LENGTH + 1)\n",
        "ds = ds.flat_map(split_with_window)\n",
        "\n",
        "# Splits a chunk into input steps and target steps\n",
        "ds = ds.map(prepare_inputs)\n",
        "# If in train mode, repeat dataset forever and shuffle.\n",
        "ds = ds.repeat()\n",
        "ds = ds.shuffle(512)\n",
        "# Custom batching on the leading axis.\n",
        "ds = batch_concat(ds, batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUe5GAlNCD2X",
        "cellView": "form"
      },
      "source": [
        "#@title ### Create Model\n",
        "\n",
        "noise_std=6.7e-4\n",
        "latent_size=128\n",
        "hidden_size=128\n",
        "hidden_layers=2\n",
        "message_passing_steps=10\n",
        "\n",
        "\"\"\"Gets one step model for training simulation.\"\"\"\n",
        "#metadata = _read_metadata(data_path)\n",
        "model_kwargs = dict(\n",
        "      latent_size=latent_size,\n",
        "      mlp_hidden_size=hidden_size,\n",
        "      mlp_num_hidden_layers=hidden_layers,\n",
        "      num_message_passing_steps=message_passing_steps)\n",
        "def _combine_std(std_x, std_y):\n",
        "  return np.sqrt(std_x**2 + std_y**2)\n",
        "\n",
        "Stats = collections.namedtuple('Stats', ['mean', 'std'])\n",
        "vel_noise_std=noise_std\n",
        "acc_noise_std=noise_std\n",
        "\"\"\"Instantiates the simulator.\"\"\"\n",
        "# Cast statistics to numpy so they are arrays when entering the model.\n",
        "cast = lambda v: np.array(v, dtype=np.float32)\n",
        "acceleration_stats = Stats(cast(metadata['acc_mean']), _combine_std(cast(metadata['acc_std']), acc_noise_std))\n",
        "velocity_stats = Stats(cast(metadata['vel_mean']),_combine_std(cast(metadata['vel_std']), vel_noise_std))\n",
        "normalization_stats = {'acceleration': acceleration_stats, 'velocity': velocity_stats}\n",
        "\n",
        "\n",
        "\n",
        "if 'context_mean' in metadata:\n",
        "    context_stats = Stats(cast(metadata['context_mean']), cast(metadata['context_std']))\n",
        "    normalization_stats['context'] = context_stats\n",
        "\n",
        "\n",
        "simulator = LearnedSimulator(\n",
        "      num_dimensions=metadata['dim'],\n",
        "      connectivity_radius=metadata['default_connectivity_radius'],\n",
        "      graph_network_kwargs=model_kwargs,\n",
        "      boundaries=metadata['bounds'],\n",
        "      num_particle_types=NUM_PARTICLE_TYPES,\n",
        "      normalization_stats=normalization_stats,\n",
        "      particle_type_embedding_size=16)\n",
        "\n",
        "\n",
        "KINEMATIC_PARTICLE_ID = 3\n",
        "def get_kinematic_mask(particle_types):\n",
        "  \"\"\"Returns a boolean mask, set to true for kinematic (obstacle) particles.\"\"\"\n",
        "  return tf.equal(particle_types, KINEMATIC_PARTICLE_ID)\n",
        "\n",
        "#@tf.function\n",
        "def loss_fn(features, labels):\n",
        "    target_next_position = labels\n",
        "    # Sample the noise to add to the inputs to the model during training.\n",
        "    sampled_noise = noise_utils.get_random_walk_noise_for_position_sequence(\n",
        "        features['pos'], noise_std_last_step=noise_std)\n",
        "    non_kinematic_mask = tf.logical_not(get_kinematic_mask(features['particle_type']))\n",
        "    noise_mask = tf.cast(non_kinematic_mask, sampled_noise.dtype)[:, tf.newaxis, tf.newaxis]\n",
        "    sampled_noise *= noise_mask\n",
        "\n",
        "    # Get the predictions and target accelerations.\n",
        "    pred_target = simulator.get_predicted_and_target_normalized_accelerations(\n",
        "        next_position=target_next_position,\n",
        "        position_sequence=features['pos'],\n",
        "        position_sequence_noise=sampled_noise,\n",
        "        n_particles_per_example=features['n_particles_per_example'],\n",
        "        particle_types=features['particle_type'],\n",
        "        global_context=features.get('step_context'))\n",
        "    pred_acceleration, target_acceleration = pred_target\n",
        "\n",
        "    # Calculate the loss and mask out loss on kinematic particles/\n",
        "    loss = (pred_acceleration - target_acceleration)**2\n",
        "\n",
        "    num_non_kinematic = tf.reduce_sum(tf.cast(non_kinematic_mask, tf.float32))\n",
        "    loss = tf.where(tf.expand_dims(non_kinematic_mask,-1), loss, tf.zeros_like(loss))\n",
        "    loss = tf.reduce_sum(loss) / tf.reduce_sum(num_non_kinematic)\n",
        "    \n",
        "    return loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "X8VFYHpFS-6X",
        "outputId": "2c85b9ed-a91b-4fcb-c911-56dbb8009f00"
      },
      "source": [
        "min_lr = 1e-6\n",
        "lr = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4 - min_lr,\n",
        "                                decay_steps=int(5e6),\n",
        "                                decay_rate=0.1) #+ min_lr\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "# @tf.function - ideally we'd like to decorate this with tf.function for faster code - but the connectivity utils is written using numpy so will need to be converted to tensorflow code\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss_fn(x,y)\n",
        "    grads = tape.gradient(loss_value, simulator.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, simulator.trainable_variables))\n",
        "    return loss_value\n",
        "\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(ds):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-73377706ef16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Iterate over the batches of the dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: /content/train_datasets; Is a directory [Op:IteratorGetNext]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bR7a7iXuQCJ",
        "outputId": "1fbf2968-64ef-4c2f-ba18-5c60301cea10"
      },
      "source": [
        "import tensorflow as tf \n",
        "raw_dataset = tf.data.TFRecordDataset(\"/content/train_datasets/microstates-0.tfrecords\")\n",
        "\n",
        "for raw_record in raw_dataset.take(1):\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(raw_record.numpy())\n",
        "    print(example)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features {\n",
            "  feature {\n",
            "    key: \"group_id\"\n",
            "    value {\n",
            "      int64_list {\n",
            "        value: 11\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  feature {\n",
            "    key: \"parameter_vector\"\n",
            "    value {\n",
            "      float_list {\n",
            "        value: 0.8999999761581421\n",
            "        value: 0.0\n",
            "        value: 0.0\n",
            "        value: 1.0\n",
            "        value: 5.0\n",
            "        value: 6.2831854820251465\n",
            "        value: 0.10000000149011612\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  feature {\n",
            "    key: \"pos\"\n",
            "    value {\n",
            "      bytes_list {\n",
            "        value: \"\\010\\001\\022\\010\\022\\002\\010d\\022\\002\\010\\002\\\"\\240\\006\\355\\210\\361B\\327\\220GC\\323H\\004C\\325\\257\\323B=\\020\\272B\\022\\276\\'A\\010.5C@\\334\\310B\\311!\\214B\\307@\\005Bq\\316\\245BmB\\022CsV\\352AO-\\232B\\267\\265\\260B\\236*\\017C\\2127\\362B\\366\\331\\217Bi\\026\\373Bc\\272\\'C\\323\\206\\nC\\213}\\034BG\\0049B\\226K\\320B0\\250\\377BPL\\032B\\300\\223GC\\205\\263\\022C\\201\\313\\037C\\272\\177\\025C\\240\\226\\007C\\207>dA\\000\\2206=wD\\247B;S\\226Bx\\307\\001CM4\\002BbQ\\331B\\356\\327\\327B\\215,9CR?`B<3AB\\246\\262@Cb\\\\\\230B\\240\\032\\304B]\\322%C\\222\\342\\\"B\\267\\177\\013C)\\3676C\\017o\\373B2\\365BC\\215\\225\\230BJ\\340cB7\\224\\014C\\206n\\017C\\335}\\023C\\236\\233\\223B\\213\\356\\267B\\203\\211\\210BK5\\032Cn\\003!C\\371*\\310Bvq\\262B[\\346@C\\217\\247\\024C\\002=\\310BK=\\315A\\225\\016\\tC6\\206\\374BR\\244\\027C\\004\\275@B\\362\\032\\340B\\326d#C\\277T\\013C\\370\\303\\375B\\351`nBm\\353\\222BL\\227`Bun\\023C\\333\\344\\261B\\306\\n\\331B\\256\\320\\356AJ\\037!C\\002|\\252B\\252\\303\\222B]9\\262B.\\362\\036C\\245\\274\\024C\\300\\266-A\\266\\350\\257B\\225l\\355B&\\306FC\\355\\366\\361B\\354\\231\\035C\\314\\204\\273@V(\\270B\\021\\3341CC\\273\\020C\\340\\235\\222B\\362\\366\\\"C!\\006\\240B\\361xgA$w\\024C\\377\\250\\013C\\200\\322\\354A\\360\\274\\001Cr|\\275B\\351\\004{Bk\\005/C\\304>\\225B\\326\\0316C\\312\\207\\261BV_`B^\\257\\026C\\266G\\002C/\\202;C\\017\\305kB\\347\\352\\351B\\n\\374\\277B3ODC\\030z\\311B\\013$\\300A\\017\\351gBB\\002\\361B\\274\\030\\257B\\232\\014BC\\204\\315\\tCrk\\247B\\302\\247\\206B\\215\\315\\177B\\\"O\\302B\\343\\244\\247B\\t~\\277B\\032\\010@C\\021\\344\\021C\\027(\\016B\\276I\\333B\\233\\036=Bu\\242tB\\310\\234\\347B\\023:\\036C\\255-\\036C\\307\\260vB\\221\\364\\361BnziA\\0019\\332Bb<\\244B~^!C.\\200yB\\275\\312-CR!XA\\234\\327\\266B\\031]\\013C\\356\\316\\020B_[\\336BXc\\033C\\247&\\321B\\276\\330\\367A\\003\\330\\016C\\257c\\034C\\205\\247\\223B}\\265\\031Cen\\210B\\335\\274.C|?\\354B\\307\\247@C93\\023C\\351\\014LB=I\\003C\\246\\300\\372A>G\\312B\\306}\\036C\\263\\377\\237B\\'GkB\\353>0C\\210*\\360B]\\034\\251BofyB~\\334\\031CC@\\010Cu\\317\\350Bhr\\275AP\\244\\034C@w/B\\\\\\3168C\\034}\\277B\\336$!C\\340\\276\\343B\\367\\370\\241BT\\032\\343Bo\\312\\242B\\213\\3473C\\374\\347\\005C5\\2374C \\337\\366B\\202\\'\\317A\\220z-C\\340x\\317BE\\216\\226BNj\\026C\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  feature {\n",
            "    key: \"timestep\"\n",
            "    value {\n",
            "      int64_list {\n",
            "        value: 1\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  feature {\n",
            "    key: \"vel\"\n",
            "    value {\n",
            "      bytes_list {\n",
            "        value: \"\\010\\001\\022\\010\\022\\002\\010d\\022\\002\\010\\002\\\"\\240\\006\\235\\377\\177?c~a;}Kv?\\330\\243\\213>0\\023~\\277<\\257\\372\\275\\007,\\350\\276\\255*d\\277m\\252\\177?\\371?Q=\\322\\\"\\305>hCl\\277\\241\\316 >\\335\\322|\\277\\244\\347\\366>?D`\\277\\307,X\\277\\022!\\t? \\240{\\277Z~<>v\\027Z?Q\\017\\006\\277Z\\357\\226=\\307M\\177\\277\\220\\027r?hv\\246>L8\\\">l\\304|?\\004=\\331\\275D\\216~?\\3411|?\\373\\345/>\\327bH?\\302P\\037\\277\\367?v\\277\\014\\365\\213>-\\2338?)\\\\1\\277\\216\\021v\\277\\025:\\215\\276\\273mz?\\236xT\\276ko\\365>e\\253`\\277\\323mp?\\366\\326\\257\\2769f3\\277\\000\\2406?\\222\\214\\355\\276]\\307b?\\333\\313)?\\010\\226?\\277<\\313z\\277_vM>\\305\\030^?\\036\\241\\376\\276W\\313\\177\\277\\246+$\\275\\266\\324\\246\\2752&\\177?\\203\\0038\\277\\177\\3711?\\004\\220?\\277\\244\\322)?\\357\\355\\177?\\356X\\300\\274\\263\\262\\032\\277\\313\\370K?\\344\\341 >\\031\\322|?\\264\\346L?\\nw\\031?i\\315\\205>\\213\\032w?\\\\sf?i\\367\\336\\276\\257;<\\277\\201\\201-?\\021\\024\\356\\276\\325\\243b?2\\267e?\\343\\372\\341>)jy?\\'\\304f>\\243\\321y\\277H\\251_\\276.\\322\\273>&\\'n?W\\016:?\\245\\326/\\277\\027\\307\\017?\\251\\317S\\277\\265\\375_\\277@\\347\\367\\276}tN>1\\276z\\277\\222\\0038>(\\325{?\\017\\334}\\277\\242#\\004\\276\\230\\377\\177\\277j\\362f\\273\\000\\377\\177?\\334\\003\\265;6\\324\\334\\275\\350\\201~?X\\274v?\\325}\\210>\\267G\\345\\275\\002d~\\277\\312\\004;\\277p\\320.\\277\\223-:>\\264\\273{?\\232q\\034?\\322\\242J?\\373=/?)\\236:?.Q/\\277\\037\\214:\\277U\\214\\177\\277\\200?s\\2758;\\177\\277\\205\\226\\236=c\\372}\\277\\022r\\000>\\325l\\014\\277n\\014V?\\345G\\316>\\250Mj\\277\\254P\\361\\276T\\310a\\277\\235tl\\277G6\\304\\276M#z?\\312\\341Y\\276\\306NY?\\257S\\007?\\260n|\\277\\377[*\\276\\221\\213s?\\215\\301\\235>\\247\\274\\177\\277`\\2459=\\317\\321w=\\361\\207\\177\\277\\327\\220\\224\\276_\\374t?D7}\\277H\\234\\026>\\3602\\237\\276sOs\\277\\313;h?\\223p\\327\\276D\\2657?BJ2\\2778\\346\\\"\\277\\326{E?\\025\\247}?\\023Z\\n>\\355\\377\\177\\277\\014\\345\\304:g\\335\\177?c\\024\\005=\\356\\217\\033?DPK\\277\\370\\034y?z\\353k\\276\\220/\\\\?\\200\\227\\002\\277\\231\\310\\004?\\373\\336Z\\277\\021\\253W>\\375Az\\277f\\025t\\277Jd\\232\\276\\201\\254G\\276\\000\\026{\\277\\326\\213|\\277?\\243\\'\\276\\373\\021z?\\376\\036[>,\\324w?oS\\200\\276\\002\\264\\310>\\343\\202k\\277\\241k\\263\\275\\005\\004\\177\\277\\232r_\\277l\\333\\371>\\276$|\\277I\\0221>l\\350s?\\224\\177\\233\\276[gl?!v\\304>\\374\\367`\\276\\332\\276y\\277M\\345L\\277\\351x\\031\\277\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}