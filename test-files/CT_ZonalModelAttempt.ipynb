{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ZonalModelAttempt.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctorney/learning-to-simulate-tf2/blob/main/test-files/ZonalModelAttempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXVqnwzwXWxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "027157e7-9d7c-497b-b314-851637a25dcd"
      },
      "source": [
        "!pip install \"graph_nets>=1.1\" \"dm-sonnet>=2.0.0b0\" \"tensorflow_probability\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graph_nets>=1.1\n",
            "  Downloading graph_nets-1.1.0.tar.gz (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting dm-sonnet>=2.0.0b0\n",
            "  Downloading dm_sonnet-2.0.0-py3-none-any.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 11.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow_probability in /usr/local/lib/python3.7/dist-packages (0.14.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from graph_nets>=1.1) (0.12.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from graph_nets>=1.1) (0.1.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from graph_nets>=1.1) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from graph_nets>=1.1) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from graph_nets>=1.1) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from graph_nets>=1.1) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from graph_nets>=1.1) (1.15.0)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet>=2.0.0b0) (0.8.9)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet>=2.0.0b0) (1.12.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (1.3.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (0.4.0)\n",
            "Building wheels for collected packages: graph-nets\n",
            "  Building wheel for graph-nets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graph-nets: filename=graph_nets-1.1.0-py3-none-any.whl size=91856 sha256=6ae4b83e72eec600fff47d521568c96a19920ffcc73c7afc591e595540ae5c41\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/3d/65/f2e8f0a8d0b28bea5f168fc717261a67303d2183a3e450c812\n",
            "Successfully built graph-nets\n",
            "Installing collected packages: dm-sonnet, graph-nets\n",
            "Successfully installed dm-sonnet-2.0.0 graph-nets-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtO-bo8q54IK"
      },
      "source": [
        "#@title ### Zonal Model\n",
        "\n",
        "import numpy as np\n",
        "from math import *\n",
        "import sys\n",
        "import random\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "def get_record(group_id,pos,vel):\n",
        "    feature = { 'group_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[group_id])),\n",
        "                'pos': tf.train.Feature(bytes_list=tf.train.BytesList(value=[pos.numpy()])),\n",
        "                'vel': tf.train.Feature(bytes_list=tf.train.BytesList(value=[vel.numpy()]))\n",
        "                }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "class zonal_model:\n",
        "    def __init__(self, N, timesteps, discard, repeat, L, dt, save_interval,train_directory='train_datasets', valid_directory='valid_datasets', disable_progress=False):\n",
        "        self.N = N\n",
        "        self.timesteps = timesteps\n",
        "        self.discard = discard\n",
        "        self.B = repeat  # repeat for B batches\n",
        "        self.L = L\n",
        "        self.dt = dt\n",
        "        self.save_interval = save_interval\n",
        "        \n",
        "        self.micro_state = np.zeros((self.B, (self.timesteps - self.discard)//self.save_interval, N, 4),dtype=np.float32)\n",
        "\n",
        "        self.sim_counter=0\n",
        "\n",
        "        if not os.path.exists(train_directory):\n",
        "            os.makedirs(train_directory)\n",
        "\n",
        "        if not os.path.exists(valid_directory):\n",
        "            os.makedirs(valid_directory)\n",
        "\n",
        "        self.train_directory = train_directory\n",
        "        self.valid_directory = valid_directory\n",
        "\n",
        "        # turn progress bar on or off\n",
        "        self.disable_progress = disable_progress\n",
        "\n",
        "        self.valid_fraction = 0.1\n",
        "        \n",
        "    def initialise_state(self):\n",
        "\n",
        "        self.positions = tf.random.uniform((self.B,self.N,2),0.5*self.L, 0.5*self.L+20) #0,self.L)\n",
        "        #self.positions = tf.random.uniform((self.B,self.N,2),0, self.L) \n",
        "        self.angles = tf.random.uniform((self.B,self.N,1), 0, 2*pi) #\n",
        "        \n",
        "\n",
        "\n",
        "    def run_sim(self, *params):\n",
        "\n",
        "        eta, Ra, Ro, Rr, vs, va, sigma = params\n",
        "        \n",
        "        record_file = self.train_directory + '/microstates-' + str(self.sim_counter) + '.tfrecords'\n",
        "        self.writer = tf.io.TFRecordWriter(record_file) \n",
        "        \n",
        "        valid_file = self.valid_directory + '/microstates-' + str(self.sim_counter) + '.tfrecords'\n",
        "        self.validwriter = tf.io.TFRecordWriter(valid_file) \n",
        "        \n",
        "        # tensorflow function to run an update step\n",
        "        @tf.function\n",
        "        def update_tf(X, A):\n",
        "            cos_A = tf.math.cos(A)\n",
        "            sin_A = tf.math.sin(A)\n",
        "\n",
        "\n",
        "            Xx = tf.expand_dims(X[...,0],-1)\n",
        "            dx = -Xx + tf.linalg.matrix_transpose(Xx)\n",
        "            dx = tf.where(dx>0.5*self.L, dx-self.L, dx)\n",
        "            dx = tf.where(dx<-0.5*self.L, dx+self.L, dx)\n",
        "\n",
        "            Xy = tf.expand_dims(X[...,1],-1)\n",
        "            dy = -Xy + tf.linalg.matrix_transpose(Xy)\n",
        "            dy = tf.where(dy>0.5*self.L, dy-self.L, dy)\n",
        "            dy = tf.where(dy<-0.5*self.L, dy+self.L, dy)\n",
        "\n",
        "\n",
        "            angle_to_neigh = tf.math.atan2(dy, dx)\n",
        "            cos_N = tf.math.cos(angle_to_neigh)\n",
        "            sin_N = tf.math.sin(angle_to_neigh)\n",
        "            rel_angle_to_neigh = angle_to_neigh - A\n",
        "            rel_angle_to_neigh = tf.math.atan2(tf.math.sin(rel_angle_to_neigh), tf.math.cos(rel_angle_to_neigh))\n",
        "            \n",
        "            dist = tf.math.sqrt(tf.square(dx)+tf.square(dy))\n",
        "    \n",
        "            # repulsion \n",
        "            rep_x = tf.where(dist<=Rr, -dx, tf.zeros_like(dx))\n",
        "            rep_x = tf.where(rel_angle_to_neigh<0.5*va, rep_x, tf.zeros_like(rep_x))\n",
        "            rep_x = tf.where(rel_angle_to_neigh>-0.5*va, rep_x, tf.zeros_like(rep_x))\n",
        "            rep_x = tf.math.divide_no_nan(rep_x,tf.math.square(dist))\n",
        "            rep_x = tf.reduce_sum(rep_x,axis=2)\n",
        "\n",
        "            rep_y = tf.where(dist<=Rr, -dy, tf.zeros_like(dy))\n",
        "            rep_y = tf.where(rel_angle_to_neigh<0.5*va, rep_y, tf.zeros_like(rep_y))\n",
        "            rep_y = tf.where(rel_angle_to_neigh>-0.5*va, rep_y, tf.zeros_like(rep_y))\n",
        "            rep_y = tf.math.divide_no_nan(rep_y,tf.math.square(dist))\n",
        "            rep_y = tf.reduce_sum(rep_y,axis=2)\n",
        "\n",
        "            # alignment \n",
        "            align_x = tf.where(dist<=Ro, cos_A, tf.zeros_like(cos_A))\n",
        "            align_x = tf.where(rel_angle_to_neigh<0.5*va, align_x, tf.zeros_like(align_x))\n",
        "            align_x = tf.where(rel_angle_to_neigh>-0.5*va, align_x, tf.zeros_like(align_x))\n",
        "            align_x = tf.reduce_sum(align_x,axis=1)\n",
        "            \n",
        "            align_y = tf.where(dist<=Ro, sin_A, tf.zeros_like(sin_A))\n",
        "            align_y = tf.where(rel_angle_to_neigh<0.5*va, align_y, tf.zeros_like(align_y))\n",
        "            align_y = tf.where(rel_angle_to_neigh>-0.5*va, align_y, tf.zeros_like(align_y))\n",
        "            align_y = tf.reduce_sum(align_y,axis=1)\n",
        "\n",
        "            al_norm = tf.math.sqrt(align_x**2+align_y**2)\n",
        "            align_x = tf.math.divide_no_nan(align_x,al_norm)\n",
        "            align_y = tf.math.divide_no_nan(align_y,al_norm)\n",
        "\n",
        "            # attractive interactions\n",
        "            attr_x = tf.where(dist<=Ra, dx, tf.zeros_like(dx))\n",
        "            attr_x = tf.where(rel_angle_to_neigh<0.5*va, attr_x, tf.zeros_like(attr_x))\n",
        "            attr_x = tf.where(rel_angle_to_neigh>-0.5*va, attr_x, tf.zeros_like(attr_x))\n",
        "            attr_x = tf.reduce_sum(attr_x,axis=2)\n",
        "\n",
        "            attr_y = tf.where(dist<=Ra, dy, tf.zeros_like(dy))\n",
        "            attr_y = tf.where(rel_angle_to_neigh<0.5*va, attr_y, tf.zeros_like(attr_y))\n",
        "            attr_y = tf.where(rel_angle_to_neigh>-0.5*va, attr_y, tf.zeros_like(attr_y))\n",
        "            attr_y = tf.reduce_sum(attr_y,axis=2)\n",
        "\n",
        "            at_norm = tf.math.sqrt(attr_x**2+attr_y**2)\n",
        "            attr_x = tf.math.divide_no_nan(attr_x,at_norm)\n",
        "            attr_y = tf.math.divide_no_nan(attr_y,at_norm)\n",
        "\n",
        "            # combine angles and convert to desired angle change\n",
        "            social_x = rep_x + align_x + attr_x\n",
        "            social_y = rep_y + align_y + attr_y\n",
        "\n",
        "            d_angle = tf.math.atan2(social_y,social_x)\n",
        "            d_angle = tf.expand_dims(d_angle,-1)\n",
        "\n",
        "            \n",
        "            d_angle = tf.math.atan2((1-eta)*tf.math.sin(d_angle) + eta*sin_A, (1-eta)*tf.math.cos(d_angle) + eta*cos_A)\n",
        "\n",
        "            d_angle = d_angle - A\n",
        "            d_angle = tf.where(d_angle>pi, d_angle-2*pi, d_angle)\n",
        "            d_angle = tf.where(d_angle<-pi, d_angle+2*pi, d_angle)\n",
        "\n",
        "\n",
        "            # add perception noise\n",
        "            noise = tf.random.normal(shape=(self.B,self.N,1),mean=0,stddev=sigma*(self.dt**0.5))\n",
        "            d_angle = d_angle + noise\n",
        "            \n",
        "            # restrict to maximum turning angle\n",
        "            #d_angle = tf.where(tf.math.abs(d_angle)>eta*self.dt, tf.math.sign(d_angle)*eta*self.dt, d_angle)\n",
        "            \n",
        "            # rotate headings\n",
        "            A = A + d_angle\n",
        "            \n",
        "            # update positions\n",
        "            velocity = self.dt*vs*tf.concat([tf.cos(A),tf.sin(A)],axis=-1)\n",
        "            X += velocity\n",
        "\n",
        "            # add periodic boundary conditions\n",
        "            A = tf.where(A<-pi,  A+2*pi, A)\n",
        "            A = tf.where(A>pi, A-2*pi, A)\n",
        "\n",
        "            X = tf.where(X>self.L, X-self.L, X)\n",
        "            X = tf.where(X<0, X+self.L, X)\n",
        "\n",
        "            X = tf.where(X>self.L, X-self.L, X)\n",
        "            X = tf.where(X<0, X+self.L, X)\n",
        "\n",
        "            return X, A\n",
        "            \n",
        "        self.initialise_state()\n",
        "\n",
        "        counter=0\n",
        "        for i in tqdm(range(self.timesteps),disable=self.disable_progress):\n",
        "            self.positions, self.angles = update_tf(self.positions,  self.angles)\n",
        "            if i>=self.discard:\n",
        "                if i%self.save_interval==0:\n",
        "                    # store in an array in case we want to visualise\n",
        "                    self.micro_state[:,counter,:,0:2] = self.positions.numpy()\n",
        "                    self.micro_state[:,counter,:,2:3] = np.cos(self.angles.numpy())\n",
        "                    self.micro_state[:,counter,:,3:4] = np.sin(self.angles.numpy())\n",
        "                        \n",
        "                    \n",
        "\n",
        "                    counter = counter + 1\n",
        "\n",
        "        for b in range(self.B):\n",
        "            self.save_tf_record(b)\n",
        "\n",
        "        self.writer.close()\n",
        "        self.validwriter.close()\n",
        "        self.sim_counter+=1\n",
        "        return \n",
        "\n",
        "    def save_tf_record(self, b):\n",
        "        pos =  tf.io.serialize_tensor(self.micro_state[b,:,:,0:2])\n",
        "        vel =  tf.io.serialize_tensor(self.micro_state[b,:,:,2:4])\n",
        "\n",
        "        tf_record = get_record(b,pos,vel)\n",
        "        if b> self.B*self.valid_fraction:\n",
        "            self.writer.write(tf_record.SerializeToString())\n",
        "        else:\n",
        "            self.validwriter.write(tf_record.SerializeToString())\n",
        "\n",
        "        \n",
        "        return "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "tUA_iPLo6ARy",
        "outputId": "503c87a2-7c64-4377-e456-270c3803e9d0"
      },
      "source": [
        "#@title ### Create Training Data\n",
        "\n",
        "n_points=50 #10\n",
        "\n",
        "param_values = np.linspace(0,25,n_points)\n",
        "L= 200\n",
        "N= 100 \n",
        "repeat = 100\n",
        "discard = 500\n",
        "timesteps = 500\n",
        "save_interval=10\n",
        "dt=0.1 \n",
        "\n",
        "\n",
        "sim = zonal_model(N,timesteps=timesteps+discard,discard=discard,L=L,repeat=repeat, dt=dt,save_interval=save_interval,disable_progress=False)\n",
        "\n",
        "latt=0  # adapt\n",
        "lrep= 1 # adapt\n",
        "lali= 5 # adapt\n",
        "eta=0.9 # adapt\n",
        "va=2*pi # adapt\n",
        "vs=5 # fix \n",
        "sigma=0.1 \n",
        "\n",
        "def evaluate_zonal_model(X):\n",
        "    sim.run_sim(eta, latt, X, lrep, vs, va, sigma)\n",
        "    return\n",
        "\n",
        "evaluate_zonal_model(0)\n",
        "\n",
        "\"\"\"\n",
        "for i in tqdm(range(param_values.shape[0])):\n",
        "    evaluate_zonal_model(param_values[i])\n",
        "\"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:05<00:00, 175.53it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor i in tqdm(range(param_values.shape[0])):\\n    evaluate_zonal_model(param_values[i])\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaWJxsTFcha1"
      },
      "source": [
        "## Maybe working datasets code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVuzYIbrbPl9",
        "outputId": "bc522612-6744-412f-c1a8-88da2cc733cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "WINDOW_SIZE=5\n",
        "\n",
        "#Create a tf.data.Dataset from the TFRecord.\n",
        "ds = tf.data.TFRecordDataset(['train_datasets/microstates-' + str(i) + '.tfrecords' for i in range(1)])\n",
        "\n",
        "feature_description = {'group_id': tf.io.FixedLenFeature([], tf.int64),\n",
        "                        'pos': tf.io.FixedLenFeature([], tf.string),\n",
        "                        'vel': tf.io.FixedLenFeature([], tf.string)}\n",
        "\n",
        "def _parse_record(x):\n",
        "  # Parse the input tf.train.Example proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(x, feature_description)\n",
        "\n",
        "def _parse_tensor(x):\n",
        "    output = {'group_id': x['group_id'],\n",
        "                'pos': tf.io.parse_tensor(x['pos'],out_type=tf.float32),\n",
        "                'vel': tf.io.parse_tensor(x['vel'],out_type=tf.float32)}\n",
        "    return output\n",
        "\n",
        "\n",
        "# map the record to features\n",
        "ds = ds.map(_parse_record)\n",
        "# map the features to tensors\n",
        "ds = ds.map(_parse_tensor)\n",
        "\n",
        "def make_window_dataset(x):\n",
        "\n",
        "    # make a dataset from the time series tensor\n",
        "    windows = tf.data.Dataset.from_tensor_slices((x['pos'],x['vel']))\n",
        "    # convert to windows\n",
        "    windows = windows.window(WINDOW_SIZE, shift=1, stride=1)\n",
        "    # take a batch of window size and combine pos, vel to a single dataset\n",
        "    windows = windows.flat_map(lambda pos_ds,vel_ds: tf.data.Dataset.zip((pos_ds.batch(WINDOW_SIZE, drop_remainder=True),vel_ds.batch(WINDOW_SIZE, drop_remainder=True))))\n",
        "  \n",
        "    return windows\n",
        "\n",
        "# flatten the windowed dataset\n",
        "ds = ds.flat_map(make_window_dataset)\n",
        "\n",
        "ds.shuffle(2000)\n",
        "\n",
        "for example in ds.take(1):\n",
        "  print(example[0].numpy().shape)\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 100, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BL8x-cdXhgo"
      },
      "source": [
        "#@title ### connectivity_utils\n",
        "\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import neighbors\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def _compute_connectivity(positions, radius, add_self_edges):\n",
        "  \"\"\"Get the indices of connected edges with radius connectivity.\n",
        "  Args:\n",
        "    positions: Positions of nodes in the graph. Shape:\n",
        "      [num_nodes_in_graph, num_dims].\n",
        "    radius: Radius of connectivity.\n",
        "    add_self_edges: Whether to include self edges or not.\n",
        "  Returns:\n",
        "    senders indices [num_edges_in_graph]\n",
        "    receiver indices [num_edges_in_graph]\n",
        "  \"\"\"\n",
        "  tree = neighbors.KDTree(positions)\n",
        "  receivers_list = tree.query_radius(positions, r=radius)\n",
        "  num_nodes = len(positions)\n",
        "  senders = np.repeat(range(num_nodes), [len(a) for a in receivers_list])\n",
        "  receivers = np.concatenate(receivers_list, axis=0)\n",
        "\n",
        "  if not add_self_edges:\n",
        "    # Remove self edges.\n",
        "    mask = senders != receivers\n",
        "    senders = senders[mask]\n",
        "    receivers = receivers[mask]\n",
        "\n",
        "  return senders, receivers\n",
        "\n",
        "\n",
        "def _compute_connectivity_for_batch(\n",
        "    positions, n_node, radius, add_self_edges):\n",
        "  \"\"\"`compute_connectivity` for a batch of graphs.\n",
        "  Args:\n",
        "    positions: Positions of nodes in the batch of graphs. Shape:\n",
        "      [num_nodes_in_batch, num_dims].\n",
        "    n_node: Number of nodes for each graph in the batch. Shape:\n",
        "      [num_graphs in batch].\n",
        "    radius: Radius of connectivity.\n",
        "    add_self_edges: Whether to include self edges or not.\n",
        "  Returns:\n",
        "    senders indices [num_edges_in_batch]\n",
        "    receiver indices [num_edges_in_batch]\n",
        "    number of edges per graph [num_graphs_in_batch]\n",
        "  \"\"\"\n",
        "\n",
        "  # TODO(alvarosg): Consider if we want to support batches here or not.\n",
        "  # Separate the positions corresponding to particles in different graphs.\n",
        "  positions_per_graph_list = np.split(positions, np.cumsum(n_node[:-1]), axis=0)\n",
        "  receivers_list = []\n",
        "  senders_list = []\n",
        "  n_edge_list = []\n",
        "  num_nodes_in_previous_graphs = 0\n",
        "\n",
        "  # Compute connectivity for each graph in the batch.\n",
        "  for positions_graph_i in positions_per_graph_list:\n",
        "    senders_graph_i, receivers_graph_i = _compute_connectivity(\n",
        "        positions_graph_i, radius, add_self_edges)\n",
        "\n",
        "    num_edges_graph_i = len(senders_graph_i)\n",
        "    n_edge_list.append(num_edges_graph_i)\n",
        "\n",
        "    # Because the inputs will be concatenated, we need to add offsets to the\n",
        "    # sender and receiver indices according to the number of nodes in previous\n",
        "    # graphs in the same batch.\n",
        "    receivers_list.append(receivers_graph_i + num_nodes_in_previous_graphs)\n",
        "    senders_list.append(senders_graph_i + num_nodes_in_previous_graphs)\n",
        "\n",
        "    num_nodes_graph_i = len(positions_graph_i)\n",
        "    num_nodes_in_previous_graphs += num_nodes_graph_i\n",
        "\n",
        "  # Concatenate all of the results.\n",
        "  senders = np.concatenate(senders_list, axis=0).astype(np.int32)\n",
        "  receivers = np.concatenate(receivers_list, axis=0).astype(np.int32)\n",
        "  n_edge = np.stack(n_edge_list).astype(np.int32)\n",
        "\n",
        "  return senders, receivers, n_edge\n",
        "\n",
        "\n",
        "def compute_connectivity_for_batch_pyfunc(\n",
        "    positions, n_node, radius, add_self_edges=True):\n",
        "  \"\"\"`_compute_connectivity_for_batch` wrapped in a pyfunc.\"\"\"\n",
        "  partial_fn = functools.partial(\n",
        "      _compute_connectivity_for_batch, add_self_edges=add_self_edges)\n",
        "  senders, receivers, n_edge = tf.py_function(\n",
        "      partial_fn,\n",
        "      [positions, n_node, radius],\n",
        "      [tf.int32, tf.int32, tf.int32])\n",
        "  senders.set_shape([None])\n",
        "  receivers.set_shape([None])\n",
        "  n_edge.set_shape(n_node.get_shape())\n",
        "  return senders, receivers, n_edge"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "EEx3i6DgXslW"
      },
      "source": [
        "#@title ### graph_network\n",
        "\n",
        "from typing import Callable\n",
        "\n",
        "import graph_nets as gn\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "\n",
        "Reducer = Callable[[tf.Tensor, tf.Tensor, tf.Tensor], tf.Tensor]\n",
        "\n",
        "\n",
        "def build_mlp(\n",
        "    hidden_size: int, num_hidden_layers: int, output_size: int) -> snt.Module:\n",
        "  \"\"\"Builds an MLP.\"\"\"\n",
        "  return snt.nets.MLP(\n",
        "      output_sizes=[hidden_size] * num_hidden_layers + [output_size])\n",
        "\n",
        "\n",
        "class EncodeProcessDecode(snt.Module):\n",
        "  \"\"\"Encode-Process-Decode function approximator for learnable simulator.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      latent_size: int,\n",
        "      mlp_hidden_size: int,\n",
        "      mlp_num_hidden_layers: int,\n",
        "      num_message_passing_steps: int,\n",
        "      output_size: int,\n",
        "      reducer: Reducer = tf.math.unsorted_segment_sum,\n",
        "      name: str = \"EncodeProcessDecode\"):\n",
        "    \"\"\"Inits the model.\n",
        "    Args:\n",
        "      latent_size: Size of the node and edge latent representations.\n",
        "      mlp_hidden_size: Hidden layer size for all MLPs.\n",
        "      mlp_num_hidden_layers: Number of hidden layers in all MLPs.\n",
        "      num_message_passing_steps: Number of message passing steps.\n",
        "      output_size: Output size of the decode node representations as required\n",
        "        by the downstream update function.\n",
        "      reducer: Reduction to be used when aggregating the edges in the nodes in\n",
        "        the interaction network. This should be a callable whose signature\n",
        "        matches tf.math.unsorted_segment_sum.\n",
        "      name: Name of the model.\n",
        "    \"\"\"\n",
        "\n",
        "    super().__init__(name=name)\n",
        "\n",
        "    self._latent_size = latent_size\n",
        "    self._mlp_hidden_size = mlp_hidden_size\n",
        "    self._mlp_num_hidden_layers = mlp_num_hidden_layers\n",
        "    self._num_message_passing_steps = num_message_passing_steps\n",
        "    self._output_size = output_size\n",
        "    self._reducer = reducer\n",
        "\n",
        "    #with self._enter_variable_scope():\n",
        "    self._networks_builder()\n",
        "\n",
        "  def __call__(self, input_graph: gn.graphs.GraphsTuple) -> tf.Tensor:\n",
        "    \"\"\"Forward pass of the learnable dynamics model.\"\"\"\n",
        "\n",
        "    # Encode the input_graph.\n",
        "    latent_graph_0 = self._encode(input_graph)\n",
        "\n",
        "    # Do `m` message passing steps in the latent graphs.\n",
        "    latent_graph_m = self._process(latent_graph_0)\n",
        "\n",
        "    # Decode from the last latent graph.\n",
        "    return self._decode(latent_graph_m)\n",
        "\n",
        "  def _networks_builder(self):\n",
        "    \"\"\"Builds the networks.\"\"\"\n",
        "    def build_mlp_with_layer_norm():\n",
        "      mlp = build_mlp(\n",
        "          hidden_size=self._mlp_hidden_size,\n",
        "          num_hidden_layers=self._mlp_num_hidden_layers,\n",
        "          output_size=self._latent_size)\n",
        "      return snt.Sequential([mlp, snt.LayerNorm(axis=slice(1, None),create_scale=False,create_offset=False)])\n",
        "\n",
        "    # The encoder graph network independently encodes edge and node features.\n",
        "    encoder_kwargs = dict(\n",
        "        edge_model_fn=build_mlp_with_layer_norm,\n",
        "        node_model_fn=build_mlp_with_layer_norm)\n",
        "    self._encoder_network = gn.modules.GraphIndependent(**encoder_kwargs)\n",
        "    # Create `num_message_passing_steps` graph networks with unshared parameters\n",
        "    # that update the node and edge latent features.\n",
        "    # Note that we can use `modules.InteractionNetwork` because\n",
        "    # it also outputs the messages as updated edge latent features.\n",
        "    self._processor_networks = []\n",
        "    for _ in range(self._num_message_passing_steps):\n",
        "      self._processor_networks.append(\n",
        "          gn.modules.InteractionNetwork(\n",
        "              edge_model_fn=build_mlp_with_layer_norm,\n",
        "              node_model_fn=build_mlp_with_layer_norm,\n",
        "              reducer=self._reducer))\n",
        "    # The decoder MLP decodes node latent features into the output size.\n",
        "    self._decoder_network = build_mlp(\n",
        "        hidden_size=self._mlp_hidden_size,\n",
        "        num_hidden_layers=self._mlp_num_hidden_layers,\n",
        "        output_size=self._output_size)\n",
        "  def _encode(\n",
        "      self, input_graph: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n",
        "    \"\"\"Encodes the input graph features into a latent graph.\"\"\"\n",
        "\n",
        "    # Copy the globals to all of the nodes, if applicable.\n",
        "    if input_graph.globals is not None:\n",
        "      broadcasted_globals = gn.blocks.broadcast_globals_to_nodes(input_graph)\n",
        "      input_graph = input_graph.replace(\n",
        "          nodes=tf.concat([input_graph.nodes, broadcasted_globals], axis=-1),\n",
        "          globals=None)\n",
        "\n",
        "    # Encode the node and edge features.\n",
        "    latent_graph_0 = self._encoder_network(input_graph)\n",
        "    return latent_graph_0\n",
        "\n",
        "  def _process(\n",
        "      self, latent_graph_0: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n",
        "    \"\"\"Processes the latent graph with several steps of message passing.\"\"\"\n",
        "\n",
        "    # Do `m` message passing steps in the latent graphs.\n",
        "    # (In the shared parameters case, just reuse the same `processor_network`)\n",
        "    latent_graph_prev_k = latent_graph_0\n",
        "    latent_graph_k = latent_graph_0\n",
        "    for processor_network_k in self._processor_networks:\n",
        "      latent_graph_k = self._process_step(\n",
        "          processor_network_k, latent_graph_prev_k)\n",
        "      latent_graph_prev_k = latent_graph_k\n",
        "\n",
        "    latent_graph_m = latent_graph_k\n",
        "    return latent_graph_m\n",
        "\n",
        "  def _process_step(\n",
        "      self, processor_network_k: snt.Module,\n",
        "      latent_graph_prev_k: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n",
        "    \"\"\"Single step of message passing with node/edge residual connections.\"\"\"\n",
        "\n",
        "    # One step of message passing.\n",
        "    latent_graph_k = processor_network_k(latent_graph_prev_k)\n",
        "\n",
        "    # Add residuals.\n",
        "    latent_graph_k = latent_graph_k.replace(\n",
        "        nodes=latent_graph_k.nodes+latent_graph_prev_k.nodes,\n",
        "        edges=latent_graph_k.edges+latent_graph_prev_k.edges)\n",
        "    return latent_graph_k\n",
        "\n",
        "  def _decode(self, latent_graph: gn.graphs.GraphsTuple) -> tf.Tensor:\n",
        "    \"\"\"Decodes from the latent graph.\"\"\"\n",
        "    return self._decoder_network(latent_graph.nodes)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "CnGLHy8zTbYo"
      },
      "source": [
        "#@title ### learned_simulator\n",
        "\n",
        "\n",
        "\n",
        "import graph_nets as gn\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# from learning_to_simulate import connectivity_utils\n",
        "# from learning_to_simulate import graph_network\n",
        "\n",
        "STD_EPSILON = 1e-8\n",
        "\n",
        "\n",
        "class LearnedSimulator(snt.Module):\n",
        "  \"\"\"Learned simulator from https://arxiv.org/pdf/2002.09405.pdf.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      num_dimensions,\n",
        "      connectivity_radius,\n",
        "      graph_network_kwargs,\n",
        "      boundaries,\n",
        "      normalization_stats,\n",
        "      num_particle_types,\n",
        "      particle_type_embedding_size,\n",
        "      name=\"LearnedSimulator\"):\n",
        "    \"\"\"Inits the model.\n",
        "    Args:\n",
        "      num_dimensions: Dimensionality of the problem.\n",
        "      connectivity_radius: Scalar with the radius of connectivity.\n",
        "      graph_network_kwargs: Keyword arguments to pass to the learned part\n",
        "        of the graph network `model.EncodeProcessDecode`.\n",
        "      boundaries: List of 2-tuples, containing the lower and upper boundaries of\n",
        "        the cuboid containing the particles along each dimensions, matching\n",
        "        the dimensionality of the problem.\n",
        "      normalization_stats: Dictionary with statistics with keys \"acceleration\"\n",
        "        and \"velocity\", containing a named tuple for each with mean and std\n",
        "        fields, matching the dimensionality of the problem.\n",
        "      num_particle_types: Number of different particle types.\n",
        "      particle_type_embedding_size: Embedding size for the particle type.\n",
        "      name: Name of the Sonnet module.\n",
        "    \"\"\"\n",
        "    super().__init__(name=name)\n",
        "\n",
        "    self._connectivity_radius = connectivity_radius\n",
        "    self._num_particle_types = num_particle_types\n",
        "    self._boundaries = boundaries\n",
        "    self._normalization_stats = normalization_stats\n",
        "    #with self._enter_variable_scope():\n",
        "    self._graph_network = EncodeProcessDecode(output_size=num_dimensions, **graph_network_kwargs)\n",
        "\n",
        "    if self._num_particle_types > 1:\n",
        "        self._particle_type_embedding = tf.compat.v1.get_variable(\n",
        "            \"particle_embedding\",\n",
        "            [self._num_particle_types, particle_type_embedding_size],\n",
        "            trainable=True, use_resource=True)\n",
        "\n",
        "  def __call__(self, position_sequence, n_particles_per_example,\n",
        "             global_context=None, particle_types=None):\n",
        "    \"\"\"Produces a model step, outputting the next position for each particle.\n",
        "    Args:\n",
        "      position_sequence: Sequence of positions for each node in the batch,\n",
        "        with shape [num_particles_in_batch, sequence_length, num_dimensions]\n",
        "      n_particles_per_example: Number of particles for each graph in the batch\n",
        "        with shape [batch_size]\n",
        "      global_context: Tensor of shape [batch_size, context_size], with global\n",
        "        context.\n",
        "      particle_types: Integer tensor of shape [num_particles_in_batch] with\n",
        "        the integer types of the particles, from 0 to `num_particle_types - 1`.\n",
        "        If None, we assume all particles are the same type.\n",
        "    Returns:\n",
        "      Next position with shape [num_particles_in_batch, num_dimensions] for one\n",
        "      step into the future from the input sequence.\n",
        "    \"\"\"\n",
        "    input_graphs_tuple = self._encoder_preprocessor(\n",
        "        position_sequence, n_particles_per_example, global_context,\n",
        "        particle_types)\n",
        "\n",
        "    normalized_acceleration = self._graph_network(input_graphs_tuple)\n",
        "\n",
        "    next_position = self._decoder_postprocessor(\n",
        "        normalized_acceleration, position_sequence)\n",
        "\n",
        "    return next_position\n",
        "\n",
        "  def _encoder_preprocessor(\n",
        "      self, position_sequence, n_node, global_context, particle_types):\n",
        "    # Extract important features from the position_sequence.\n",
        "    most_recent_position = position_sequence[:, -1]\n",
        "    velocity_sequence = time_diff(position_sequence)  # Finite-difference.\n",
        "\n",
        "    # Get connectivity of the graph.\n",
        "    (senders, receivers, n_edge\n",
        "     ) = connectivity_utils.compute_connectivity_for_batch_pyfunc(\n",
        "         most_recent_position, n_node, self._connectivity_radius)\n",
        "\n",
        "    # Collect node features.\n",
        "    node_features = []\n",
        "\n",
        "    # Normalized velocity sequence, merging spatial an time axis.\n",
        "    velocity_stats = self._normalization_stats[\"velocity\"]\n",
        "    normalized_velocity_sequence = (\n",
        "        velocity_sequence - velocity_stats.mean) / velocity_stats.std\n",
        "\n",
        "    flat_velocity_sequence = snt.Flatten()(\n",
        "        normalized_velocity_sequence)\n",
        "    node_features.append(flat_velocity_sequence)\n",
        "\n",
        "    # Normalized clipped distances to lower and upper boundaries.\n",
        "    # boundaries are an array of shape [num_dimensions, 2], where the second\n",
        "    # axis, provides the lower/upper boundaries.\n",
        "    boundaries = tf.constant(self._boundaries, dtype=tf.float32)\n",
        "    distance_to_lower_boundary = (\n",
        "        most_recent_position - tf.expand_dims(boundaries[:, 0], 0))\n",
        "    distance_to_upper_boundary = (\n",
        "        tf.expand_dims(boundaries[:, 1], 0) - most_recent_position)\n",
        "    distance_to_boundaries = tf.concat(\n",
        "        [distance_to_lower_boundary, distance_to_upper_boundary], axis=1)\n",
        "    normalized_clipped_distance_to_boundaries = tf.clip_by_value(\n",
        "        distance_to_boundaries / self._connectivity_radius, -1., 1.)\n",
        "    node_features.append(normalized_clipped_distance_to_boundaries)\n",
        "\n",
        "    # Particle type.\n",
        "    if self._num_particle_types > 1:\n",
        "      particle_type_embeddings = tf.nn.embedding_lookup(\n",
        "          self._particle_type_embedding, particle_types)\n",
        "      node_features.append(particle_type_embeddings)\n",
        "\n",
        "    # Collect edge features.\n",
        "    edge_features = []\n",
        "\n",
        "    # Relative displacement and distances normalized to radius\n",
        "    normalized_relative_displacements = (\n",
        "        tf.gather(most_recent_position, senders) -\n",
        "        tf.gather(most_recent_position, receivers)) / self._connectivity_radius\n",
        "    edge_features.append(normalized_relative_displacements)\n",
        "\n",
        "    normalized_relative_distances = tf.norm(\n",
        "        normalized_relative_displacements, axis=-1, keepdims=True)\n",
        "    edge_features.append(normalized_relative_distances)\n",
        "\n",
        "    # Normalize the global context.\n",
        "    if global_context is not None:\n",
        "      context_stats = self._normalization_stats[\"context\"]\n",
        "      # Context in some datasets are all zero, so add an epsilon for numerical\n",
        "      # stability.\n",
        "      global_context = (global_context - context_stats.mean) / tf.math.maximum(\n",
        "          context_stats.std, STD_EPSILON)\n",
        "\n",
        "    return gn.graphs.GraphsTuple(\n",
        "        nodes=tf.concat(node_features, axis=-1),\n",
        "        edges=tf.concat(edge_features, axis=-1),\n",
        "        globals=global_context,  # self._graph_net will appending this to nodes.\n",
        "        n_node=n_node,\n",
        "        n_edge=n_edge,\n",
        "        senders=senders,\n",
        "        receivers=receivers,\n",
        "        )\n",
        "\n",
        "  def _decoder_postprocessor(self, normalized_acceleration, position_sequence):\n",
        "\n",
        "    # The model produces the output in normalized space so we apply inverse\n",
        "    # normalization.\n",
        "    acceleration_stats = self._normalization_stats[\"acceleration\"]\n",
        "    acceleration = (\n",
        "        normalized_acceleration * acceleration_stats.std\n",
        "        ) + acceleration_stats.mean\n",
        "\n",
        "    # Use an Euler integrator to go from acceleration to position, assuming\n",
        "    # a dt=1 corresponding to the size of the finite difference.\n",
        "    most_recent_position = position_sequence[:, -1]\n",
        "    most_recent_velocity = most_recent_position - position_sequence[:, -2]\n",
        "\n",
        "    new_velocity = most_recent_velocity + acceleration  # * dt = 1\n",
        "    new_position = most_recent_position + new_velocity  # * dt = 1\n",
        "    return new_position\n",
        "\n",
        "  def get_predicted_and_target_normalized_accelerations(\n",
        "      self, next_position, position_sequence_noise, position_sequence,\n",
        "      n_particles_per_example, global_context=None, particle_types=None):  # pylint: disable=g-doc-args\n",
        "    \"\"\"Produces normalized and predicted acceleration targets.\n",
        "    Args:\n",
        "      next_position: Tensor of shape [num_particles_in_batch, num_dimensions]\n",
        "        with the positions the model should output given the inputs.\n",
        "      position_sequence_noise: Tensor of the same shape as `position_sequence`\n",
        "        with the noise to apply to each particle.\n",
        "      position_sequence, n_node, global_context, particle_types: Inputs to the\n",
        "        model as defined by `_build`.\n",
        "    Returns:\n",
        "      Tensors of shape [num_particles_in_batch, num_dimensions] with the\n",
        "        predicted and target normalized accelerations.\n",
        "    \"\"\"\n",
        "\n",
        "    # Add noise to the input position sequence.\n",
        "    noisy_position_sequence = position_sequence + position_sequence_noise\n",
        "\n",
        "    # Perform the forward pass with the noisy position sequence.\n",
        "    input_graphs_tuple = self._encoder_preprocessor(\n",
        "        noisy_position_sequence, n_particles_per_example, global_context,\n",
        "        particle_types)\n",
        "    predicted_normalized_acceleration = self._graph_network(input_graphs_tuple)\n",
        "\n",
        "    # Calculate the target acceleration, using an `adjusted_next_position `that\n",
        "    # is shifted by the noise in the last input position.\n",
        "    next_position_adjusted = next_position + position_sequence_noise[:, -1]\n",
        "    target_normalized_acceleration = self._inverse_decoder_postprocessor(\n",
        "        next_position_adjusted, noisy_position_sequence)\n",
        "    # As a result the inverted Euler update in the `_inverse_decoder` produces:\n",
        "    # * A target acceleration that does not explicitly correct for the noise in\n",
        "    #   the input positions, as the `next_position_adjusted` is different\n",
        "    #   from the true `next_position`.\n",
        "    # * A target acceleration that exactly corrects noise in the input velocity\n",
        "    #   since the target next velocity calculated by the inverse Euler update\n",
        "    #   as `next_position_adjusted - noisy_position_sequence[:,-1]`\n",
        "    #   matches the ground truth next velocity (noise cancels out).\n",
        "\n",
        "    return predicted_normalized_acceleration, target_normalized_acceleration\n",
        "\n",
        "  def _inverse_decoder_postprocessor(self, next_position, position_sequence):\n",
        "    \"\"\"Inverse of `_decoder_postprocessor`.\"\"\"\n",
        "\n",
        "    previous_position = position_sequence[:, -1]\n",
        "    previous_velocity = previous_position - position_sequence[:, -2]\n",
        "    next_velocity = next_position - previous_position\n",
        "    acceleration = next_velocity - previous_velocity\n",
        "\n",
        "    acceleration_stats = self._normalization_stats[\"acceleration\"]\n",
        "    normalized_acceleration = (\n",
        "        acceleration - acceleration_stats.mean) / acceleration_stats.std\n",
        "    return normalized_acceleration\n",
        "\n",
        "\n",
        "def time_diff(input_sequence):\n",
        "  return input_sequence[:, 1:] - input_sequence[:, :-1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "6ntN9CfJTROC"
      },
      "source": [
        "#@title ### noise_utils\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def get_random_walk_noise_for_position_sequence(\n",
        "    position_sequence, noise_std_last_step):\n",
        "  \"\"\"Returns random-walk noise in the velocity applied to the position.\"\"\"\n",
        "\n",
        "  velocity_sequence = learned_simulator.time_diff(position_sequence)\n",
        "\n",
        "  # We want the noise scale in the velocity at the last step to be fixed.\n",
        "  # Because we are going to compose noise at each step using a random_walk:\n",
        "  # std_last_step**2 = num_velocities * std_each_step**2\n",
        "  # so to keep `std_last_step` fixed, we apply at each step:\n",
        "  # std_each_step `std_last_step / np.sqrt(num_input_velocities)`\n",
        "  # TODO(alvarosg): Make sure this is consistent with the value and\n",
        "  # description provided in the paper.\n",
        "  num_velocities = velocity_sequence.shape.as_list()[1]\n",
        "  velocity_sequence_noise = tf.random.normal(\n",
        "      tf.shape(velocity_sequence),\n",
        "      stddev=noise_std_last_step / num_velocities ** 0.5,\n",
        "      dtype=position_sequence.dtype)\n",
        "\n",
        "  # Apply the random walk.\n",
        "  velocity_sequence_noise = tf.cumsum(velocity_sequence_noise, axis=1)\n",
        "\n",
        "  # Integrate the noise in the velocity to the positions, assuming\n",
        "  # an Euler intergrator and a dt = 1, and adding no noise to the very first\n",
        "  # position (since that will only be used to calculate the first position\n",
        "  # change).\n",
        "  position_sequence_noise = tf.concat([\n",
        "      tf.zeros_like(velocity_sequence_noise[:, 0:1]),\n",
        "      tf.cumsum(velocity_sequence_noise, axis=1)], axis=1)\n",
        "\n",
        "  return position_sequence_noise"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKnr3tQGX7pv"
      },
      "source": [
        "#@title ### reading_utils\n",
        "\n",
        "import functools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a description of the features.\n",
        "_FEATURE_DESCRIPTION = {\n",
        "    'pos': tf.io.FixedLenSequenceFeature([timesteps//save_interval, N, 2], tf.string),\n",
        "    'vel': tf.io.FixedLenSequenceFeature([timesteps//save_interval, N, 2], tf.string)\n",
        "}\n",
        "\n",
        "_FEATURE_DESCRIPTION_WITH_GLOBAL_CONTEXT = _FEATURE_DESCRIPTION.copy()\n",
        "_FEATURE_DESCRIPTION_WITH_GLOBAL_CONTEXT['step_context'] = tf.io.VarLenFeature(\n",
        "    tf.string)\n",
        "\n",
        "_FEATURE_DTYPES = {\n",
        "    'pos': {\n",
        "        'in': np.float32,\n",
        "        'out': tf.float32\n",
        "    },\n",
        "    'vel': {\n",
        "        'in': np.float32,\n",
        "        'out': tf.float32\n",
        "    }\n",
        "}\n",
        "\n",
        "_CONTEXT_FEATURES = {\n",
        "    'group_id': tf.io.FixedLenFeature([1],tf.int64)\n",
        "}\n",
        "\n",
        "\n",
        "def convert_to_tensor(x, encoded_dtype):\n",
        "  if len(x) == 1:\n",
        "    out = np.frombuffer(x[0].numpy(), dtype=encoded_dtype)\n",
        "  else:\n",
        "    out = []\n",
        "    for el in x:\n",
        "      out.append(np.frombuffer(el.numpy(), dtype=encoded_dtype))\n",
        "  out = tf.convert_to_tensor(np.array(out))\n",
        "  return out\n",
        "\n",
        "\n",
        "def parse_serialized_simulation_example(example_proto, metadata):\n",
        "  \"\"\"Parses a serialized simulation tf.SequenceExample.\n",
        "  Args:\n",
        "    example_proto: A string encoding of the tf.SequenceExample proto.\n",
        "    metadata: A dict of metadata for the dataset.\n",
        "  Returns:\n",
        "    context: A dict, with features that do not vary over the trajectory.\n",
        "    parsed_features: A dict of tf.Tensors representing the parsed examples\n",
        "      across time, where axis zero is the time axis.\n",
        "  \"\"\"\n",
        "  if 'context_mean' in metadata:\n",
        "    feature_description = _FEATURE_DESCRIPTION_WITH_GLOBAL_CONTEXT\n",
        "  else:\n",
        "    feature_description = _FEATURE_DESCRIPTION\n",
        "  \n",
        "  context, parsed_features = tf.io.parse_single_sequence_example(\n",
        "      example_proto,\n",
        "      context_features=_CONTEXT_FEATURES,\n",
        "      sequence_features=feature_description)\n",
        "\n",
        "  #print(parsed_features.items())\n",
        "  for feature_key, item in parsed_features.items():\n",
        "    #print(feature_key, item)\n",
        "    convert_fn = functools.partial(\n",
        "        convert_to_tensor, encoded_dtype=_FEATURE_DTYPES[feature_key]['in'])\n",
        "    parsed_features[feature_key] = tf.py_function(\n",
        "        convert_fn, inp=[item], Tout=_FEATURE_DTYPES[feature_key]['out'])\n",
        "    \n",
        "  #print(parsed_features.items())\n",
        "  # There is an extra frame at the beginning so we can calculate pos change\n",
        "  # for all frames used in the paper.\n",
        "  position_shape = [metadata['sequence_length'] + 1, N, metadata['dim']]\n",
        "  #print(position_shape)\n",
        "  # Reshape positions/velocities to correct dim:\n",
        "  parsed_features['pos'] = tf.reshape(parsed_features['pos'],\n",
        "                                           position_shape)\n",
        "  parsed_features['vel'] = tf.reshape(parsed_features['vel'],\n",
        "                                           position_shape)\n",
        "\n",
        "  # Set correct shapes of the remaining tensors.\n",
        "  sequence_length = metadata['sequence_length'] + 1\n",
        "  if 'context_mean' in metadata:\n",
        "    context_feat_len = len(metadata['context_mean'])\n",
        "    parsed_features['step_context'] = tf.reshape(\n",
        "        parsed_features['step_context'],\n",
        "        [sequence_length, context_feat_len])\n",
        "  \n",
        "  # Decode particle type explicitly\n",
        "  context['group_id'] = tf.py_function(\n",
        "      functools.partial(convert_fn, encoded_dtype=np.int64),\n",
        "      inp=[context['group_id']],\n",
        "      Tout=[tf.int64])\n",
        "  context['group_id'] = tf.reshape(context['group_id'], [1])\n",
        "  return context, parsed_features\n",
        "\n",
        "\n",
        "def split_trajectory(context, features, window_length=7):\n",
        "  \"\"\"Splits trajectory into sliding windows.\"\"\"\n",
        "  # Our strategy is to make sure all the leading dimensions are the same size,\n",
        "  # then we can use from_tensor_slices.\n",
        "  \n",
        "  trajectory_length = features['pos'].get_shape().as_list()[0]\n",
        "\n",
        "  # We then stack window_length position changes so the final\n",
        "  # trajectory length will be - window_length +1 (the 1 to make sure we get\n",
        "  # the last split).\n",
        "  input_trajectory_length = trajectory_length - window_length + 1\n",
        "\n",
        "  model_input_features = {}\n",
        "  # Prepare the context features per step.\n",
        "  model_input_features['group_id'] = tf.tile(\n",
        "      tf.expand_dims(context['group_id'], axis=0),\n",
        "      [input_trajectory_length, 1])\n",
        "\n",
        "  if 'step_context' in features:\n",
        "    global_stack = []\n",
        "    for idx in range(input_trajectory_length):\n",
        "      global_stack.append(features['step_context'][idx:idx + window_length])\n",
        "    model_input_features['step_context'] = tf.stack(global_stack)\n",
        "\n",
        "  pos_stack = []\n",
        "  for idx in range(input_trajectory_length):\n",
        "    pos_stack.append(features['pos'][idx:idx + window_length])\n",
        "  # Get the corresponding positions\n",
        "  model_input_features['pos'] = tf.stack(pos_stack)\n",
        "\n",
        "  vel_stack = []\n",
        "  for idx in range(input_trajectory_length):\n",
        "    vel_stack.append(features['vel'][idx:idx + window_length])\n",
        "  # Get the corresponding velocities\n",
        "  model_input_features['vel'] = tf.stack(vel_stack)\n",
        "\n",
        "  return tf.data.Dataset.from_tensor_slices(model_input_features)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFgDdkQqT4bQ"
      },
      "source": [
        "#@title ### Preprocessing\n",
        "\n",
        "train_dir = 'train_datasets/'\n",
        "valid_dir = 'valid_datasets/'\n",
        "\n",
        "feature_description = {'group_id': tf.io.FixedLenFeature([], tf.int64),\n",
        "                        'pos': tf.io.FixedLenFeature([], tf.string),\n",
        "                        'vel': tf.io.FixedLenFeature([], tf.string)}\n",
        "\n",
        "def _parse_record(x):\n",
        "  # Parse the input tf.train.Example proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(x, feature_description)\n",
        "\n",
        "def _parse_tensor(x):\n",
        "    output = {'group_id': x['group_id'],\n",
        "                'pos': tf.io.parse_tensor(x['pos'],out_type=tf.float32),\n",
        "                'vel': tf.io.parse_tensor(x['vel'],out_type=tf.float32)}\n",
        "    return output\n",
        "\n",
        "train_dataset =  tf.data.TFRecordDataset(tf.data.Dataset.list_files([train_dir + filename for filename in os.listdir(train_dir)]))\n",
        "\n",
        "parsed_train_dataset = train_dataset.map(_parse_record)\n",
        "parsed_train_dataset = parsed_train_dataset.map(_parse_tensor)\n",
        "parsed_train_dataset = parsed_train_dataset.shuffle(10000, reshuffle_each_iteration=True)\n",
        "parsed_train_dataset = parsed_train_dataset.batch(32, drop_remainder=True)\n",
        "\n",
        "\n",
        "\n",
        "valid_dataset =  tf.data.TFRecordDataset(tf.data.Dataset.list_files([valid_dir + filename for filename in os.listdir(valid_dir)]))\n",
        "\n",
        "parsed_valid_dataset = valid_dataset.map(_parse_record)\n",
        "parsed_valid_dataset = parsed_valid_dataset.map(_parse_tensor)\n",
        "parsed_valid_dataset = parsed_valid_dataset.shuffle(10000, reshuffle_each_iteration=True)\n",
        "parsed_valid_dataset = parsed_valid_dataset.batch(4, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "VzgGNFysMx35"
      },
      "source": [
        "#@title ### Preprocessing function\n",
        "\n",
        "interaction_radius = 15.0\n",
        "L = 200\n",
        "def preprocess_data(databatch):\n",
        "    \n",
        "    # node features xpos, ypos, xvel, yvel\n",
        "    # edge features distance, rel angle to receiver\n",
        "    X = databatch['pos']\n",
        "    V = databatch['vel']\n",
        "    \n",
        "    Xx = tf.expand_dims(X[...,0],-1)\n",
        "    dx = -Xx + tf.linalg.matrix_transpose(Xx)\n",
        "    dx = tf.where(dx>0.5*L, dx-L, dx)\n",
        "    dx = tf.where(dx<-0.5*L, dx+L, dx)\n",
        "\n",
        "    Xy = tf.expand_dims(X[...,1],-1)\n",
        "    dy = -Xy + tf.linalg.matrix_transpose(Xy)\n",
        "    dy = tf.where(dy>0.5*L, dy-L, dy)\n",
        "    dy = tf.where(dy<-0.5*L, dy+L, dy)\n",
        "\n",
        "\n",
        "\n",
        "    A = tf.expand_dims(tf.math.atan2(V[...,1],V[...,0]),-1)\n",
        "    angle_to_neigh = tf.math.atan2(dy, dx)\n",
        "\n",
        "    rel_angle_to_neigh = angle_to_neigh - A\n",
        "\n",
        "    dist = tf.math.sqrt(tf.square(dx)+tf.square(dy))\n",
        "\n",
        "    adj_matrix = tf.where(dist<interaction_radius, tf.ones_like(dist,dtype=tf.int32), tf.zeros_like(dist,dtype=tf.int32))\n",
        "    adj_matrix = tf.linalg.set_diag(adj_matrix, tf.zeros(tf.shape(adj_matrix)[:2],dtype=tf.int32))\n",
        "    sender_recv_list = tf.where(adj_matrix)\n",
        "    n_edge = tf.reduce_sum(adj_matrix, axis=[1,2])\n",
        "    n_node = tf.ones_like(n_edge)*tf.shape(adj_matrix)[-1]\n",
        "\n",
        "    senders = sender_recv_list[:,1] + sender_recv_list[:,0]*tf.shape(adj_matrix,out_type=tf.int64)[-1]\n",
        "    receivers = sender_recv_list[:,2] + sender_recv_list[:,0]*tf.shape(adj_matrix,out_type=tf.int64)[-1]\n",
        "\n",
        "\n",
        "    edge_distance = tf.expand_dims(tf.gather_nd(dist,sender_recv_list),-1)\n",
        "    edge_x_distance =  tf.expand_dims(tf.gather_nd(tf.math.cos(rel_angle_to_neigh),sender_recv_list),-1)  # relative to sender heading\n",
        "    edge_y_distance =  tf.expand_dims( tf.gather_nd(tf.math.sin(rel_angle_to_neigh),sender_recv_list),-1)  # relative to sender heading\n",
        "\n",
        "\n",
        "    edges = tf.concat([edge_distance,edge_x_distance,edge_y_distance],axis=-1)\n",
        "\n",
        "    node_positions = tf.reshape(X,(-1,2))\n",
        "    node_velocities = tf.reshape(V,(-1,2))\n",
        "\n",
        "    nodes = tf.concat([node_positions,node_velocities],axis=-1)\n",
        "\n",
        "    gn = graphs.GraphsTuple(nodes=nodes,edges=edges,globals=None,receivers=receivers,senders=senders,n_node=n_node,n_edge=n_edge)\n",
        "    gn = utils_tf.set_zero_global_features(gn,1)\n",
        "    \n",
        "    return gn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "AbMPiqZENpAe"
      },
      "source": [
        "#@title ### More Functions\n",
        "\n",
        "INPUT_SEQUENCE_LENGTH = 6  # So we can calculate the last 5 velocities.\n",
        "NUM_PARTICLE_TYPES = 1\n",
        "KINEMATIC_PARTICLE_ID = 3\n",
        "\n",
        "batch_size=5\n",
        "\n",
        "def _read_metadata(data_path):\n",
        "    with open(os.path.join(data_path, 'metadata.json'), 'rt') as fp:\n",
        "        return json.loads(fp.read())\n",
        "\n",
        "def prepare_inputs(tensor_dict):\n",
        "  \"\"\"Prepares a single stack of inputs by calculating inputs and targets.\n",
        "\n",
        "  Computes n_particles_per_example, which is a tensor that contains information\n",
        "  about how to partition the axis - i.e. which nodes belong to which graph.\n",
        "\n",
        "  Adds a batch axis to `n_particles_per_example` and `step_context` so they can\n",
        "  later be batched using `batch_concat`. This batch will be the same as if the\n",
        "  elements had been batched via stacking.\n",
        "\n",
        "  Note that all other tensors have a variable size particle axis,\n",
        "  and in this case they will simply be concatenated along that\n",
        "  axis.\n",
        "\n",
        "\n",
        "\n",
        "  Args:\n",
        "    tensor_dict: A dict of tensors containing positions, and step context (\n",
        "    if available).\n",
        "\n",
        "  Returns:\n",
        "    A tuple of input features and target positions.\n",
        "\n",
        "  \"\"\"\n",
        "  # Position is encoded as [sequence_length, num_particles, dim] but the model\n",
        "  # expects [num_particles, sequence_length, dim].\n",
        "  pos = tensor_dict['pos']\n",
        "  pos = pos[tf.newaxis,...]\n",
        "  pos = tf.transpose(pos, perm=[0, 2, 1, 3])\n",
        "\n",
        "  # The target position is the final step of the stack of positions.\n",
        "  target_position = pos[:, :, -1]\n",
        "\n",
        "  # Remove the target from the input.\n",
        "  tensor_dict['pos'] = pos[:, :, :-1]\n",
        "\n",
        "  # Velocity is encoded as [sequence_length, num_particles, dim] but the model\n",
        "  # expects [num_particles, sequence_length, dim].\n",
        "  vel = tensor_dict['vel']\n",
        "  vel = vel[tf.newaxis, ...]\n",
        "  vel = tf.transpose(vel, perm=[0, 2, 1, 3])\n",
        "\n",
        "  # The target position is the final step of the stack of positions.\n",
        "  target_position = vel[:, :, -1]\n",
        "\n",
        "  # Remove the target from the input.\n",
        "  tensor_dict['vel'] = vel[:, :, :-1]\n",
        "\n",
        "  # Compute the number of particles per example.\n",
        "  num_particles = tf.shape(pos)[0]\n",
        "  # Add an extra dimension for stacking via concat.\n",
        "  tensor_dict['n_particles_per_example'] = num_particles[tf.newaxis]\n",
        "\n",
        "  if 'step_context' in tensor_dict:\n",
        "    # Take the input global context. We have a stack of global contexts,\n",
        "    # and we take the penultimate since the final is the target.\n",
        "    tensor_dict['step_context'] = tensor_dict['step_context'][-2]\n",
        "    # Add an extra dimension for stacking via concat.\n",
        "    tensor_dict['step_context'] = tensor_dict['step_context'][tf.newaxis]\n",
        "  return tensor_dict, target_position\n",
        "\n",
        "def batch_concat(dataset, batch_size):\n",
        "  \"\"\"We implement batching as concatenating on the leading axis.\"\"\"\n",
        "\n",
        "  # We create a dataset of datasets of length batch_size.\n",
        "  windowed_ds = dataset.window(batch_size)\n",
        "  print(windowed_ds)\n",
        "  for window in dataset:\n",
        "      print(\"yes\")\n",
        "      [print(item.numpy()) for item in window]\n",
        "  # The plan is then to reduce every nested dataset by concatenating. We can\n",
        "  # do this using tf.data.Dataset.reduce. This requires an initial state, and\n",
        "  # then incrementally reduces by running through the dataset\n",
        "\n",
        "  # Get initial state. In this case this will be empty tensors of the\n",
        "  # correct shape.\n",
        "  initial_state = tree.map_structure(\n",
        "      lambda spec: tf.zeros(  # pylint: disable=g-long-lambda\n",
        "          shape=[1] + spec.shape.as_list()[1:], dtype=spec.dtype),\n",
        "      dataset.element_spec)\n",
        "  #print(initial_state.shape)\n",
        "  # We run through the nest and concatenate each entry with the previous state.\n",
        "  def reduce_window(initial_state, ds):\n",
        "    return ds.reduce(initial_state, lambda x, y: tf.stack([x, y], axis=0))\n",
        "\n",
        "  return windowed_ds.map(\n",
        "      lambda *x: tree.map_structure(reduce_window, initial_state, x))\n",
        "\n",
        "\n",
        "def prepare_rollout_inputs(context, features):\n",
        "  \"\"\"Prepares an inputs trajectory for rollout.\"\"\"\n",
        "  out_dict = {**context}\n",
        "  # Position is encoded as [sequence_length, num_particles, dim] but the model\n",
        "  # expects [num_particles, sequence_length, dim].\n",
        "  pos = tf.transpose(features['pos'], [1, 0, 2])\n",
        "  # The target position is the final step of the stack of positions.\n",
        "  target_position = pos[:, -1]\n",
        "  # Remove the target from the input.\n",
        "  out_dict['pos'] = pos[:, :-1]\n",
        "\n",
        "  # Velocity is encoded as [sequence_length, num_particles, dim] but the model\n",
        "  # expects [num_particles, sequence_length, dim].\n",
        "  vel = tf.transpose(features['vel'], [1, 0, 2])\n",
        "  # The target position is the final step of the stack of positions.\n",
        "  target_position = vel[:, -1]\n",
        "  # Remove the target from the input.\n",
        "  out_dict['vel'] = vel[:, :-1]\n",
        "\n",
        "  # Compute the number of nodes\n",
        "  out_dict['n_particles_per_example'] = [tf.shape(pos)[0]]\n",
        "  if 'step_context' in features:\n",
        "    out_dict['step_context'] = features['step_context']\n",
        "  out_dict['is_trajectory'] = tf.constant([True], tf.bool)\n",
        "  return out_dict, target_position"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgUJ3nUEOVfs",
        "outputId": "db0fb140-a584-47a5-c75b-10e791c1e276"
      },
      "source": [
        "\n",
        "import collections\n",
        "import functools\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import tree\n",
        "\n",
        "data_path = '/content/'\n",
        "\n",
        "\"\"\"\n",
        "What metadata do we need?\n",
        "-sequence length\n",
        "-dim\n",
        "\"\"\"\n",
        "\n",
        "#Experiment metadata dict\n",
        "metadata = {\"sequence_length\": timesteps//save_interval,\n",
        "            \"dim\": 2,\n",
        "            \"acc_mean\": 1,\n",
        "            \"acc_std\": 1,\n",
        "            \"vel_mean\": 1,\n",
        "            \"vel_std\": 1,\n",
        "            \"default_connectivity_radius\": 1,\n",
        "            \"bounds\": 1\n",
        "            }\n",
        "\n",
        "\"\"\"\n",
        "# Loads the metadata of the dataset.\n",
        "metadata = _read_metadata(data_path)\n",
        "\"\"\"\n",
        "\n",
        "#Create a tf.data.Dataset from the TFRecord.\n",
        "ds = tf.data.TFRecordDataset(['train_datasets/microstates-' + str(i) + '.tfrecords' for i in range(1)])\n",
        "print(1, ds)\n",
        "\n",
        "feature_description2 = {\n",
        "    'pos': tf.io.FixedLenSequenceFeature([timesteps//save_interval, N, 2], tf.string),\n",
        "    'vel': tf.io.FixedLenSequenceFeature([timesteps//save_interval, N, 2], tf.string)\n",
        "}\n",
        "feature_description = {'group_id': tf.io.FixedLenFeature([], tf.int64),\n",
        "                        #'timestep': tf.io.FixedLenFeature([], tf.int64),\n",
        "                        #'parameter_vector': tf.io.FixedLenSequenceFeature([], tf.float32,allow_missing=True),\n",
        "                        'pos': tf.io.FixedLenFeature([], tf.string),\n",
        "                        'vel': tf.io.FixedLenFeature([], tf.string)}\n",
        "\n",
        "_CONTEXT_FEATURES = {\n",
        "    'group_id': tf.io.FixedLenFeature([],tf.int64)\n",
        "}\n",
        "def _parse_record(x):\n",
        "  # Parse the input tf.train.Example proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(x, feature_description)\n",
        "\n",
        "def _parse_record2(x):\n",
        "    return tf.io.parse_single_sequence_example(x,\n",
        "                                                context_features=_CONTEXT_FEATURES,\n",
        "                                                sequence_features=feature_description2)\n",
        "def _parse_tensor(x):\n",
        "    output = {'group_id': x['group_id'],\n",
        "                #'timestep': x['timestep'],\n",
        "                #'parameter_vector': x['parameter_vector'],\n",
        "                'pos': tf.io.parse_tensor(x['pos'],out_type=tf.float32),\n",
        "                'vel': tf.io.parse_tensor(x['vel'],out_type=tf.float32)}\n",
        "    return output\n",
        "\n",
        "def _get_pos(x):\n",
        "    return (x['pos'])\n",
        "# train_dataset =  tf.data.TFRecordDataset(tf.data.Dataset.list_files([train_dir + filename for filename in os.listdir(train_dir)]))\n",
        "\n",
        "ds = ds.map(_parse_record)\n",
        "ds = ds.map(_parse_tensor)\n",
        "#ds = ds.map(_get_pos)\n",
        "\n",
        "def make_window_dataset(x):#ds, window_size=5, shift=1, stride=1):\n",
        "  window_size=3\n",
        "\n",
        "  windows = tf.data.Dataset.from_tensor_slices((x['pos'],x['vel']))\n",
        "  windows = windows.window(window_size, shift=1, stride=1)\n",
        "\n",
        "  def sub_to_batch(sub):\n",
        "    return sub.batch(window_size, drop_remainder=True)\n",
        "\n",
        "  windows = windows.flat_map(lambda x,y: tf.data.Dataset.zip((x.batch(window_size, drop_remainder=True),x.batch(window_size, drop_remainder=True))))\n",
        "  return windows\n",
        "\n",
        "\n",
        "#ds = make_window_dataset(dataset, window_size=3, shift = None, stride=1)\n",
        "ds = ds.flat_map(make_window_dataset)\n",
        "\n",
        "# for example in ds.take(20):\n",
        "#   print(example.numpy())\n",
        "\n",
        "\n",
        "# def flat_map_impl(x):\n",
        "#     #print(x)\n",
        "#     ds2 = tf.data.Dataset.from_tensor_slices(x)\n",
        "#     #ds2 = ds2.window(5)\n",
        "#     #ds2 = ds2.flat_map(lambda x: x)#.take(1)\n",
        "#     return ds2\n",
        "\n",
        "# ds = ds.flat_map(flat_map_impl)\n",
        "\n",
        "#ds = ds.take(1)\n",
        "\n",
        "#window_size = 5\n",
        "\n",
        "#windows = ds.window(window_size, shift=1)\n",
        "#for sub_ds in windows.take(5):\n",
        "#  print(sub_ds)\n",
        "#ds2 = tf.data.Dataset.from_generator(ds)#.window(5)\n",
        "#ds = tf.data.experimental.sample_from_datasets([ds])\n",
        "\n",
        "#ds = ds.map(_parse_record2)\n",
        "\n",
        "\n",
        "\n",
        "# if 'context_mean' in metadata:\n",
        "#     feature_description = _FEATURE_DESCRIPTION_WITH_GLOBAL_CONTEXT\n",
        "#   else:\n",
        "#     feature_description = _FEATURE_DESCRIPTION\n",
        "  \n",
        "#   context, parsed_features = tf.io.parse_single_sequence_example(\n",
        "#       example_proto,\n",
        "#       context_features=_CONTEXT_FEATURES,\n",
        "#       sequence_features=feature_description)\n",
        "\n",
        "#   #print(parsed_features.items())\n",
        "#   for feature_key, item in parsed_features.items():\n",
        "#     #print(feature_key, item)\n",
        "#     convert_fn = functools.partial(\n",
        "#         convert_to_tensor, encoded_dtype=_FEATURE_DTYPES[feature_key]['in'])\n",
        "#     parsed_features[feature_key] = tf.py_function(\n",
        "#         convert_fn, inp=[item], Tout=_FEATURE_DTYPES[feature_key]['out'])\n",
        "    \n",
        "#   #print(parsed_features.items())\n",
        "#   # There is an extra frame at the beginning so we can calculate pos change\n",
        "#   # for all frames used in the paper.\n",
        "#   position_shape = [metadata['sequence_length'] + 1, N, metadata['dim']]\n",
        "#   #print(position_shape)\n",
        "#   # Reshape positions/velocities to correct dim:\n",
        "#   parsed_features['pos'] = tf.reshape(parsed_features['pos'],\n",
        "#                                            position_shape)\n",
        "#   parsed_features['vel'] = tf.reshape(parsed_features['vel'],\n",
        "#                                            position_shape)\n",
        "\n",
        "#   # Set correct shapes of the remaining tensors.\n",
        "#   sequence_length = metadata['sequence_length'] + 1\n",
        "#   if 'context_mean' in metadata:\n",
        "#     context_feat_len = len(metadata['context_mean'])\n",
        "#     parsed_features['step_context'] = tf.reshape(\n",
        "#         parsed_features['step_context'],\n",
        "#         [sequence_length, context_feat_len])\n",
        "  \n",
        "#   # Decode particle type explicitly\n",
        "#   context['group_id'] = tf.py_function(\n",
        "#       functools.partial(convert_fn, encoded_dtype=np.int64),\n",
        "#       inp=[context['group_id']],\n",
        "#       Tout=[tf.int64])\n",
        "#   context['group_id'] = tf.reshape(context['group_id'], [1])\n",
        "#   return context, parsed_features\n",
        "# #You cannot iterate over ds even here\n",
        "\n",
        "#ds = ds.map(functools.partial(parse_serialized_simulation_example, metadata=metadata))\n",
        "# print(2, ds)\n",
        "# # Splits an entire trajectory into chunks of 7 steps.\n",
        "# # Previous 5 velocities, current velocity and target.\n",
        "# split_with_window = functools.partial(\n",
        "#     split_trajectory,\n",
        "#     window_length=INPUT_SEQUENCE_LENGTH + 1)\n",
        "# ds = ds.flat_map(split_with_window)\n",
        "# print(3, ds)\n",
        "# # Splits a chunk into input steps and target steps\n",
        "# ds = ds.map(prepare_inputs)\n",
        "# print(4, ds)\n",
        "# # If in train mode, repeat dataset forever and shuffle.\n",
        "# ds = ds.repeat()\n",
        "# ds = ds.shuffle(512)\n",
        "# print(5, ds)\n",
        "# # Custom batching on the leading axis.\n",
        "# #ds = batch_concat(ds, batch_size)\n",
        "# print(6, ds)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 <TFRecordDatasetV2 shapes: (), types: tf.string>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSQ0w45nEq03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c0779d2-79c6-40e5-d177-c9d2ee306c15"
      },
      "source": [
        "for d in ds:#.as_numpy_iterator():\n",
        "    print(d[0].shape)\n",
        "    break"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 100, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eyEh9I0QRI4",
        "outputId": "a3534f0d-6f5c-446b-ed9a-3b13d1848718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for dd in d:\n",
        "    print(dd.shape)\n",
        "    break"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKU54VGLTXb3",
        "outputId": "4f7e94f1-f952-407f-b2b8-2edd3d6a6748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "initial_state = tf.constant(0, dtype=tf.int64)\n",
        "scan_func = lambda state, i: (state + i, state + i)\n",
        "dataset = dataset.scan(initial_state=initial_state, scan_func=scan_func)\n",
        "list(dataset.as_numpy_iterator())\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 3, 6, 10, 15, 21, 28, 36, 45]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I58MzYqyTzpo",
        "outputId": "68023420-cb25-4e2b-f9bd-135df18a8261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gen = [tf.range(100*i,10+100*i) for i in range(10)]\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(lambda: gen, tf.int64,output_shapes=[None])\n",
        "\n",
        "def make_window_dataset(x):#ds, window_size=5, shift=1, stride=1):\n",
        "  window_size=3\n",
        "  shift = 1\n",
        "  stride=1\n",
        "\n",
        "  windows = tf.data.Dataset.from_tensor_slices((x,x))\n",
        "  windows = windows.window(window_size, shift=shift, stride=stride)\n",
        "  #return windows\n",
        "\n",
        "  def sub_to_batch(sub,s2):\n",
        "    return tf.data.Dataset.zip((sub.batch(window_size, drop_remainder=True),s2.batch(window_size, drop_remainder=True)))\n",
        "\n",
        "  windows = windows.flat_map(sub_to_batch)\n",
        "  return windows\n",
        "\n",
        "\n",
        "#ds = make_window_dataset(dataset, window_size=3, shift = None, stride=1)\n",
        "ds = dataset.flat_map(make_window_dataset)\n",
        "\n",
        "for example in ds.take(20):\n",
        "  print(example[0].numpy(),example[1].numpy())\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2] [0 1 2]\n",
            "[1 2 3] [1 2 3]\n",
            "[2 3 4] [2 3 4]\n",
            "[3 4 5] [3 4 5]\n",
            "[4 5 6] [4 5 6]\n",
            "[5 6 7] [5 6 7]\n",
            "[6 7 8] [6 7 8]\n",
            "[7 8 9] [7 8 9]\n",
            "[100 101 102] [100 101 102]\n",
            "[101 102 103] [101 102 103]\n",
            "[102 103 104] [102 103 104]\n",
            "[103 104 105] [103 104 105]\n",
            "[104 105 106] [104 105 106]\n",
            "[105 106 107] [105 106 107]\n",
            "[106 107 108] [106 107 108]\n",
            "[107 108 109] [107 108 109]\n",
            "[200 201 202] [200 201 202]\n",
            "[201 202 203] [201 202 203]\n",
            "[202 203 204] [202 203 204]\n",
            "[203 204 205] [203 204 205]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1MFLkS4UIbk",
        "outputId": "f218ab48-7172-437f-d4ed-6defc3396af7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for d in dataset:\n",
        "    print(d)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int64)\n",
            "tf.Tensor([ 1  2  3  4  5  6  7  8  9 10], shape=(10,), dtype=int64)\n",
            "tf.Tensor([ 2  3  4  5  6  7  8  9 10 11], shape=(10,), dtype=int64)\n",
            "tf.Tensor([ 3  4  5  6  7  8  9 10 11 12], shape=(10,), dtype=int64)\n",
            "tf.Tensor([ 4  5  6  7  8  9 10 11 12 13], shape=(10,), dtype=int64)\n",
            "tf.Tensor([ 5  6  7  8  9 10 11 12 13 14], shape=(10,), dtype=int64)\n",
            "tf.Tensor([ 6  7  8  9 10 11 12 13 14 15], shape=(10,), dtype=int64)\n",
            "tf.Tensor([ 7  8  9 10 11 12 13 14 15 16], shape=(10,), dtype=int64)\n",
            "tf.Tensor([ 8  9 10 11 12 13 14 15 16 17], shape=(10,), dtype=int64)\n",
            "tf.Tensor([ 9 10 11 12 13 14 15 16 17 18], shape=(10,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkRSc9W6FB6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d23bb1-ec4f-4e98-8a7e-7e25685288f3"
      },
      "source": [
        "for x in ds.flat_map(lambda x: x).take(1):\n",
        "   print(x.numpy(), end=' ')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 20.760218 142.06569 ]\n",
            "  [ 84.208595  20.093307]\n",
            "  [118.98569   71.48303 ]\n",
            "  ...\n",
            "  [131.05612  152.07451 ]\n",
            "  [172.14363  118.43679 ]\n",
            "  [ 65.101036  52.436974]]\n",
            "\n",
            " [[ 22.610064 146.70657 ]\n",
            "  [ 79.93171   17.508766]\n",
            "  [121.5864    67.216965]\n",
            "  ...\n",
            "  [127.3659   148.72049 ]\n",
            "  [170.54655  113.702965]\n",
            "  [ 61.047462  49.512726]]\n",
            "\n",
            " [[ 24.384892 151.3793  ]\n",
            "  [ 75.45887   15.279919]\n",
            "  [124.97054   63.572205]\n",
            "  ...\n",
            "  [123.59827  145.43948 ]\n",
            "  [170.70056  108.712715]\n",
            "  [ 56.7892    46.90427 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 30.989862 161.92624 ]\n",
            "  [146.26755  170.69328 ]\n",
            "  [ 62.230206  97.63636 ]\n",
            "  ...\n",
            "  [128.49237   65.80049 ]\n",
            "  [176.91776   86.40204 ]\n",
            "  [ 42.856564 194.97238 ]]\n",
            "\n",
            " [[ 29.398932 166.66576 ]\n",
            "  [143.67657  174.9676  ]\n",
            "  [ 63.279446  92.748634]\n",
            "  ...\n",
            "  [123.563774  66.60753 ]\n",
            "  [176.55753   81.41979 ]\n",
            "  [ 38.43589  192.63893 ]]\n",
            "\n",
            " [[ 27.561266 171.31247 ]\n",
            "  [140.9535   179.15826 ]\n",
            "  [ 64.85887   88.01017 ]\n",
            "  ...\n",
            "  [118.716644  67.81467 ]\n",
            "  [175.76974   76.483574]\n",
            "  [ 34.027355 190.28535 ]]] "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2G1vNgrOSes",
        "outputId": "f54fe9ef-d211-4b52-95bf-b93a438118f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([50, 100, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI_Hf6iSE8mV"
      },
      "source": [
        "#@title ### Dummy Code to Reproduce Error Message\n",
        "\n",
        "print(ds.element_spec)\n",
        "print(iter(ds.take(1)))\n",
        "\n",
        "for window in ds.as_numpy_iterator():\n",
        "    print(window)\n",
        "\"\"\"\n",
        "for x in ds.take(10).as_numpy_iterator():\n",
        "  print(x)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "rUe5GAlNCD2X"
      },
      "source": [
        "#@title ### Create Model\n",
        "\n",
        "noise_std=6.7e-4\n",
        "latent_size=128\n",
        "hidden_size=128\n",
        "hidden_layers=2\n",
        "message_passing_steps=10\n",
        "\n",
        "\"\"\"Gets one step model for training simulation.\"\"\"\n",
        "#metadata = _read_metadata(data_path)\n",
        "model_kwargs = dict(\n",
        "      latent_size=latent_size,\n",
        "      mlp_hidden_size=hidden_size,\n",
        "      mlp_num_hidden_layers=hidden_layers,\n",
        "      num_message_passing_steps=message_passing_steps)\n",
        "def _combine_std(std_x, std_y):\n",
        "  return np.sqrt(std_x**2 + std_y**2)\n",
        "\n",
        "Stats = collections.namedtuple('Stats', ['mean', 'std'])\n",
        "vel_noise_std=noise_std\n",
        "acc_noise_std=noise_std\n",
        "\"\"\"Instantiates the simulator.\"\"\"\n",
        "# Cast statistics to numpy so they are arrays when entering the model.\n",
        "cast = lambda v: np.array(v, dtype=np.float32)\n",
        "acceleration_stats = Stats(cast(metadata['acc_mean']), _combine_std(cast(metadata['acc_std']), acc_noise_std))\n",
        "velocity_stats = Stats(cast(metadata['vel_mean']),_combine_std(cast(metadata['vel_std']), vel_noise_std))\n",
        "normalization_stats = {'acceleration': acceleration_stats, 'velocity': velocity_stats}\n",
        "\n",
        "\n",
        "\n",
        "if 'context_mean' in metadata:\n",
        "    context_stats = Stats(cast(metadata['context_mean']), cast(metadata['context_std']))\n",
        "    normalization_stats['context'] = context_stats\n",
        "\n",
        "\n",
        "simulator = LearnedSimulator(\n",
        "      num_dimensions=metadata['dim'],\n",
        "      connectivity_radius=metadata['default_connectivity_radius'],\n",
        "      graph_network_kwargs=model_kwargs,\n",
        "      boundaries=metadata['bounds'],\n",
        "      num_particle_types=NUM_PARTICLE_TYPES,\n",
        "      normalization_stats=normalization_stats,\n",
        "      particle_type_embedding_size=16)\n",
        "\n",
        "\n",
        "KINEMATIC_PARTICLE_ID = 3\n",
        "def get_kinematic_mask(particle_types):\n",
        "  \"\"\"Returns a boolean mask, set to true for kinematic (obstacle) particles.\"\"\"\n",
        "  return tf.equal(particle_types, KINEMATIC_PARTICLE_ID)\n",
        "\n",
        "#@tf.function\n",
        "def loss_fn(features, labels):\n",
        "    target_next_position = labels\n",
        "    # Sample the noise to add to the inputs to the model during training.\n",
        "    sampled_noise = noise_utils.get_random_walk_noise_for_position_sequence(\n",
        "        features['pos'], noise_std_last_step=noise_std)\n",
        "    non_kinematic_mask = tf.logical_not(get_kinematic_mask(features['particle_type']))\n",
        "    noise_mask = tf.cast(non_kinematic_mask, sampled_noise.dtype)[:, tf.newaxis, tf.newaxis]\n",
        "    sampled_noise *= noise_mask\n",
        "\n",
        "    # Get the predictions and target accelerations.\n",
        "    pred_target = simulator.get_predicted_and_target_normalized_accelerations(\n",
        "        next_position=target_next_position,\n",
        "        position_sequence=features['pos'],\n",
        "        position_sequence_noise=sampled_noise,\n",
        "        n_particles_per_example=features['n_particles_per_example'],\n",
        "        particle_types=features['particle_type'],\n",
        "        global_context=features.get('step_context'))\n",
        "    pred_acceleration, target_acceleration = pred_target\n",
        "\n",
        "    # Calculate the loss and mask out loss on kinematic particles/\n",
        "    loss = (pred_acceleration - target_acceleration)**2\n",
        "\n",
        "    num_non_kinematic = tf.reduce_sum(tf.cast(non_kinematic_mask, tf.float32))\n",
        "    loss = tf.where(tf.expand_dims(non_kinematic_mask,-1), loss, tf.zeros_like(loss))\n",
        "    loss = tf.reduce_sum(loss) / tf.reduce_sum(num_non_kinematic)\n",
        "    \n",
        "    return loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8VFYHpFS-6X"
      },
      "source": [
        "#@title ### Train\n",
        "\n",
        "min_lr = 1e-6\n",
        "lr = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4 - min_lr,\n",
        "                                decay_steps=int(5e6),\n",
        "                                decay_rate=0.1) #+ min_lr\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "# @tf.function - ideally we'd like to decorate this with tf.function for faster code - but the connectivity utils is written using numpy so will need to be converted to tensorflow code\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss_fn(x,y)\n",
        "    grads = tape.gradient(loss_value, simulator.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, simulator.trainable_variables))\n",
        "    return loss_value\n",
        "\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(iter(ds)):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bR7a7iXuQCJ"
      },
      "source": [
        "import tensorflow as tf \n",
        "raw_dataset = tf.data.TFRecordDataset(\"/content/train_datasets/microstates-0.tfrecords\")\n",
        "\n",
        "for raw_record in raw_dataset.take(1):\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(raw_record.numpy())\n",
        "    print(example)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
